{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3NTtwE_tJBM",
        "outputId": "1562b63f-d569-4b61-d54d-1bec94ff54fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_B3Vxla6mdNt"
      },
      "outputs": [],
      "source": [
        "!pip -q install -U transformers datasets accelerate evaluate optuna wandb\n",
        "# If CUDA isn't detected, restart runtime > change runtime type > GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ktv6TR9a-T3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d06c3330-76c9-490a-e60c-26c679e34a2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.5.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.16.4)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.43)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.14.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCcucSrt-Qeh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import glob\n",
        "import math\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn import Linear\n",
        "from torch.nn.utils import prune\n",
        "from torch.quantization import quantize_dynamic\n",
        "\n",
        "import transformers\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    get_scheduler,\n",
        "    set_seed,\n",
        "    AutoConfig,\n",
        ")\n",
        "\n",
        "from datasets import load_dataset, Dataset as HFDataset\n",
        "import evaluate\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        ")\n",
        "\n",
        "import wandb\n",
        "import optuna\n",
        "\n",
        "import shutil, os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdYgPxFDAi6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d53f74ad-2a5f-4eae-950c-f0bebf75b107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Set device for training (GPU if available, else CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7_EnvylAqi2"
      },
      "source": [
        "**Load Preprocessed DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlkIOwRSmira",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f150818-d8c5-401a-d067-cca653725b8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "All specified training, test data, and length statistics loaded successfully.\n",
            "\n",
            "DistilBERT Train Data (first 5 rows):\n",
            "                                          covid_norm  label\n",
            "0     [USER] [USER] [USER] [URL] and [URL] and [URL]      1\n",
            "1  advice Talk to your neighbours family to excha...      2\n",
            "2  covid Australia: Woolworths to give elderly, d...      2\n",
            "3  My food stock is not the only one which is emp...      2\n",
            "4  Me, ready to go at supermarket during the covi...      0\n",
            "Shape: (41157, 2)\n",
            "\n",
            "BERTweet Train Data (first 5 rows):\n",
            "                                          covid_norm  label\n",
            "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...      1\n",
            "1  advice Talk to your neighbours family to excha...      2\n",
            "2  covid Australia: Woolworths to give elderly, d...      2\n",
            "3  My food stock is not the only one which is emp...      2\n",
            "4  Me, ready to go at supermarket during the covi...      0\n",
            "Shape: (41157, 2)\n",
            "\n",
            "DistilBERT Test Data (first 5 rows):\n",
            "                                          covid_norm  label\n",
            "0  TRENDING: New Yorkers encounter empty supermar...      0\n",
            "1  When I couldn't find hand sanitizer at Fred Me...      2\n",
            "2  Find out how you can protect yourself and love...      2\n",
            "3  Panic buying hits New York City as anxious sho...      0\n",
            "4  toiletpaper dunnypaper covid covidaustralia co...      1\n",
            "Shape: (3798, 2)\n",
            "\n",
            "BERTweet Test Data (first 5 rows):\n",
            "                                          covid_norm  label\n",
            "0  TRENDING: New Yorkers encounter empty supermar...      0\n",
            "1  When I couldn't find hand sanitizer at Fred Me...      2\n",
            "2  Find out how you can protect yourself and love...      2\n",
            "3  #Panic buying hits #NewYork City as anxious sh...      0\n",
            "4  #toiletpaper #dunnypaper covid covidaustralia ...      1\n",
            "Shape: (3798, 2)\n",
            "\n",
            "Length Statistics (JSON content preview):\n",
            "{\n",
            "  \"distilbert\": {\n",
            "    \"overall\": {\n",
            "      \"p90\": 81.0,\n",
            "      \"p95\": 88.0,\n",
            "      \"p99\": 101.0,\n",
            "      \"%> 64\": 32.101465121364534,\n",
            "      \"%> 96\": 1.7955633306606409,\n",
            "      \"%> 128\": 0.07532133051485773\n",
            "    },\n",
            "    \"by_sentiment\": {\n",
            "      \"negative\": {\n",
            "        \"p95\": 85.0,\n",
            "        \"%> 64\": 31.46512534095337,\n",
            "        \"%> 96\": 1.0975451357319133,\n",
            "        \"%> 128\": 0.019483049746720355\n",
            "      },\n",
            "      \"neutral\": {\n",
            "        \"p95\": 89.0,\n",
            "        \"%> 64\": 24.893037728510308,\n",
            "        \"%> 96\": 2.554129391935693,\n",
            "        \"%> 128\": 0.31116297160637885\n",
            "      },\n",
            "      \"positive\": {\n",
            "        \"p95\": 89.0,\n",
            "        \"%> 64\": 35.725368502715284,\n",
            "        \"%> 96\": 2.066940042114596,\n",
            "        \"%> 128\": 0.02216557685913776\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"bertweet\": {\n",
            "    \"overall\": {\n",
            "      \"p90\": 73.0,\n",
            "      \"p95\": 78.0,\n",
            "      \"p99\": 88.0,\n",
            "      \"%> 64\": 22.404451247661395,\n",
            "      \"%> 96\": 0.2939961610418641,\n",
            "      \"%> 128\": 0.05588356780134606\n",
            "    },\n",
            "    \"by_sentiment\": {\n",
            "      \"negative\": {\n",
            "        \"p95\": 77.0,\n",
            "        \"%> 64\": 22.197688011430056,\n",
            "        \"%> 96\": 0.14287569814261594,\n",
            "        \"%> 128\": 0.0129886998311469\n",
            "      },\n",
            "      \"neutral\": {\n",
            "        \"p95\": 77.0,\n",
            "        \"%> 64\": 15.01361338000778,\n",
            "        \"%> 96\": 0.6871515622974199,\n",
            "        \"%> 128\": 0.24633735252171657\n",
            "      },\n",
            "      \"positive\": {\n",
            "        \"p95\": 79.0,\n",
            "        \"%> 64\": 25.739776127673725,\n",
            "        \"%> 96\": 0.2549041338800842,\n",
            "        \"%> 128\": 0.01108278842956888\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Expected Output: Mounted at /content/drive\n",
        "\n",
        "# Define your base directory where the files are located\n",
        "# This path should point to the folder containing your data on Google Drive\n",
        "BASE_DIR = \"/content/drive/MyDrive/ADV_DL\"\n",
        "\n",
        "# Define paths to your preprocessed data using the exact file names we specified\n",
        "DISTILBERT_TRAIN_FILE = f\"{BASE_DIR}/distilbert_train.xls\"\n",
        "BERTWEET_TRAIN_FILE   = f\"{BASE_DIR}/bertweet_train.xls\"\n",
        "DISTILBERT_TEST_FILE  = f\"{BASE_DIR}/distilbert_test.xls\"\n",
        "BERTWEET_TEST_FILE    = f\"{BASE_DIR}/bertweet_test.xls\"\n",
        "LENGTH_STATS_FILE     = f\"{BASE_DIR}/length_stats.json\"\n",
        "\n",
        "# Load the dataframes and JSON file\n",
        "try:\n",
        "    # Load training and test data for DistilBERT and BERTweet.\n",
        "    # The encoding \"ISO-8859-1\" is used in exercises\n",
        "    df_distilbert_train = pd.read_csv(DISTILBERT_TRAIN_FILE, encoding=\"ISO-8859-1\")\n",
        "    df_bertweet_train   = pd.read_csv(BERTWEET_TRAIN_FILE, encoding=\"ISO-8859-1\")\n",
        "    df_distilbert_test  = pd.read_csv(DISTILBERT_TEST_FILE, encoding=\"ISO-8859-1\")\n",
        "    df_bertweet_test    = pd.read_csv(BERTWEET_TEST_FILE, encoding=\"ISO-8859-1\")\n",
        "\n",
        "    # Load the length statistics from the JSON file\n",
        "    with open(LENGTH_STATS_FILE, 'r') as f:\n",
        "        length_stats = json.load(f)\n",
        "\n",
        "    print(\"All specified training, test data, and length statistics loaded successfully.\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: One or more files not found. Ensure they are in the specified directory ({BASE_DIR}): {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred during data loading: {e}\")\n",
        "\n",
        "# Display head and shapes for verification of dataframes, and confirm JSON loaded\n",
        "if 'df_distilbert_train' in locals():\n",
        "    print(\"\\nDistilBERT Train Data (first 5 rows):\")\n",
        "    print(df_distilbert_train.head())\n",
        "    print(f\"Shape: {df_distilbert_train.shape}\")\n",
        "\n",
        "if 'df_bertweet_train' in locals():\n",
        "    print(\"\\nBERTweet Train Data (first 5 rows):\")\n",
        "    print(df_bertweet_train.head())\n",
        "    print(f\"Shape: {df_bertweet_train.shape}\")\n",
        "\n",
        "if 'df_distilbert_test' in locals():\n",
        "    print(\"\\nDistilBERT Test Data (first 5 rows):\")\n",
        "    print(df_distilbert_test.head())\n",
        "    print(f\"Shape: {df_distilbert_test.shape}\")\n",
        "\n",
        "if 'df_bertweet_test' in locals():\n",
        "    print(\"\\nBERTweet Test Data (first 5 rows):\")\n",
        "    print(df_bertweet_test.head())\n",
        "    print(f\"Shape: {df_bertweet_test.shape}\")\n",
        "\n",
        "if 'length_stats' in locals():\n",
        "    print(\"\\nLength Statistics (JSON content preview):\")\n",
        "    print(json.dumps(length_stats, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmgK2oZz2t_x"
      },
      "source": [
        "**Create Train and Validation Splits from the loaded full training data**\n",
        "\n",
        "We split 80% for training and 20% for validation.\n",
        "\n",
        "stratify=df['label'] ensures that the proportion of labels is maintained in both splits [1, 2]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_meZmtjt3uZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "752f523b-8e93-461d-e481-f83cfa138716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Splitting training data into train and validation sets...\n",
            "DistilBERT Train shape: (32925, 2), Validation shape: (8232, 2)\n",
            "BERTweet Train shape: (32925, 2), Validation shape: (8232, 2)\n"
          ]
        }
      ],
      "source": [
        "# --- Create Train and Validation Splits from the loaded full training data ---\n",
        "print(\"\\nSplitting training data into train and validation sets...\")\n",
        "\n",
        "# DistilBERT splits\n",
        "train_df_distilbert, val_df_distilbert = train_test_split(\n",
        "    df_distilbert_train, test_size=0.2, random_state=42, stratify=df_distilbert_train['label']\n",
        ")\n",
        "\n",
        "# BERTweet splits\n",
        "train_df_bertweet, val_df_bertweet = train_test_split(\n",
        "    df_bertweet_train, test_size=0.2, random_state=42, stratify=df_bertweet_train['label']\n",
        ")\n",
        "\n",
        "print(f\"DistilBERT Train shape: {train_df_distilbert.shape}, Validation shape: {val_df_distilbert.shape}\")\n",
        "print(f\"BERTweet Train shape: {train_df_bertweet.shape}, Validation shape: {val_df_bertweet.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLipQTgjPsw-"
      },
      "source": [
        "### Preprocessing and Tokenization\n",
        "\n",
        "We've converted text data into numerical token IDs for use with two distinct Transformer models: DistilBERT and BERTweet. This process included padding to ensure uniform sequence length and truncation to manage longer texts.\n",
        "\n",
        "*  **Max Sequence Length (MAX_SEQ_LENGTH):** To make our\n",
        "code more generic and data-driven, the MAX_SEQ_LENGTH is not hardcoded. Instead, it is dynamically determined by taking the 99th percentile of token lengths from a pre-calculated JSON file and adding a buffer of 5 tokens. This approach ensures that our maximum sequence length is always optimized for the specific data distribution, minimizing unnecessary padding and truncation without significant information loss.\n",
        "\n",
        "*   **Model-Specific Pipelines:** We developed separate preprocessing pipelines to match the unique characteristics of each model.\n",
        "\n",
        "  *   **DistilBERT:** As a general-purpose, uncased model, its pipeline normalizes tweet-specific elements. This includes replacing URLs with [URL] and user mentions with [USER], and splitting hashtags like #StayHome into Stay Home to improve the model's understanding of semantic content over tweet-specific syntax.\n",
        "\n",
        "  *   **BERTweet:** Pre-trained on a vast corpus of tweets, BERTweet is a cased model that natively understands tweet syntax. For this model, we preserved hashtags, mentions, and URLs as they are, as they contain valuable contextual information the model was specifically trained to interpret."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTE8EfvXG0B8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24616c77-b1da-4957-bfe8-bc2bd85a71a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBERT max_length from JSON (p99+5, ≤512): 106\n",
            "BERTweet   max_length from JSON (p99+5, ≤512): 93\n",
            "Using unified MAX_SEQ_LENGTH for tokenization: 106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokenizing DistilBERT data...\n",
            "Tokenizing BERTweet data...\n",
            "Tokenization complete for all datasets.\n"
          ]
        }
      ],
      "source": [
        "# --- Load max_length from JSON file (correct keys: \"distilbert\", \"bertweet\") ---\n",
        "try:\n",
        "    length_stats_path = f\"{BASE_DIR}/length_stats.json\"\n",
        "    with open(length_stats_path, \"r\") as f:\n",
        "        length_stats = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    print(\"Warning: 'length_stats.json' not found. Using safe defaults.\")\n",
        "    # Fallback with the CORRECT top-level keys used by Part A\n",
        "    length_stats = {\n",
        "        \"distilbert\": {\"overall\": {\"p99\": 96}},\n",
        "        \"bertweet\":   {\"overall\": {\"p99\": 96}},\n",
        "    }\n",
        "\n",
        "def _get_p99(stats: dict, model_key: str, default_p99: int = 96) -> int:\n",
        "    \"\"\"Read overall.p99 for a given model_key, with a safe default.\"\"\"\n",
        "    try:\n",
        "        return int(stats.get(model_key, {}).get(\"overall\", {}).get(\"p99\", default_p99))\n",
        "    except (TypeError, ValueError):\n",
        "        return default_p99\n",
        "\n",
        "# --- Determine max_length for each model based on the 99th percentile ---\n",
        "# Add a small buffer of 5 tokens; cap at 512\n",
        "distilbert_max_len_json = _get_p99(length_stats, \"distilbert\", 96) + 5\n",
        "bertweet_max_len_json   = _get_p99(length_stats, \"bertweet\",   96) + 5\n",
        "\n",
        "distilbert_max_len = min(distilbert_max_len_json, 512)\n",
        "bertweet_max_len   = min(bertweet_max_len_json,   512)\n",
        "\n",
        "# --- Define MAX_SEQ_LENGTH (keep single max for both models, as you wanted) ---\n",
        "MAX_SEQ_LENGTH = max(distilbert_max_len, bertweet_max_len)\n",
        "\n",
        "print(f\"DistilBERT max_length from JSON (p99+5, ≤512): {distilbert_max_len}\")\n",
        "print(f\"BERTweet   max_length from JSON (p99+5, ≤512): {bertweet_max_len}\")\n",
        "print(f\"Using unified MAX_SEQ_LENGTH for tokenization: {MAX_SEQ_LENGTH}\")\n",
        "\n",
        "# --- Tokenization ---\n",
        "distilbert_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "# NOTE: BERTweet tokenizer often requires use_fast=False depending on version.\n",
        "bertweet_tokenizer   = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)\n",
        "\n",
        "def tokenize_data(df, tokenizer, text_column, max_length):\n",
        "    return tokenizer(\n",
        "        df[text_column].tolist(),\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "print(\"\\nTokenizing DistilBERT data...\")\n",
        "distilbert_train_encodings = tokenize_data(train_df_distilbert, distilbert_tokenizer, \"covid_norm\", MAX_SEQ_LENGTH)\n",
        "val_distilbert_encodings   = tokenize_data(val_df_distilbert,   distilbert_tokenizer, \"covid_norm\", MAX_SEQ_LENGTH)\n",
        "distilbert_test_encodings  = tokenize_data(df_distilbert_test,  distilbert_tokenizer, \"covid_norm\", MAX_SEQ_LENGTH)\n",
        "\n",
        "print(\"Tokenizing BERTweet data...\")\n",
        "bertweet_train_encodings = tokenize_data(train_df_bertweet, bertweet_tokenizer, \"covid_norm\", MAX_SEQ_LENGTH)\n",
        "val_bertweet_encodings   = tokenize_data(val_df_bertweet,   bertweet_tokenizer, \"covid_norm\", MAX_SEQ_LENGTH)\n",
        "bertweet_test_encodings  = tokenize_data(df_bertweet_test,  bertweet_tokenizer, \"covid_norm\", MAX_SEQ_LENGTH)\n",
        "\n",
        "print(\"Tokenization complete for all datasets.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5Ueln0jPfL4"
      },
      "source": [
        "**Create Custom PyTorch Dataset Classes**\n",
        "\n",
        "To use the tokenized data with PyTorch's DataLoader and Hugging Face's Trainer, you'll need to create a custom Dataset class. This class will provide the tokenized inputs (input_ids, attention_mask) and the corresponding labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CE4u3zqwPc5K"
      },
      "outputs": [],
      "source": [
        "# --- Custom PyTorch Dataset ---\n",
        "class TweetSentimentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Return a dictionary of input_ids, attention_mask, and label\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ks4sdblwTAcK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "5b669123-86db-416e-f187-9a3557055db3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          covid_norm  label\n",
              "0     [USER] [USER] [USER] [URL] and [URL] and [URL]      1\n",
              "1  advice Talk to your neighbours family to excha...      2\n",
              "2  covid Australia: Woolworths to give elderly, d...      2\n",
              "3  My food stock is not the only one which is emp...      2\n",
              "4  Me, ready to go at supermarket during the covi...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50806266-a2d3-4dbc-b492-7f2801bc4226\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>covid_norm</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[USER] [USER] [USER] [URL] and [URL] and [URL]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>covid Australia: Woolworths to give elderly, d...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Me, ready to go at supermarket during the covi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50806266-a2d3-4dbc-b492-7f2801bc4226')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-50806266-a2d3-4dbc-b492-7f2801bc4226 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-50806266-a2d3-4dbc-b492-7f2801bc4226');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-38056f9c-e0aa-4c9f-a49e-102a7e67956e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38056f9c-e0aa-4c9f-a49e-102a7e67956e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-38056f9c-e0aa-4c9f-a49e-102a7e67956e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_distilbert_train",
              "summary": "{\n  \"name\": \"df_distilbert_train\",\n  \"rows\": 41157,\n  \"fields\": [\n    {\n      \"column\": \"covid_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 41095,\n        \"samples\": [\n          \"[USER] and [USER] nice to see a hike in the alcohol prices during this pandemic! Our usual bottle of white spiked by approx \\u00c3\\u0082\\u00c2\\u00a33 in a matter of days I sense some profiteering going on here! profiteering covid covid Disgusted\",\n          \"Visit our covid Consumer Resource Center for the latest updates on assistance that is available for residential consumers who are experiencing covid-related financial hardship for maintaining their electricity, water, and wastewater services: [URL] [URL]\",\n          \"The latest copy of our weekly consumer behaviour and attitude tracker has just been released. Download it now from: [URL] [URL]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df_distilbert_train.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instantiate Custom PyTorch Datasets**"
      ],
      "metadata": {
        "id": "SnuI3hOoEL8-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-z1a_AKYSmDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10d2dafb-a326-417a-dcb1-e216b6edc672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating custom PyTorch Dataset instances for all splits...\n",
            "Custom PyTorch Datasets created successfully.\n",
            "DistilBERT Train Dataset size: 32925\n",
            "DistilBERT Validation Dataset size: 8232\n",
            "DistilBERT Test Dataset size: 3798\n",
            "BERTweet Train Dataset size: 32925\n",
            "BERTweet Validation Dataset size: 8232\n",
            "BERTweet Test Dataset size: 3798\n"
          ]
        }
      ],
      "source": [
        "# --- Instantiate Custom PyTorch Datasets ---\n",
        "print(\"\\nCreating custom PyTorch Dataset instances for all splits...\")\n",
        "\n",
        "# DistilBERT datasets\n",
        "train_dataset_distilbert = TweetSentimentDataset(distilbert_train_encodings, train_df_distilbert['label'].tolist())\n",
        "val_dataset_distilbert = TweetSentimentDataset(val_distilbert_encodings, val_df_distilbert['label'].tolist())\n",
        "test_dataset_distilbert = TweetSentimentDataset(distilbert_test_encodings, df_distilbert_test['label'].tolist())\n",
        "\n",
        "# BERTweet datasets\n",
        "train_dataset_bertweet = TweetSentimentDataset(bertweet_train_encodings, train_df_bertweet['label'].tolist())\n",
        "val_dataset_bertweet = TweetSentimentDataset(val_bertweet_encodings, val_df_bertweet['label'].tolist())\n",
        "test_dataset_bertweet = TweetSentimentDataset(bertweet_test_encodings, df_bertweet_test['label'].tolist())\n",
        "\n",
        "print(\"Custom PyTorch Datasets created successfully.\")\n",
        "\n",
        "# Optional: Print sizes to verify\n",
        "print(f\"DistilBERT Train Dataset size: {len(train_dataset_distilbert)}\")\n",
        "print(f\"DistilBERT Validation Dataset size: {len(val_dataset_distilbert)}\")\n",
        "print(f\"DistilBERT Test Dataset size: {len(test_dataset_distilbert)}\")\n",
        "print(f\"BERTweet Train Dataset size: {len(train_dataset_bertweet)}\")\n",
        "print(f\"BERTweet Validation Dataset size: {len(val_dataset_bertweet)}\")\n",
        "print(f\"BERTweet Test Dataset size: {len(test_dataset_bertweet)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12h8K0Ym5qPk"
      },
      "source": [
        "**Create PyTorch s**\n",
        "\n",
        "We will now create PyTorch DataLoaders. DataLoaders are essential for:\n",
        "\n",
        "• **Batching:** Grouping individual data samples into mini-batches, which is necessary for efficient training on GPUs and stable gradient updates.\n",
        "\n",
        "• **Shuffling:** Randomizing the order of samples in each epoch (for training data) to prevent the model from learning the order of the data.\n",
        "\n",
        "• **Parallel Loading:** Loading data in parallel using multiple worker processes, which speeds up data fetching.\n",
        "\n",
        "We will create separate DataLoaders for training, validation, and test datasets for both DistilBERT and BERTweet. We will pay attention to shuffle=True for training data and shuffle=False for validation and test data.\n",
        "\n",
        "The batch_size is a hyperparameter we will likely tune later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-tbXG_L4lpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19f15142-fe7f-4c67-8a4c-28f0d904a2d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating PyTorch DataLoaders with batch_size: 32...\n",
            "DataLoaders created successfully.\n",
            "DistilBERT Train DataLoader batches: 1029\n",
            "DistilBERT Validation DataLoader batches: 258\n",
            "DistilBERT Test DataLoader batches: 119\n",
            "BERTweet Train DataLoader batches: 1029\n",
            "BERTweet Validation DataLoader batches: 258\n",
            "BERTweet Test DataLoader batches: 119\n"
          ]
        }
      ],
      "source": [
        "# A reasonable starting batch size. This is a hyperparameter often tuned later.\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "print(f\"\\nCreating PyTorch DataLoaders with batch_size: {BATCH_SIZE}...\")\n",
        "\n",
        "# DistilBERT DataLoaders\n",
        "train_loader_distilbert = DataLoader(train_dataset_distilbert, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader_distilbert = DataLoader(val_dataset_distilbert, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader_distilbert = DataLoader(test_dataset_distilbert, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# BERTweet DataLoaders\n",
        "train_loader_bertweet = DataLoader(train_dataset_bertweet, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader_bertweet = DataLoader(val_dataset_bertweet, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader_bertweet = DataLoader(test_dataset_bertweet, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(\"DataLoaders created successfully.\")\n",
        "\n",
        "# Optional: Print sizes to verify\n",
        "print(f\"DistilBERT Train DataLoader batches: {len(train_loader_distilbert)}\")\n",
        "print(f\"DistilBERT Validation DataLoader batches: {len(val_loader_distilbert)}\")\n",
        "print(f\"DistilBERT Test DataLoader batches: {len(test_loader_distilbert)}\")\n",
        "print(f\"BERTweet Train DataLoader batches: {len(train_loader_bertweet)}\")\n",
        "print(f\"BERTweet Validation DataLoader batches: {len(val_loader_bertweet)}\")\n",
        "print(f\"BERTweet Test DataLoader batches: {len(test_loader_bertweet)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK0mbALG6Xb_"
      },
      "source": [
        "**Load Pre-trained Models**\n",
        "\n",
        "We will need to load the pre-trained Transformer models (DistilBertForSequenceClassification and RobertaForSequenceClassification for BERTweet, as BERTweet is a RoBERTa-style model) that we intend to fine-tune.\n",
        "\n",
        "These models are designed for sequence classification tasks and will be initialized with pre-trained weights, except for the newly added classification head, which will be randomly initialized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMDVxNFo6ME9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80d84731-7e23-4557-d7a1-17fb3f1ab05a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading pre-trained DistilBERT and BERTweet models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models loaded successfully.\n",
            "DistilBERT model structure (first few layers):\n",
            "DistilBertForSequenceClassification(\n",
            "  (distilbert): DistilBertModel(\n",
            "    (embeddings): Embeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): Transformer(\n",
            "      (layer): ModuleList(\n",
            "        (0-5): 6 x TransformerBlock(\n",
            "          (attention): DistilBertSdpaAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (activation): GELUActivation()\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n",
            "\n",
            "BERTweet model structure (first few layers):\n",
            "RobertaForSequenceClassification(\n",
            "  (roberta): RobertaModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
            "      (position_embeddings): Embedding(130, 768, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSdpaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (classifier): RobertaClassificationHead(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "print(\"\\nLoading pre-trained DistilBERT and BERTweet models...\")\n",
        "\n",
        "# Number of labels for sentiment classification task (negative, neutral, positive)\n",
        "NUM_LABELS = 3\n",
        "\n",
        "# Load DistilBERT model\n",
        "distilbert_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\",\n",
        "    num_labels=NUM_LABELS\n",
        ").to(device) # Move model to GPU/CPU [11]\n",
        "\n",
        "# Load BERTweet model\n",
        "# BERTweet is a RoBERTa-style model, so you load RobertaForSequenceClassification [7, 8]\n",
        "bertweet_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"vinai/bertweet-base\",\n",
        "    num_labels=NUM_LABELS\n",
        ").to(device) # Move model to GPU/CPU [11]\n",
        "\n",
        "print(\"Models loaded successfully.\")\n",
        "print(\"DistilBERT model structure (first few layers):\")\n",
        "print(distilbert_model)\n",
        "print(\"\\nBERTweet model structure (first few layers):\")\n",
        "print(bertweet_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKo-FO9LIXmY"
      },
      "source": [
        "define the early_stop_check function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcGsJ1ALHuDp"
      },
      "outputs": [],
      "source": [
        "# Helper function for early stopping logic [6]\n",
        "def early_stop_check(patience, best_val_accuracy, best_val_accuracy_epoch, current_val_accuracy, current_val_accuracy_epoch):\n",
        "    early_stop_flag = False\n",
        "    if current_val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = current_val_accuracy\n",
        "        best_val_accuracy_epoch = current_val_accuracy_epoch\n",
        "    else:\n",
        "        # Check if the current epoch is beyond the patience window relative to the best epoch\n",
        "        if current_val_accuracy_epoch - best_val_accuracy_epoch > patience:\n",
        "            early_stop_flag = True\n",
        "    return best_val_accuracy, best_val_accuracy_epoch, early_stop_flag\n",
        "\n",
        "print(\"\\nEarly stopping utility function defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Function"
      ],
      "metadata": {
        "id": "9CNmcqW9tTAK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and validation loop that:  \n",
        "- Trains the model over 10 epochs, computing loss and accuracy each step.  \n",
        "- Evaluates on the validation set each epoch and calculates additional metrics (precision, recall, F1).  \n",
        "- Tracks the best validation accuracy, saves the best model state, and supports early stopping with a patience parameter.  \n",
        "- Integrates with Optuna trials (saving per-trial best models) and Weights & Biases for experiment logging.  \n",
        "\n"
      ],
      "metadata": {
        "id": "GR7LIjzWEddF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8lrmrWmIaA0",
        "outputId": "b3cfe1ee-b5f2-4afc-f610-fd142c00a9d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training and evaluation loop function 'train_model_with_hyperparams' defined.\n"
          ]
        }
      ],
      "source": [
        "# Main training and validation loop function [2]\n",
        "def train_model_with_hyperparams(model, train_loader, val_loader, optimizer, criterion, epochs, patience, trial):\n",
        "    # Initialize variables for tracking best performance and early stopping [2]\n",
        "    best_val_accuracy = 0.0\n",
        "    best_val_accuracy_epoch = 0\n",
        "    early_stop_flag = False\n",
        "    best_model_state = None # To save the state dict of the best performing model [8]\n",
        "\n",
        "    print(f\"\\nStarting training for trial {trial.number if trial else 'N/A'} for {epochs} epochs with patience {patience}...\")\n",
        "\n",
        "    # Loop through each epoch [2]\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        # --- Training loop ---\n",
        "        model.train() # Set model to training mode [2]\n",
        "        train_loss = 0.0\n",
        "        total_train_samples = 0\n",
        "        correct_train_predictions = 0\n",
        "\n",
        "        # Iterate over batches from the training DataLoader [2]\n",
        "        for batch in train_loader:\n",
        "            # Move input tensors to the specified device (GPU/CPU) [2]\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            optimizer.zero_grad() # Clear previously computed gradients [9]\n",
        "            outputs = model(input_ids, attention_mask=attention_mask) # Perform forward pass [9]\n",
        "            logits = outputs.logits # Get the raw output logits from the model [9]\n",
        "            loss = criterion(logits, labels) # Calculate the loss using the defined criterion [9]\n",
        "\n",
        "            loss.backward() # Perform backward pass to compute gradients [9]\n",
        "            optimizer.step() # Update model weights using the optimizer [9]\n",
        "\n",
        "            # Accumulate training loss and correct predictions [9]\n",
        "            train_loss += loss.item() * input_ids.size(0)\n",
        "            total_train_samples += input_ids.size(0)\n",
        "            correct_train_predictions += (logits.argmax(dim=1) == labels).sum().item()\n",
        "\n",
        "        train_loss /= total_train_samples\n",
        "        train_accuracy = correct_train_predictions / total_train_samples\n",
        "\n",
        "        # --- Validation loop ---\n",
        "        model.eval() # Set model to evaluation mode [10]\n",
        "        val_loss = 0.0\n",
        "        total_val_samples = 0\n",
        "        correct_val_predictions = 0\n",
        "        all_val_labels = [] # To store all true labels for metric calculation [10]\n",
        "        all_val_preds = [] # To store all predicted labels for metric calculation [10]\n",
        "\n",
        "        with torch.no_grad(): # Disable gradient computation for validation [10]\n",
        "            for batch in val_loader:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['labels'].to(device) # [11]\n",
        "\n",
        "                outputs = model(input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs.logits\n",
        "                loss = criterion(logits, labels)\n",
        "\n",
        "                val_loss += loss.item() * input_ids.size(0)\n",
        "                total_val_samples += input_ids.size(0)\n",
        "                correct_val_predictions += (logits.argmax(dim=1) == labels).sum().item()\n",
        "\n",
        "                all_val_labels.extend(labels.cpu().numpy())\n",
        "                all_val_preds.extend(logits.argmax(dim=1).cpu().numpy())\n",
        "\n",
        "        val_loss /= total_val_samples\n",
        "        val_accuracy = correct_val_predictions / total_val_samples\n",
        "\n",
        "        # For our 3-class sentiment analysis, we might need to adjust 'average' or calculate macro/weighted F1\n",
        "        # from sklearn.metrics import precision_score, recall_score, f1_score # These imports are usually at the top\n",
        "        try: # Use a try-except block to handle cases where precision/recall/f1 might fail for specific label distributions\n",
        "            # For multi-class classification, 'average' parameter is crucial. 'None' returns scores per class.\n",
        "            # 'macro' computes metrics independently for each class and then takes the unweighted mean.\n",
        "            # 'weighted' computes metrics for each class and then takes the mean weighted by support.\n",
        "            # Given your three classes (negative, neutral, positive), 'weighted' or 'macro' are common.\n",
        "            val_precision = precision_score(all_val_labels, all_val_preds, average='weighted', zero_division=0)\n",
        "            val_recall = recall_score(all_val_labels, all_val_preds, average='weighted', zero_division=0)\n",
        "            val_f1 = f1_score(all_val_labels, all_val_preds, average='weighted', zero_division=0)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not compute advanced metrics for epoch {epoch}: {e}\")\n",
        "            val_precision, val_recall, val_f1 = np.nan, np.nan, np.nan\n",
        "\n",
        "\n",
        "        # Check for early stopping and update best model state [7, 8]\n",
        "        best_val_accuracy, best_val_accuracy_epoch, early_stop_flag = early_stop_check(\n",
        "            patience, best_val_accuracy, best_val_accuracy_epoch, val_accuracy, epoch\n",
        "        )\n",
        "\n",
        "        if val_accuracy >= best_val_accuracy: # Save the model state if current accuracy is the best or equal [8]\n",
        "            # Use deepcopy if you plan to modify the model after saving, otherwise state_dict() is fine\n",
        "            best_model_state = model.state_dict()\n",
        "            if trial: # Only save if part of an Optuna trial [3]\n",
        "                torch.save(best_model_state, f\"best_model_trial_{trial.number}.pt\") # Save as .pt file [3]\n",
        "\n",
        "        # Log metrics to Weights & Biases for the current epoch [8]\n",
        "        if wandb.run: # Only log if wandb is initialized\n",
        "            wandb.log({\n",
        "                \"Epoch\": epoch,\n",
        "                \"Train Loss\": train_loss,\n",
        "                \"Train Accuracy\": train_accuracy,\n",
        "                \"Validation Loss\": val_loss,\n",
        "                \"Validation Accuracy\": val_accuracy,\n",
        "                \"Validation Precision\": val_precision,\n",
        "                \"Validation Recall\": val_recall,\n",
        "                \"Validation F1\": val_f1\n",
        "            })\n",
        "\n",
        "        print(f\"Epoch {epoch}/{epochs} | Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f} | \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, Val F1: {val_f1:.4f}\")\n",
        "\n",
        "        if early_stop_flag: # Exit training loop if early stopping condition is met [3]\n",
        "            print(f\"Early stopping triggered at epoch {epoch}.\")\n",
        "            break\n",
        "\n",
        "    # Load the best model state back into the model if it was saved [3]\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "\n",
        "    print(f\"Training complete. Best Validation Accuracy: {best_val_accuracy:.4f} at epoch {best_val_accuracy_epoch}.\")\n",
        "    return best_val_accuracy # Return the best validation accuracy (for Optuna maximization) [3]\n",
        "\n",
        "print(\"\\nTraining and evaluation loop function 'train_model_with_hyperparams' defined.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_rr2NDzSXLu"
      },
      "source": [
        "#### Hyperparameter Search Space (Optuna)\n",
        "\n",
        "We use `log=True` when sampling learning rate and weight decay.  \n",
        "This makes Optuna draw values on a logarithmic scale, which is more appropriate for parameters that span several orders of magnitude.  \n",
        "- `learning_rate ∈ [1e-5, 1e-3]` (log scale)  \n",
        "- `weight_decay ∈ [1e-6, 1e-4]` (log scale)  \n",
        "Other parameters (`patience`, `num_layers`, `batch_size`) are searched on linear or categorical spaces.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHhLyev_kHNC"
      },
      "source": [
        "**Handling Class Imbalance**\n",
        "\n",
        "e implemented a class-weighted loss function within the Optuna function to handle the imbalanced sentiment labels identified in Part A. This technique assigns a higher penalty to misclassifications of under-represented classes, forcing the model to pay more attention to them during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOH-H8iIsT5P"
      },
      "source": [
        "## BERTweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXNgodWSI5d3"
      },
      "outputs": [],
      "source": [
        "# Define the objective function for Optuna\n",
        "def objective(trial):\n",
        "\n",
        "    # Hyperparameter suggestions for tuning\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True)\n",
        "    weight_decay  = trial.suggest_float(\"weight_decay\", 1e-6, 1e-4, log=True)\n",
        "    patience      = trial.suggest_int(\"patience\",6 ,7)\n",
        "    batch_size    = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
        "    num_layers    = trial.suggest_int(\"num_layers\", 1, 3)\n",
        "\n",
        "    # Datasets / loaders (uses your existing encodings & splits)\n",
        "    train_dataset = TweetSentimentDataset(bertweet_train_encodings, train_df_bertweet['label'].tolist())\n",
        "    val_dataset   = TweetSentimentDataset(val_bertweet_encodings,   val_df_bertweet['label'].tolist())\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Model\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        'vinai/bertweet-base', num_labels=3\n",
        "    ).to(device)\n",
        "\n",
        "    # Freeze base; unfreeze last `num_layers` + classifier\n",
        "    for p in model.roberta.parameters():\n",
        "        p.requires_grad = False\n",
        "    for p in model.roberta.encoder.layer[-num_layers:].parameters():\n",
        "        p.requires_grad = True\n",
        "    for p in model.classifier.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "    # ---------- imbalance handling: weighted loss ----------\n",
        "    classes = np.array([0, 1, 2], dtype=int)\n",
        "    y_train = np.array(train_df_bertweet['label'].tolist(), dtype=int)\n",
        "    weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
        "    class_weights = torch.tensor(weights, dtype=torch.float, device=device)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "    # -------------------------------------------------------\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # W&B\n",
        "    wandb.init(\n",
        "        project=\"tweet-sentiment-finetuning\",\n",
        "        config={\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"weight_decay\": weight_decay,\n",
        "            \"patience\": patience,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"num_layers\": num_layers,\n",
        "            \"architecture\": \"BERTweet (RoBERTa-style)\",\n",
        "            \"dataset\": \"COVID-19-tweets-standardized\"\n",
        "        },\n",
        "        name=f\"trial_{trial.number}\",\n",
        "        reinit=True\n",
        "    )\n",
        "\n",
        "    # Train/eval loop (your function)\n",
        "    best_val_accuracy = train_model_with_hyperparams(\n",
        "        model, train_loader, val_loader, optimizer, criterion,\n",
        "        epochs=10, patience=patience, trial=trial\n",
        "    )\n",
        "\n",
        "    wandb.finish()\n",
        "    return best_val_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jJ3ffOiSJ7FN",
        "outputId": "cd3a6749-db19-4a43-abdc-ce62b10b9c26"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-17 21:21:29,154] A new study created in memory with name: no-name-06b2d4ed-b0cd-4d38-9492-73a192dd9bef\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnogapaz98\u001b[0m (\u001b[33mnogapaz98-tel-aviv-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250817_212131-u8jwm9a1</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/u8jwm9a1' target=\"_blank\">trial_0</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/u8jwm9a1' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/u8jwm9a1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 0 for 10 epochs with patience 6...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.7480, Train Acc: 0.6763 | Val Loss: 0.6145, Val Acc: 0.7702, Val F1: 0.7709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.5464, Train Acc: 0.7939 | Val Loss: 0.5592, Val Acc: 0.7907, Val F1: 0.7901\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.4646, Train Acc: 0.8316 | Val Loss: 0.5085, Val Acc: 0.8290, Val F1: 0.8287\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.3930, Train Acc: 0.8593 | Val Loss: 0.5068, Val Acc: 0.8293, Val F1: 0.8306\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.3391, Train Acc: 0.8838 | Val Loss: 0.5247, Val Acc: 0.8431, Val F1: 0.8427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.2965, Train Acc: 0.9021 | Val Loss: 0.4915, Val Acc: 0.8439, Val F1: 0.8437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.2625, Train Acc: 0.9132 | Val Loss: 0.5039, Val Acc: 0.8394, Val F1: 0.8388\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.2468, Train Acc: 0.9175 | Val Loss: 0.5492, Val Acc: 0.8236, Val F1: 0.8242\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.2256, Train Acc: 0.9259 | Val Loss: 0.5648, Val Acc: 0.8197, Val F1: 0.8188\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.1915, Train Acc: 0.9351 | Val Loss: 0.6421, Val Acc: 0.8437, Val F1: 0.8428\n",
            "Training complete. Best Validation Accuracy: 0.8439 at epoch 6.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▅▄▄▃▂▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▇▇███▆▆█</td></tr><tr><td>Validation F1</td><td>▁▃▇▇███▆▆█</td></tr><tr><td>Validation Loss</td><td>▇▄▂▂▃▁▂▄▄█</td></tr><tr><td>Validation Precision</td><td>▁▄▇▇███▆▆█</td></tr><tr><td>Validation Recall</td><td>▁▃▇▇███▆▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.93509</td></tr><tr><td>Train Loss</td><td>0.19147</td></tr><tr><td>Validation Accuracy</td><td>0.84366</td></tr><tr><td>Validation F1</td><td>0.84283</td></tr><tr><td>Validation Loss</td><td>0.6421</td></tr><tr><td>Validation Precision</td><td>0.84424</td></tr><tr><td>Validation Recall</td><td>0.84366</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/u8jwm9a1' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/u8jwm9a1</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250817_212131-u8jwm9a1/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-17 22:08:48,648] Trial 0 finished with value: 0.8439018464528668 and parameters: {'learning_rate': 0.0005067099595408021, 'weight_decay': 4.382250702866951e-05, 'patience': 6, 'batch_size': 128, 'num_layers': 3}. Best is trial 0 with value: 0.8439018464528668.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250817_220849-4h3nndx4</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/4h3nndx4' target=\"_blank\">trial_1</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/4h3nndx4' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/4h3nndx4</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 1 for 10 epochs with patience 6...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.7181, Train Acc: 0.6967 | Val Loss: 0.5897, Val Acc: 0.7760, Val F1: 0.7770\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.5375, Train Acc: 0.7910 | Val Loss: 0.5960, Val Acc: 0.7947, Val F1: 0.7945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.4540, Train Acc: 0.8297 | Val Loss: 0.5182, Val Acc: 0.8056, Val F1: 0.8078\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.3886, Train Acc: 0.8587 | Val Loss: 0.5012, Val Acc: 0.8192, Val F1: 0.8204\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.3272, Train Acc: 0.8806 | Val Loss: 0.5593, Val Acc: 0.8293, Val F1: 0.8293\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.2819, Train Acc: 0.8996 | Val Loss: 0.5515, Val Acc: 0.8310, Val F1: 0.8311\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.2387, Train Acc: 0.9126 | Val Loss: 0.6613, Val Acc: 0.8310, Val F1: 0.8307\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.1994, Train Acc: 0.9292 | Val Loss: 0.6694, Val Acc: 0.8140, Val F1: 0.8149\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.1665, Train Acc: 0.9400 | Val Loss: 0.7870, Val Acc: 0.8279, Val F1: 0.8272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.1348, Train Acc: 0.9524 | Val Loss: 0.6918, Val Acc: 0.8310, Val F1: 0.8312\n",
            "Training complete. Best Validation Accuracy: 0.8310 at epoch 6.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▅▆▇▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▅▇███▆██</td></tr><tr><td>Validation F1</td><td>▁▃▅▇███▆▇█</td></tr><tr><td>Validation Loss</td><td>▃▃▁▁▂▂▅▅█▆</td></tr><tr><td>Validation Precision</td><td>▁▅▆▇███▇▇█</td></tr><tr><td>Validation Recall</td><td>▁▃▅▇███▆██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.95244</td></tr><tr><td>Train Loss</td><td>0.13484</td></tr><tr><td>Validation Accuracy</td><td>0.83103</td></tr><tr><td>Validation F1</td><td>0.83119</td></tr><tr><td>Validation Loss</td><td>0.69175</td></tr><tr><td>Validation Precision</td><td>0.83158</td></tr><tr><td>Validation Recall</td><td>0.83103</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_1</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/4h3nndx4' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/4h3nndx4</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250817_220849-4h3nndx4/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-17 22:58:25,777] Trial 1 finished with value: 0.831025267249757 and parameters: {'learning_rate': 9.099659928275238e-05, 'weight_decay': 2.7953261830148993e-06, 'patience': 6, 'batch_size': 64, 'num_layers': 3}. Best is trial 0 with value: 0.8439018464528668.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250817_225827-9z09i7bz</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/9z09i7bz' target=\"_blank\">trial_2</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/9z09i7bz' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/9z09i7bz</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 2 for 10 epochs with patience 6...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.7858, Train Acc: 0.6548 | Val Loss: 0.6590, Val Acc: 0.7457, Val F1: 0.7472\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.6114, Train Acc: 0.7559 | Val Loss: 0.6024, Val Acc: 0.7594, Val F1: 0.7596\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.5384, Train Acc: 0.7937 | Val Loss: 0.5864, Val Acc: 0.7724, Val F1: 0.7726\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.4840, Train Acc: 0.8160 | Val Loss: 0.5554, Val Acc: 0.8015, Val F1: 0.8021\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.4352, Train Acc: 0.8344 | Val Loss: 0.5884, Val Acc: 0.8015, Val F1: 0.8005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.3902, Train Acc: 0.8538 | Val Loss: 0.5406, Val Acc: 0.8173, Val F1: 0.8176\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.3489, Train Acc: 0.8706 | Val Loss: 0.5771, Val Acc: 0.8139, Val F1: 0.8134\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.3048, Train Acc: 0.8863 | Val Loss: 0.5907, Val Acc: 0.8128, Val F1: 0.8138\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.2713, Train Acc: 0.9000 | Val Loss: 0.6192, Val Acc: 0.8120, Val F1: 0.8130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.2415, Train Acc: 0.9107 | Val Loss: 0.6776, Val Acc: 0.8198, Val F1: 0.8194\n",
            "Training complete. Best Validation Accuracy: 0.8198 at epoch 10.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▅▆▆▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▂▄▆▆█▇▇▇█</td></tr><tr><td>Validation F1</td><td>▁▂▃▆▆█▇▇▇█</td></tr><tr><td>Validation Loss</td><td>▇▄▃▂▃▁▃▄▅█</td></tr><tr><td>Validation Precision</td><td>▁▄▆▆▇█████</td></tr><tr><td>Validation Recall</td><td>▁▂▄▆▆█▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.91074</td></tr><tr><td>Train Loss</td><td>0.24146</td></tr><tr><td>Validation Accuracy</td><td>0.81985</td></tr><tr><td>Validation F1</td><td>0.81943</td></tr><tr><td>Validation Loss</td><td>0.67764</td></tr><tr><td>Validation Precision</td><td>0.81922</td></tr><tr><td>Validation Recall</td><td>0.81985</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_2</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/9z09i7bz' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/9z09i7bz</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250817_225827-9z09i7bz/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-17 23:48:44,203] Trial 2 finished with value: 0.8198493683187561 and parameters: {'learning_rate': 3.0049509402547545e-05, 'weight_decay': 1.4035442108174199e-06, 'patience': 6, 'batch_size': 64, 'num_layers': 3}. Best is trial 0 with value: 0.8439018464528668.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250817_234845-7mbcopte</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/7mbcopte' target=\"_blank\">trial_3</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/7mbcopte' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/7mbcopte</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 3 for 10 epochs with patience 7...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.7353, Train Acc: 0.6886 | Val Loss: 0.6460, Val Acc: 0.7471, Val F1: 0.7476\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.5755, Train Acc: 0.7738 | Val Loss: 0.5773, Val Acc: 0.7932, Val F1: 0.7938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.4969, Train Acc: 0.8120 | Val Loss: 0.5742, Val Acc: 0.7980, Val F1: 0.7973\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.4308, Train Acc: 0.8418 | Val Loss: 0.5313, Val Acc: 0.8031, Val F1: 0.8048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.3706, Train Acc: 0.8653 | Val Loss: 0.5738, Val Acc: 0.8062, Val F1: 0.8070\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.3152, Train Acc: 0.8859 | Val Loss: 0.5820, Val Acc: 0.8222, Val F1: 0.8221\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.2692, Train Acc: 0.9033 | Val Loss: 0.5891, Val Acc: 0.8121, Val F1: 0.8143\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.2302, Train Acc: 0.9193 | Val Loss: 0.5988, Val Acc: 0.8000, Val F1: 0.8049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.1962, Train Acc: 0.9318 | Val Loss: 0.6524, Val Acc: 0.8024, Val F1: 0.8041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.1669, Train Acc: 0.9405 | Val Loss: 0.6646, Val Acc: 0.8186, Val F1: 0.8193\n",
            "Training complete. Best Validation Accuracy: 0.8222 at epoch 6.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▆▆▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▅▄▄▃▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▆▇█▇▆▆█</td></tr><tr><td>Validation F1</td><td>▁▅▆▆▇█▇▆▆█</td></tr><tr><td>Validation Loss</td><td>▇▃▃▁▃▄▄▅▇█</td></tr><tr><td>Validation Precision</td><td>▁▄▅▆▇█▇▇▆▇</td></tr><tr><td>Validation Recall</td><td>▁▅▆▆▇█▇▆▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.94047</td></tr><tr><td>Train Loss</td><td>0.16692</td></tr><tr><td>Validation Accuracy</td><td>0.81863</td></tr><tr><td>Validation F1</td><td>0.81929</td></tr><tr><td>Validation Loss</td><td>0.6646</td></tr><tr><td>Validation Precision</td><td>0.82093</td></tr><tr><td>Validation Recall</td><td>0.81863</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_3</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/7mbcopte' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/7mbcopte</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250817_234845-7mbcopte/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 00:33:34,822] Trial 3 finished with value: 0.8221574344023324 and parameters: {'learning_rate': 0.00013709512423518383, 'weight_decay': 4.637652847378576e-06, 'patience': 7, 'batch_size': 32, 'num_layers': 2}. Best is trial 0 with value: 0.8439018464528668.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_003336-mx95uev3</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/mx95uev3' target=\"_blank\">trial_4</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/mx95uev3' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/mx95uev3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 4 for 10 epochs with patience 7...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.7098, Train Acc: 0.7035 | Val Loss: 0.5949, Val Acc: 0.7821, Val F1: 0.7818\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.5371, Train Acc: 0.7959 | Val Loss: 0.5615, Val Acc: 0.7919, Val F1: 0.7926\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.4567, Train Acc: 0.8292 | Val Loss: 0.5135, Val Acc: 0.8211, Val F1: 0.8207\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.3906, Train Acc: 0.8571 | Val Loss: 0.5103, Val Acc: 0.8158, Val F1: 0.8162\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.3311, Train Acc: 0.8812 | Val Loss: 0.5185, Val Acc: 0.8192, Val F1: 0.8203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.2853, Train Acc: 0.8979 | Val Loss: 0.5926, Val Acc: 0.8218, Val F1: 0.8222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.2459, Train Acc: 0.9137 | Val Loss: 0.6080, Val Acc: 0.8207, Val F1: 0.8219\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.2087, Train Acc: 0.9267 | Val Loss: 0.6627, Val Acc: 0.8349, Val F1: 0.8345\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.1735, Train Acc: 0.9378 | Val Loss: 0.6708, Val Acc: 0.8308, Val F1: 0.8309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.1411, Train Acc: 0.9495 | Val Loss: 0.6648, Val Acc: 0.8228, Val F1: 0.8240\n",
            "Training complete. Best Validation Accuracy: 0.8349 at epoch 8.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▅▆▇▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▂▆▅▆▆▆█▇▆</td></tr><tr><td>Validation F1</td><td>▁▂▆▆▆▆▆██▇</td></tr><tr><td>Validation Loss</td><td>▅▃▁▁▁▅▅███</td></tr><tr><td>Validation Precision</td><td>▁▄▆▇▇▇▇██▇</td></tr><tr><td>Validation Recall</td><td>▁▂▆▅▆▆▆█▇▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.94949</td></tr><tr><td>Train Loss</td><td>0.14111</td></tr><tr><td>Validation Accuracy</td><td>0.82276</td></tr><tr><td>Validation F1</td><td>0.82395</td></tr><tr><td>Validation Loss</td><td>0.66485</td></tr><tr><td>Validation Precision</td><td>0.82934</td></tr><tr><td>Validation Recall</td><td>0.82276</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_4</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/mx95uev3' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/mx95uev3</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_003336-mx95uev3/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 01:23:57,014] Trial 4 finished with value: 0.8349125364431487 and parameters: {'learning_rate': 6.416833262371767e-05, 'weight_decay': 1.1950671454056966e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 3}. Best is trial 0 with value: 0.8439018464528668.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_012358-y2lfi8ro</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/y2lfi8ro' target=\"_blank\">trial_5</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/y2lfi8ro' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/y2lfi8ro</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 5 for 10 epochs with patience 6...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.9598, Train Acc: 0.5427 | Val Loss: 0.8214, Val Acc: 0.6586, Val F1: 0.6599\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.7856, Train Acc: 0.6744 | Val Loss: 0.7497, Val Acc: 0.7136, Val F1: 0.7162\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.6968, Train Acc: 0.7206 | Val Loss: 0.6921, Val Acc: 0.7335, Val F1: 0.7355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.6562, Train Acc: 0.7398 | Val Loss: 0.6875, Val Acc: 0.7539, Val F1: 0.7478\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.6152, Train Acc: 0.7576 | Val Loss: 0.6317, Val Acc: 0.7606, Val F1: 0.7626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.5936, Train Acc: 0.7665 | Val Loss: 0.6679, Val Acc: 0.7546, Val F1: 0.7549\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.5755, Train Acc: 0.7778 | Val Loss: 0.6285, Val Acc: 0.7697, Val F1: 0.7682\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.5575, Train Acc: 0.7859 | Val Loss: 0.5945, Val Acc: 0.7720, Val F1: 0.7741\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.5456, Train Acc: 0.7891 | Val Loss: 0.6077, Val Acc: 0.7792, Val F1: 0.7790\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.5288, Train Acc: 0.7999 | Val Loss: 0.5955, Val Acc: 0.7666, Val F1: 0.7694\n",
            "Training complete. Best Validation Accuracy: 0.7792 at epoch 9.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▆▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▅▇▇▇▇██▇</td></tr><tr><td>Validation F1</td><td>▁▄▅▆▇▇▇██▇</td></tr><tr><td>Validation Loss</td><td>█▆▄▄▂▃▂▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▄▆▆▇▆▇███</td></tr><tr><td>Validation Recall</td><td>▁▄▅▇▇▇▇██▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.79991</td></tr><tr><td>Train Loss</td><td>0.52878</td></tr><tr><td>Validation Accuracy</td><td>0.76664</td></tr><tr><td>Validation F1</td><td>0.76938</td></tr><tr><td>Validation Loss</td><td>0.59546</td></tr><tr><td>Validation Precision</td><td>0.78366</td></tr><tr><td>Validation Recall</td><td>0.76664</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_5</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/y2lfi8ro' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/y2lfi8ro</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_012358-y2lfi8ro/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 02:14:31,238] Trial 5 finished with value: 0.7791545189504373 and parameters: {'learning_rate': 0.0004976043155941766, 'weight_decay': 1.3180146810801098e-05, 'patience': 6, 'batch_size': 32, 'num_layers': 3}. Best is trial 0 with value: 0.8439018464528668.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_021432-prjm0cn1</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/prjm0cn1' target=\"_blank\">trial_6</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/prjm0cn1' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/prjm0cn1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 6 for 10 epochs with patience 7...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.8168, Train Acc: 0.6332 | Val Loss: 0.6935, Val Acc: 0.7267, Val F1: 0.7271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.6726, Train Acc: 0.7209 | Val Loss: 0.6341, Val Acc: 0.7484, Val F1: 0.7490\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.6193, Train Acc: 0.7463 | Val Loss: 0.6127, Val Acc: 0.7670, Val F1: 0.7681\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.5759, Train Acc: 0.7677 | Val Loss: 0.6013, Val Acc: 0.7609, Val F1: 0.7630\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.5327, Train Acc: 0.7856 | Val Loss: 0.5931, Val Acc: 0.7751, Val F1: 0.7775\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.4781, Train Acc: 0.8101 | Val Loss: 0.6220, Val Acc: 0.7768, Val F1: 0.7770\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.4140, Train Acc: 0.8347 | Val Loss: 0.6610, Val Acc: 0.7788, Val F1: 0.7785\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.3519, Train Acc: 0.8595 | Val Loss: 0.7324, Val Acc: 0.7708, Val F1: 0.7706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.2997, Train Acc: 0.8799 | Val Loss: 0.7669, Val Acc: 0.7691, Val F1: 0.7700\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.2501, Train Acc: 0.9007 | Val Loss: 0.8358, Val Acc: 0.7767, Val F1: 0.7764\n",
            "Training complete. Best Validation Accuracy: 0.7788 at epoch 7.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▅▆▆▇▇█</td></tr><tr><td>Train Loss</td><td>█▆▆▅▄▄▃▂▂▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▆▆███▇▇█</td></tr><tr><td>Validation F1</td><td>▁▄▇▆███▇▇█</td></tr><tr><td>Validation Loss</td><td>▄▂▂▁▁▂▃▅▆█</td></tr><tr><td>Validation Precision</td><td>▁▄▆▇█▇▇▆▇▇</td></tr><tr><td>Validation Recall</td><td>▁▄▆▆███▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.90074</td></tr><tr><td>Train Loss</td><td>0.25011</td></tr><tr><td>Validation Accuracy</td><td>0.77672</td></tr><tr><td>Validation F1</td><td>0.77643</td></tr><tr><td>Validation Loss</td><td>0.83584</td></tr><tr><td>Validation Precision</td><td>0.77638</td></tr><tr><td>Validation Recall</td><td>0.77672</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_6</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/prjm0cn1' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/prjm0cn1</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_021432-prjm0cn1/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 02:54:55,475] Trial 6 finished with value: 0.7787900874635568 and parameters: {'learning_rate': 0.00015189462596156502, 'weight_decay': 1.5405250215890978e-05, 'patience': 7, 'batch_size': 64, 'num_layers': 1}. Best is trial 0 with value: 0.8439018464528668.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_025456-8d7brrq4</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/8d7brrq4' target=\"_blank\">trial_7</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/8d7brrq4' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/8d7brrq4</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 7 for 10 epochs with patience 6...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.7330, Train Acc: 0.6888 | Val Loss: 0.6213, Val Acc: 0.7479, Val F1: 0.7519\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.5732, Train Acc: 0.7754 | Val Loss: 0.5804, Val Acc: 0.7920, Val F1: 0.7926\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.4924, Train Acc: 0.8139 | Val Loss: 0.5968, Val Acc: 0.7949, Val F1: 0.7942\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.4259, Train Acc: 0.8405 | Val Loss: 0.5515, Val Acc: 0.8086, Val F1: 0.8095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.3741, Train Acc: 0.8650 | Val Loss: 0.6046, Val Acc: 0.8044, Val F1: 0.8039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.3232, Train Acc: 0.8867 | Val Loss: 0.5601, Val Acc: 0.8134, Val F1: 0.8124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.2725, Train Acc: 0.9035 | Val Loss: 0.5687, Val Acc: 0.8168, Val F1: 0.8170\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.2378, Train Acc: 0.9153 | Val Loss: 0.6232, Val Acc: 0.8145, Val F1: 0.8159\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.2017, Train Acc: 0.9301 | Val Loss: 0.6712, Val Acc: 0.8166, Val F1: 0.8176\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.1731, Train Acc: 0.9381 | Val Loss: 0.7078, Val Acc: 0.8207, Val F1: 0.8200\n",
            "Training complete. Best Validation Accuracy: 0.8207 at epoch 10.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▅▅▆▇▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▅▄▄▃▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▇▆▇█▇██</td></tr><tr><td>Validation F1</td><td>▁▅▅▇▆▇████</td></tr><tr><td>Validation Loss</td><td>▄▂▃▁▃▁▂▄▆█</td></tr><tr><td>Validation Precision</td><td>▁▅▅▇▇▇████</td></tr><tr><td>Validation Recall</td><td>▁▅▆▇▆▇█▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.93807</td></tr><tr><td>Train Loss</td><td>0.1731</td></tr><tr><td>Validation Accuracy</td><td>0.8207</td></tr><tr><td>Validation F1</td><td>0.82</td></tr><tr><td>Validation Loss</td><td>0.70782</td></tr><tr><td>Validation Precision</td><td>0.82116</td></tr><tr><td>Validation Recall</td><td>0.8207</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_7</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/8d7brrq4' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/8d7brrq4</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_025456-8d7brrq4/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 03:38:23,421] Trial 7 finished with value: 0.8206997084548106 and parameters: {'learning_rate': 0.0003979053776068072, 'weight_decay': 7.323770717077471e-06, 'patience': 6, 'batch_size': 128, 'num_layers': 2}. Best is trial 0 with value: 0.8439018464528668.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_033824-egznsein</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/egznsein' target=\"_blank\">trial_8</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/egznsein' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/egznsein</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 8 for 10 epochs with patience 7...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.9679, Train Acc: 0.5282 | Val Loss: 0.8489, Val Acc: 0.6029, Val F1: 0.6097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.8140, Train Acc: 0.6380 | Val Loss: 0.7783, Val Acc: 0.6544, Val F1: 0.6587\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.7491, Train Acc: 0.6793 | Val Loss: 0.7390, Val Acc: 0.6952, Val F1: 0.6968\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.7057, Train Acc: 0.7008 | Val Loss: 0.7098, Val Acc: 0.7089, Val F1: 0.7109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.6744, Train Acc: 0.7198 | Val Loss: 0.6799, Val Acc: 0.7247, Val F1: 0.7268\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.6472, Train Acc: 0.7351 | Val Loss: 0.6620, Val Acc: 0.7359, Val F1: 0.7381\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.6257, Train Acc: 0.7457 | Val Loss: 0.6492, Val Acc: 0.7404, Val F1: 0.7433\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.6085, Train Acc: 0.7531 | Val Loss: 0.6366, Val Acc: 0.7496, Val F1: 0.7510\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.5896, Train Acc: 0.7627 | Val Loss: 0.6311, Val Acc: 0.7479, Val F1: 0.7514\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.5676, Train Acc: 0.7749 | Val Loss: 0.6265, Val Acc: 0.7575, Val F1: 0.7591\n",
            "Training complete. Best Validation Accuracy: 0.7575 at epoch 10.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇██</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▅▆▇▇▇███</td></tr><tr><td>Validation F1</td><td>▁▃▅▆▆▇▇███</td></tr><tr><td>Validation Loss</td><td>█▆▅▄▃▂▂▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▃▄▅▆▇▇▇██</td></tr><tr><td>Validation Recall</td><td>▁▃▅▆▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.77494</td></tr><tr><td>Train Loss</td><td>0.56757</td></tr><tr><td>Validation Accuracy</td><td>0.75753</td></tr><tr><td>Validation F1</td><td>0.7591</td></tr><tr><td>Validation Loss</td><td>0.62652</td></tr><tr><td>Validation Precision</td><td>0.7653</td></tr><tr><td>Validation Recall</td><td>0.75753</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_8</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/egznsein' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/egznsein</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_033824-egznsein/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 04:23:24,631] Trial 8 finished with value: 0.7575315840621963 and parameters: {'learning_rate': 1.2511324122289102e-05, 'weight_decay': 8.201997235370834e-05, 'patience': 7, 'batch_size': 128, 'num_layers': 2}. Best is trial 0 with value: 0.8439018464528668.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_042326-wsarsnit</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/wsarsnit' target=\"_blank\">trial_9</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/wsarsnit' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/wsarsnit</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 9 for 10 epochs with patience 6...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.7412, Train Acc: 0.6855 | Val Loss: 0.6115, Val Acc: 0.7670, Val F1: 0.7680\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.5881, Train Acc: 0.7701 | Val Loss: 0.5808, Val Acc: 0.7741, Val F1: 0.7750\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.5309, Train Acc: 0.7976 | Val Loss: 0.6160, Val Acc: 0.7885, Val F1: 0.7874\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.4817, Train Acc: 0.8214 | Val Loss: 0.5705, Val Acc: 0.8014, Val F1: 0.8024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.4497, Train Acc: 0.8331 | Val Loss: 0.6225, Val Acc: 0.7990, Val F1: 0.7984\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.4127, Train Acc: 0.8515 | Val Loss: 0.6305, Val Acc: 0.7994, Val F1: 0.8000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.3821, Train Acc: 0.8625 | Val Loss: 0.5845, Val Acc: 0.8149, Val F1: 0.8145\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.3601, Train Acc: 0.8720 | Val Loss: 0.5891, Val Acc: 0.8082, Val F1: 0.8085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.3353, Train Acc: 0.8813 | Val Loss: 0.5670, Val Acc: 0.8127, Val F1: 0.8121\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.3054, Train Acc: 0.8932 | Val Loss: 0.5860, Val Acc: 0.8191, Val F1: 0.8189\n",
            "Training complete. Best Validation Accuracy: 0.8191 at epoch 10.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▂▄▆▅▅▇▇▇█</td></tr><tr><td>Validation F1</td><td>▁▂▄▆▅▅▇▇▇█</td></tr><tr><td>Validation Loss</td><td>▆▃▆▁▇█▃▃▁▃</td></tr><tr><td>Validation Precision</td><td>▁▃▃▆▆▅▇▇▇█</td></tr><tr><td>Validation Recall</td><td>▁▂▄▆▅▅▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.89318</td></tr><tr><td>Train Loss</td><td>0.30544</td></tr><tr><td>Validation Accuracy</td><td>0.81912</td></tr><tr><td>Validation F1</td><td>0.81885</td></tr><tr><td>Validation Loss</td><td>0.58604</td></tr><tr><td>Validation Precision</td><td>0.81872</td></tr><tr><td>Validation Recall</td><td>0.81912</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_9</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/wsarsnit' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/wsarsnit</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_042326-wsarsnit/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 05:08:23,968] Trial 9 finished with value: 0.8191205053449951 and parameters: {'learning_rate': 0.0005270646678704237, 'weight_decay': 1.1391038609191056e-05, 'patience': 6, 'batch_size': 64, 'num_layers': 2}. Best is trial 0 with value: 0.8439018464528668.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_050825-wv4cud9d</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/wv4cud9d' target=\"_blank\">trial_10</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/wv4cud9d' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/wv4cud9d</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 10 for 10 epochs with patience 6...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.7823, Train Acc: 0.6543 | Val Loss: 0.6531, Val Acc: 0.7206, Val F1: 0.7250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.6371, Train Acc: 0.7415 | Val Loss: 0.6142, Val Acc: 0.7609, Val F1: 0.7622\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.5901, Train Acc: 0.7662 | Val Loss: 0.5978, Val Acc: 0.7670, Val F1: 0.7683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.5624, Train Acc: 0.7767 | Val Loss: 0.5914, Val Acc: 0.7666, Val F1: 0.7691\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.5382, Train Acc: 0.7883 | Val Loss: 0.6017, Val Acc: 0.7840, Val F1: 0.7838\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.5217, Train Acc: 0.7932 | Val Loss: 0.5847, Val Acc: 0.7863, Val F1: 0.7866\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.5009, Train Acc: 0.8014 | Val Loss: 0.5863, Val Acc: 0.7913, Val F1: 0.7913\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.4804, Train Acc: 0.8114 | Val Loss: 0.6049, Val Acc: 0.7868, Val F1: 0.7870\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.4621, Train Acc: 0.8138 | Val Loss: 0.5733, Val Acc: 0.7858, Val F1: 0.7867\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.4529, Train Acc: 0.8198 | Val Loss: 0.6027, Val Acc: 0.7818, Val F1: 0.7831\n",
            "Training complete. Best Validation Accuracy: 0.7913 at epoch 7.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▆▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▆▇███▇▇</td></tr><tr><td>Validation F1</td><td>▁▅▆▆▇▇███▇</td></tr><tr><td>Validation Loss</td><td>█▅▃▃▃▂▂▄▁▄</td></tr><tr><td>Validation Precision</td><td>▁▃▅▆▆█▇█▇▆</td></tr><tr><td>Validation Recall</td><td>▁▅▆▆▇███▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.8198</td></tr><tr><td>Train Loss</td><td>0.45293</td></tr><tr><td>Validation Accuracy</td><td>0.78183</td></tr><tr><td>Validation F1</td><td>0.78306</td></tr><tr><td>Validation Loss</td><td>0.60267</td></tr><tr><td>Validation Precision</td><td>0.78567</td></tr><tr><td>Validation Recall</td><td>0.78183</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_10</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/wv4cud9d' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/wv4cud9d</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_050825-wv4cud9d/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 05:47:30,013] Trial 10 finished with value: 0.7913022351797862 and parameters: {'learning_rate': 0.0009029948969690496, 'weight_decay': 6.339803747776122e-05, 'patience': 6, 'batch_size': 128, 'num_layers': 1}. Best is trial 0 with value: 0.8439018464528668.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_054731-vrnwt8me</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/vrnwt8me' target=\"_blank\">trial_11</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/vrnwt8me' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/vrnwt8me</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 11 for 10 epochs with patience 7...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.7249, Train Acc: 0.6937 | Val Loss: 0.5859, Val Acc: 0.7739, Val F1: 0.7752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.5483, Train Acc: 0.7885 | Val Loss: 0.5593, Val Acc: 0.7937, Val F1: 0.7943\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.4710, Train Acc: 0.8234 | Val Loss: 0.5319, Val Acc: 0.8137, Val F1: 0.8131\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.3994, Train Acc: 0.8522 | Val Loss: 0.5317, Val Acc: 0.8129, Val F1: 0.8128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.3449, Train Acc: 0.8747 | Val Loss: 0.5398, Val Acc: 0.8309, Val F1: 0.8307\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.2912, Train Acc: 0.8939 | Val Loss: 0.5705, Val Acc: 0.8265, Val F1: 0.8266\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.2504, Train Acc: 0.9123 | Val Loss: 0.6084, Val Acc: 0.8245, Val F1: 0.8238\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.2137, Train Acc: 0.9225 | Val Loss: 0.6295, Val Acc: 0.8066, Val F1: 0.8102\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.1739, Train Acc: 0.9366 | Val Loss: 0.6819, Val Acc: 0.8271, Val F1: 0.8271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.1488, Train Acc: 0.9465 | Val Loss: 0.6765, Val Acc: 0.8189, Val F1: 0.8197\n",
            "Training complete. Best Validation Accuracy: 0.8309 at epoch 5.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▅▆▇▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▆▆█▇▇▅█▇</td></tr><tr><td>Validation F1</td><td>▁▃▆▆█▇▇▅█▇</td></tr><tr><td>Validation Loss</td><td>▄▂▁▁▁▃▅▆██</td></tr><tr><td>Validation Precision</td><td>▁▃▆▅██▇▆▇▇</td></tr><tr><td>Validation Recall</td><td>▁▃▆▆█▇▇▅█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.94645</td></tr><tr><td>Train Loss</td><td>0.14884</td></tr><tr><td>Validation Accuracy</td><td>0.81888</td></tr><tr><td>Validation F1</td><td>0.81965</td></tr><tr><td>Validation Loss</td><td>0.67654</td></tr><tr><td>Validation Precision</td><td>0.8243</td></tr><tr><td>Validation Recall</td><td>0.81888</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_11</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/vrnwt8me' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/vrnwt8me</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_054731-vrnwt8me/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 06:37:26,007] Trial 11 finished with value: 0.8309037900874635 and parameters: {'learning_rate': 5.137874997552416e-05, 'weight_decay': 3.2495386500303347e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 3}. Best is trial 0 with value: 0.8439018464528668.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_063727-8n1ca7oc</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/8n1ca7oc' target=\"_blank\">trial_12</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/8n1ca7oc' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/8n1ca7oc</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 12 for 10 epochs with patience 7...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.8098, Train Acc: 0.6391 | Val Loss: 0.6725, Val Acc: 0.7393, Val F1: 0.7401\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.6280, Train Acc: 0.7479 | Val Loss: 0.6057, Val Acc: 0.7699, Val F1: 0.7706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.5484, Train Acc: 0.7857 | Val Loss: 0.5719, Val Acc: 0.7832, Val F1: 0.7848\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.4966, Train Acc: 0.8103 | Val Loss: 0.5564, Val Acc: 0.8009, Val F1: 0.8017\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.4511, Train Acc: 0.8284 | Val Loss: 0.5705, Val Acc: 0.8032, Val F1: 0.8027\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.4021, Train Acc: 0.8499 | Val Loss: 0.6152, Val Acc: 0.8059, Val F1: 0.8041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.3653, Train Acc: 0.8644 | Val Loss: 0.5786, Val Acc: 0.8160, Val F1: 0.8154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.3204, Train Acc: 0.8816 | Val Loss: 0.6076, Val Acc: 0.8014, Val F1: 0.8040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.2847, Train Acc: 0.8938 | Val Loss: 0.6311, Val Acc: 0.8124, Val F1: 0.8132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.2480, Train Acc: 0.9068 | Val Loss: 0.6750, Val Acc: 0.8043, Val F1: 0.8066\n",
            "Training complete. Best Validation Accuracy: 0.8160 at epoch 7.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▅▆▇▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▅▄▄▃▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▅▇▇▇█▇█▇</td></tr><tr><td>Validation F1</td><td>▁▄▅▇▇▇█▇█▇</td></tr><tr><td>Validation Loss</td><td>█▄▂▁▂▄▂▄▅█</td></tr><tr><td>Validation Precision</td><td>▁▄▅▇▇▇████</td></tr><tr><td>Validation Recall</td><td>▁▄▅▇▇▇█▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.90682</td></tr><tr><td>Train Loss</td><td>0.24797</td></tr><tr><td>Validation Accuracy</td><td>0.8043</td></tr><tr><td>Validation F1</td><td>0.80663</td></tr><tr><td>Validation Loss</td><td>0.67504</td></tr><tr><td>Validation Precision</td><td>0.8124</td></tr><tr><td>Validation Recall</td><td>0.8043</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_12</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/8n1ca7oc' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning/runs/8n1ca7oc</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/tweet-sentiment-finetuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_063727-8n1ca7oc/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 07:26:24,646] Trial 12 finished with value: 0.8159620991253644 and parameters: {'learning_rate': 3.6780008898063395e-05, 'weight_decay': 3.052125343678765e-05, 'patience': 7, 'batch_size': 128, 'num_layers': 3}. Best is trial 0 with value: 0.8439018464528668.\n"
          ]
        }
      ],
      "source": [
        "# Optuna Study\n",
        "study = optuna.create_study(direction=\"maximize\")  # Specify maximizing the best_val_accuracy\n",
        "study.optimize(objective, n_trials=13)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save to drive (checkpoint)"
      ],
      "metadata": {
        "id": "-3KkSFa7tdGM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjkQYjBmr2aB",
        "outputId": "0c7cb544-8684-4929-ab57-bc24b7a5d591"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best BERTweet hyperparameters for 'full code' training saved to: /content/drive/MyDrive/ADV_DL/hyperparams/best_bertweet_full_code_hyperparams.json\n"
          ]
        }
      ],
      "source": [
        "# Define the directory and file path to save the hyperparameters\n",
        "HYPERPARAMS_DIR = os.path.join(BASE_DIR, \"hyperparams\")\n",
        "os.makedirs(HYPERPARAMS_DIR, exist_ok=True)\n",
        "BEST_BERTWEET_PARAMS_FILE = os.path.join(HYPERPARAMS_DIR, \"best_bertweet_full_code_hyperparams.json\")\n",
        "\n",
        "# Extract and save the best parameters from the Optuna study\n",
        "best_params = study.best_trial.params\n",
        "\n",
        "with open(BEST_BERTWEET_PARAMS_FILE, 'w') as f:\n",
        "    json.dump(best_params, f, indent=4)\n",
        "\n",
        "print(f\"Best BERTweet hyperparameters for 'full code' training saved to: {BEST_BERTWEET_PARAMS_FILE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY371bY7ykRK",
        "outputId": "ef49650e-eec0-40cf-f885-4bd4aedd7181"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading best model state from local path: /content/best_model_trial_0.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully. Now saving to Google Drive...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final fine-tuned BERTweet 'full code' model and tokenizer saved to: /content/drive/MyDrive/ADV_DL/final_models/bertweet_full_code\n"
          ]
        }
      ],
      "source": [
        "# Load the BERTweet tokenizer\n",
        "bertweet_tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)\n",
        "\n",
        "# Define the directory and filename of the best model saved by Optuna.\n",
        "# The file is saved directly in the BASE_DIR by the objective function.\n",
        "BEST_MODEL_OPTUNA_PATH = os.path.join(BASE_DIR, \"best_model_trial_0.pt\")  # <-- !! Adjust the trial number here !!\n",
        "\n",
        "# Load the best model's state dictionary\n",
        "best_bertweet_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"vinai/bertweet-base\",\n",
        "    num_labels=3\n",
        ")\n",
        "best_bertweet_model.load_state_dict(torch.load(BEST_MODEL_OPTUNA_PATH))\n",
        "best_bertweet_model.to(device)\n",
        "\n",
        "# Save the model and tokenizer to a dedicated directory in your Drive for later use.\n",
        "FINAL_MODEL_DIR_BERTWEET_FULL = os.path.join(BASE_DIR, \"final_models\", \"bertweet_full_code\")\n",
        "os.makedirs(FINAL_MODEL_DIR_BERTWEET_FULL, exist_ok=True)\n",
        "best_bertweet_model.save_pretrained(FINAL_MODEL_DIR_BERTWEET_FULL)\n",
        "bertweet_tokenizer.save_pretrained(FINAL_MODEL_DIR_BERTWEET_FULL)\n",
        "\n",
        "print(f\"Final fine-tuned BERTweet 'full code' model saved to: {FINAL_MODEL_DIR_BERTWEET_FULL}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKUygYD6sjfA"
      },
      "source": [
        "## distilBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optuna"
      ],
      "metadata": {
        "id": "qhMhvkdgCvG_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-1clbk-smuW"
      },
      "outputs": [],
      "source": [
        "def objective_distilbert_full_code(trial):\n",
        "    # Hyperparameter suggestions\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True)\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-4, log=True)\n",
        "    patience = trial.suggest_int(\"patience\", 6, 7)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
        "\n",
        "    # Unlike BERTweet, DistilBERT has 6 layers, so we tune a different range\n",
        "    num_layers = trial.suggest_int(\"num_layers\", 1, 6)\n",
        "\n",
        "    # Datasets / loaders for DistilBERT\n",
        "    train_dataset = TweetSentimentDataset(distilbert_train_encodings, train_df_distilbert['label'].tolist())\n",
        "    val_dataset = TweetSentimentDataset(val_distilbert_encodings, val_df_distilbert['label'].tolist())\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Model for DistilBERT\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        'distilbert-base-uncased', num_labels=3\n",
        "    ).to(device)\n",
        "\n",
        "    # Freeze base; unfreeze last `num_layers` + classifier\n",
        "    for p in model.distilbert.parameters():\n",
        "        p.requires_grad = False\n",
        "    for p in model.distilbert.transformer.layer[-num_layers:].parameters():\n",
        "        p.requires_grad = True\n",
        "    for p in model.pre_classifier.parameters():\n",
        "        p.requires_grad = True\n",
        "    for p in model.classifier.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "    # ---------- Imbalance handling: weighted loss ----------\n",
        "    classes = np.array([0, 1, 2], dtype=int)\n",
        "    y_train = np.array(train_df_distilbert['label'].tolist(), dtype=int)\n",
        "    weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
        "    class_weights = torch.tensor(weights, dtype=torch.float, device=device)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # W&B\n",
        "    wandb.init(\n",
        "        project=\"distilbert-full-code-tuning\",\n",
        "        config={\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"weight_decay\": weight_decay,\n",
        "            \"patience\": patience,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"num_layers\": num_layers,\n",
        "            \"architecture\": \"DistilBERT\",\n",
        "            \"dataset\": \"COVID-19-tweets-standardized\"\n",
        "        },\n",
        "        name=f\"trial_{trial.number}\",\n",
        "        reinit=True\n",
        "    )\n",
        "\n",
        "    # Train/eval loop\n",
        "    best_val_accuracy = train_model_with_hyperparams(\n",
        "        model, train_loader, val_loader, optimizer, criterion,\n",
        "        epochs=10, patience=patience, trial=trial\n",
        "    )\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "    return best_val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "46-1OxnbsoeW",
        "outputId": "d2e99a0d-46e6-46d9-f2aa-841f100473b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 08:13:25,453] A new study created in memory with name: no-name-de0ce0c5-22e2-44de-b527-32cd3c99c387\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Optuna study for DistilBERT 'full code' training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_081326-1lfplbcx</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/1lfplbcx' target=\"_blank\">trial_0</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/1lfplbcx' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/1lfplbcx</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 0 for 10 epochs with patience 7...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.8286, Train Acc: 0.6280 | Val Loss: 0.6941, Val Acc: 0.7070, Val F1: 0.7114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.6506, Train Acc: 0.7339 | Val Loss: 0.6103, Val Acc: 0.7603, Val F1: 0.7620\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.5745, Train Acc: 0.7746 | Val Loss: 0.5735, Val Acc: 0.7869, Val F1: 0.7877\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.5164, Train Acc: 0.7999 | Val Loss: 0.5542, Val Acc: 0.7939, Val F1: 0.7945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.4711, Train Acc: 0.8220 | Val Loss: 0.5317, Val Acc: 0.7968, Val F1: 0.7983\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.4313, Train Acc: 0.8392 | Val Loss: 0.5268, Val Acc: 0.8073, Val F1: 0.8084\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.3850, Train Acc: 0.8549 | Val Loss: 0.5286, Val Acc: 0.8206, Val F1: 0.8206\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.3485, Train Acc: 0.8714 | Val Loss: 0.5572, Val Acc: 0.8229, Val F1: 0.8223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.3071, Train Acc: 0.8864 | Val Loss: 0.5483, Val Acc: 0.8174, Val F1: 0.8182\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.2737, Train Acc: 0.8998 | Val Loss: 0.5738, Val Acc: 0.8243, Val F1: 0.8244\n",
            "Training complete. Best Validation Accuracy: 0.8243 at epoch 10.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▅▆▆▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▆▆▆▇████</td></tr><tr><td>Validation F1</td><td>▁▄▆▆▆▇████</td></tr><tr><td>Validation Loss</td><td>█▄▃▂▁▁▁▂▂▃</td></tr><tr><td>Validation Precision</td><td>▁▄▅▆▇▇████</td></tr><tr><td>Validation Recall</td><td>▁▄▆▆▆▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.89983</td></tr><tr><td>Train Loss</td><td>0.27369</td></tr><tr><td>Validation Accuracy</td><td>0.82434</td></tr><tr><td>Validation F1</td><td>0.82441</td></tr><tr><td>Validation Loss</td><td>0.57378</td></tr><tr><td>Validation Precision</td><td>0.82568</td></tr><tr><td>Validation Recall</td><td>0.82434</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/1lfplbcx' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/1lfplbcx</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_081326-1lfplbcx/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 08:40:00,760] Trial 0 finished with value: 0.8243440233236151 and parameters: {'learning_rate': 2.3147116447384962e-05, 'weight_decay': 4.511488931804444e-05, 'patience': 7, 'batch_size': 128, 'num_layers': 2}. Best is trial 0 with value: 0.8243440233236151.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_084001-ry21z6sh</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/ry21z6sh' target=\"_blank\">trial_1</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/ry21z6sh' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/ry21z6sh</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 1 for 10 epochs with patience 7...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.5776, Train Acc: 0.7754 | Val Loss: 0.4392, Val Acc: 0.8434, Val F1: 0.8435\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.3758, Train Acc: 0.8732 | Val Loss: 0.3821, Val Acc: 0.8773, Val F1: 0.8768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.2884, Train Acc: 0.9058 | Val Loss: 0.3502, Val Acc: 0.8802, Val F1: 0.8804\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.2300, Train Acc: 0.9260 | Val Loss: 0.3759, Val Acc: 0.8671, Val F1: 0.8689\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.1922, Train Acc: 0.9411 | Val Loss: 0.4153, Val Acc: 0.8801, Val F1: 0.8801\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.1522, Train Acc: 0.9526 | Val Loss: 0.4127, Val Acc: 0.8856, Val F1: 0.8852\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.1239, Train Acc: 0.9621 | Val Loss: 0.5298, Val Acc: 0.8867, Val F1: 0.8861\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.1044, Train Acc: 0.9666 | Val Loss: 0.4812, Val Acc: 0.8641, Val F1: 0.8652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.0852, Train Acc: 0.9724 | Val Loss: 0.5335, Val Acc: 0.8639, Val F1: 0.8660\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.0671, Train Acc: 0.9780 | Val Loss: 0.5823, Val Acc: 0.8722, Val F1: 0.8726\n",
            "Training complete. Best Validation Accuracy: 0.8867 at epoch 7.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▆▇▅▇██▄▄▆</td></tr><tr><td>Validation F1</td><td>▁▆▇▅▇██▅▅▆</td></tr><tr><td>Validation Loss</td><td>▄▂▁▂▃▃▆▅▇█</td></tr><tr><td>Validation Precision</td><td>▁▆▇▅▇██▄▅▅</td></tr><tr><td>Validation Recall</td><td>▁▆▇▅▇██▄▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.97804</td></tr><tr><td>Train Loss</td><td>0.06707</td></tr><tr><td>Validation Accuracy</td><td>0.87221</td></tr><tr><td>Validation F1</td><td>0.87264</td></tr><tr><td>Validation Loss</td><td>0.58233</td></tr><tr><td>Validation Precision</td><td>0.8743</td></tr><tr><td>Validation Recall</td><td>0.87221</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_1</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/ry21z6sh' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/ry21z6sh</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_084001-ry21z6sh/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 09:17:36,557] Trial 1 finished with value: 0.8866618075801749 and parameters: {'learning_rate': 0.00010825830161396886, 'weight_decay': 3.324174689345579e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 4}. Best is trial 1 with value: 0.8866618075801749.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_091736-vyclzpko</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/vyclzpko' target=\"_blank\">trial_2</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/vyclzpko' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/vyclzpko</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 2 for 10 epochs with patience 7...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.7485, Train Acc: 0.6746 | Val Loss: 0.6246, Val Acc: 0.7498, Val F1: 0.7521\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.5943, Train Acc: 0.7628 | Val Loss: 0.5812, Val Acc: 0.7719, Val F1: 0.7730\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.5303, Train Acc: 0.7889 | Val Loss: 0.5808, Val Acc: 0.7676, Val F1: 0.7708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.4721, Train Acc: 0.8143 | Val Loss: 0.6184, Val Acc: 0.7846, Val F1: 0.7829\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.4127, Train Acc: 0.8378 | Val Loss: 0.5898, Val Acc: 0.7948, Val F1: 0.7946\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.3517, Train Acc: 0.8607 | Val Loss: 0.6835, Val Acc: 0.7895, Val F1: 0.7896\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.2788, Train Acc: 0.8859 | Val Loss: 0.7041, Val Acc: 0.7869, Val F1: 0.7889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.2255, Train Acc: 0.9092 | Val Loss: 0.7880, Val Acc: 0.7903, Val F1: 0.7904\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.1799, Train Acc: 0.9274 | Val Loss: 0.8231, Val Acc: 0.7767, Val F1: 0.7780\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.1531, Train Acc: 0.9384 | Val Loss: 0.9251, Val Acc: 0.7861, Val F1: 0.7862\n",
            "Training complete. Best Validation Accuracy: 0.7948 at epoch 5.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▅▆▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▅▅▄▃▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▄▆█▇▇▇▅▇</td></tr><tr><td>Validation F1</td><td>▁▄▄▆█▇▇▇▅▇</td></tr><tr><td>Validation Loss</td><td>▂▁▁▂▁▃▄▅▆█</td></tr><tr><td>Validation Precision</td><td>▁▅▆▇█▇█▇▅▆</td></tr><tr><td>Validation Recall</td><td>▁▄▄▆█▇▇▇▅▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.93841</td></tr><tr><td>Train Loss</td><td>0.15309</td></tr><tr><td>Validation Accuracy</td><td>0.78608</td></tr><tr><td>Validation F1</td><td>0.78622</td></tr><tr><td>Validation Loss</td><td>0.92511</td></tr><tr><td>Validation Precision</td><td>0.78697</td></tr><tr><td>Validation Recall</td><td>0.78608</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_2</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/vyclzpko' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/vyclzpko</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_091736-vyclzpko/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 09:39:34,958] Trial 2 finished with value: 0.7948250728862973 and parameters: {'learning_rate': 0.00019831031616849638, 'weight_decay': 1.4920269827149783e-06, 'patience': 7, 'batch_size': 128, 'num_layers': 1}. Best is trial 1 with value: 0.8866618075801749.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_093935-aukq4gyr</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/aukq4gyr' target=\"_blank\">trial_3</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/aukq4gyr' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/aukq4gyr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 3 for 10 epochs with patience 7...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.7223, Train Acc: 0.6952 | Val Loss: 0.6021, Val Acc: 0.7609, Val F1: 0.7628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.5879, Train Acc: 0.7675 | Val Loss: 0.5909, Val Acc: 0.7742, Val F1: 0.7745\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.5309, Train Acc: 0.7943 | Val Loss: 0.5780, Val Acc: 0.7875, Val F1: 0.7880\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.4834, Train Acc: 0.8121 | Val Loss: 0.5490, Val Acc: 0.7953, Val F1: 0.7959\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.4246, Train Acc: 0.8337 | Val Loss: 0.5956, Val Acc: 0.7994, Val F1: 0.7983\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.3689, Train Acc: 0.8534 | Val Loss: 0.5841, Val Acc: 0.7959, Val F1: 0.7964\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.3117, Train Acc: 0.8758 | Val Loss: 0.6391, Val Acc: 0.7851, Val F1: 0.7871\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.2603, Train Acc: 0.8931 | Val Loss: 0.7611, Val Acc: 0.7929, Val F1: 0.7925\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.2216, Train Acc: 0.9106 | Val Loss: 0.7713, Val Acc: 0.7855, Val F1: 0.7860\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.1933, Train Acc: 0.9235 | Val Loss: 0.8792, Val Acc: 0.7830, Val F1: 0.7826\n",
            "Training complete. Best Validation Accuracy: 0.7994 at epoch 5.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▅▆▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▅▅▄▃▃▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▆▇█▇▅▇▅▅</td></tr><tr><td>Validation F1</td><td>▁▃▆███▆▇▆▅</td></tr><tr><td>Validation Loss</td><td>▂▂▂▁▂▂▃▅▆█</td></tr><tr><td>Validation Precision</td><td>▁▅▆▇██▆▇▆▄</td></tr><tr><td>Validation Recall</td><td>▁▃▆▇█▇▅▇▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.92349</td></tr><tr><td>Train Loss</td><td>0.19326</td></tr><tr><td>Validation Accuracy</td><td>0.78304</td></tr><tr><td>Validation F1</td><td>0.78256</td></tr><tr><td>Validation Loss</td><td>0.87916</td></tr><tr><td>Validation Precision</td><td>0.78231</td></tr><tr><td>Validation Recall</td><td>0.78304</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_3</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/aukq4gyr' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/aukq4gyr</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_093935-aukq4gyr/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 10:02:17,482] Trial 3 finished with value: 0.79944120505345 and parameters: {'learning_rate': 0.00015002091933890785, 'weight_decay': 6.145316886295965e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 1}. Best is trial 1 with value: 0.8866618075801749.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_100217-5jm0ffe8</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/5jm0ffe8' target=\"_blank\">trial_4</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/5jm0ffe8' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/5jm0ffe8</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 4 for 10 epochs with patience 6...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.7532, Train Acc: 0.7080 | Val Loss: 0.9419, Val Acc: 0.5113, Val F1: 0.4158\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 1.0248, Train Acc: 0.4330 | Val Loss: 1.0659, Val Acc: 0.4015, Val F1: 0.3242\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 1.0926, Train Acc: 0.3516 | Val Loss: 1.0988, Val Acc: 0.1874, Val F1: 0.0592\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 1.0976, Train Acc: 0.3689 | Val Loss: 1.0993, Val Acc: 0.4384, Val F1: 0.2672\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 1.0989, Train Acc: 0.3863 | Val Loss: 1.0990, Val Acc: 0.1874, Val F1: 0.0592\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 1.0985, Train Acc: 0.3533 | Val Loss: 1.1008, Val Acc: 0.4384, Val F1: 0.2672\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 1.0989, Train Acc: 0.4031 | Val Loss: 1.0985, Val Acc: 0.3741, Val F1: 0.2037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 1.0989, Train Acc: 0.4051 | Val Loss: 1.0985, Val Acc: 0.3741, Val F1: 0.2037\n",
            "Early stopping triggered at epoch 8.\n",
            "Training complete. Best Validation Accuracy: 0.5113 at epoch 1.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>Train Accuracy</td><td>█▃▁▁▂▁▂▂</td></tr><tr><td>Train Loss</td><td>▁▆██████</td></tr><tr><td>Validation Accuracy</td><td>█▆▁▆▁▆▅▅</td></tr><tr><td>Validation F1</td><td>█▆▁▅▁▅▄▄</td></tr><tr><td>Validation Loss</td><td>▁▆██████</td></tr><tr><td>Validation Precision</td><td>█▅▁▃▁▃▃▃</td></tr><tr><td>Validation Recall</td><td>█▆▁▆▁▆▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>8</td></tr><tr><td>Train Accuracy</td><td>0.40513</td></tr><tr><td>Train Loss</td><td>1.09886</td></tr><tr><td>Validation Accuracy</td><td>0.37415</td></tr><tr><td>Validation F1</td><td>0.20374</td></tr><tr><td>Validation Loss</td><td>1.0985</td></tr><tr><td>Validation Precision</td><td>0.13999</td></tr><tr><td>Validation Recall</td><td>0.37415</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_4</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/5jm0ffe8' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/5jm0ffe8</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_100217-5jm0ffe8/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 10:39:06,425] Trial 4 finished with value: 0.5112973760932945 and parameters: {'learning_rate': 0.0002577884052019022, 'weight_decay': 1.4666338702506418e-06, 'patience': 6, 'batch_size': 32, 'num_layers': 6}. Best is trial 1 with value: 0.8866618075801749.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_103906-kpsm7hj8</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/kpsm7hj8' target=\"_blank\">trial_5</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/kpsm7hj8' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/kpsm7hj8</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 5 for 10 epochs with patience 7...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.7423, Train Acc: 0.6839 | Val Loss: 0.6487, Val Acc: 0.7510, Val F1: 0.7504\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.5963, Train Acc: 0.7631 | Val Loss: 0.5918, Val Acc: 0.7711, Val F1: 0.7706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.5280, Train Acc: 0.7928 | Val Loss: 0.5658, Val Acc: 0.7798, Val F1: 0.7803\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.4692, Train Acc: 0.8158 | Val Loss: 0.5598, Val Acc: 0.7768, Val F1: 0.7788\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.3931, Train Acc: 0.8457 | Val Loss: 0.5873, Val Acc: 0.7851, Val F1: 0.7862\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.3135, Train Acc: 0.8748 | Val Loss: 0.6562, Val Acc: 0.7862, Val F1: 0.7868\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.2419, Train Acc: 0.9015 | Val Loss: 0.7739, Val Acc: 0.7861, Val F1: 0.7856\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.1898, Train Acc: 0.9223 | Val Loss: 0.8412, Val Acc: 0.7862, Val F1: 0.7874\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.1559, Train Acc: 0.9358 | Val Loss: 0.9191, Val Acc: 0.7829, Val F1: 0.7828\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.1271, Train Acc: 0.9499 | Val Loss: 1.0494, Val Acc: 0.7795, Val F1: 0.7788\n",
            "Training complete. Best Validation Accuracy: 0.7862 at epoch 6.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▄▅▆▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▆▅▄▃▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▇▆████▇▇</td></tr><tr><td>Validation F1</td><td>▁▅▇▆████▇▆</td></tr><tr><td>Validation Loss</td><td>▂▁▁▁▁▂▄▅▆█</td></tr><tr><td>Validation Precision</td><td>▁▅▆▇██▇█▆▅</td></tr><tr><td>Validation Recall</td><td>▁▅▇▆████▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.94995</td></tr><tr><td>Train Loss</td><td>0.12708</td></tr><tr><td>Validation Accuracy</td><td>0.77952</td></tr><tr><td>Validation F1</td><td>0.77878</td></tr><tr><td>Validation Loss</td><td>1.04937</td></tr><tr><td>Validation Precision</td><td>0.77861</td></tr><tr><td>Validation Recall</td><td>0.77952</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_5</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/kpsm7hj8' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/kpsm7hj8</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_103906-kpsm7hj8/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 11:01:38,436] Trial 5 finished with value: 0.7862001943634597 and parameters: {'learning_rate': 8.102377917502759e-05, 'weight_decay': 1.9968018577169306e-05, 'patience': 7, 'batch_size': 32, 'num_layers': 1}. Best is trial 1 with value: 0.8866618075801749.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_110138-1wrq2s2q</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/1wrq2s2q' target=\"_blank\">trial_6</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/1wrq2s2q' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/1wrq2s2q</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 6 for 10 epochs with patience 6...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.7724, Train Acc: 0.6645 | Val Loss: 0.6461, Val Acc: 0.7400, Val F1: 0.7411\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.5902, Train Acc: 0.7693 | Val Loss: 0.5793, Val Acc: 0.7901, Val F1: 0.7896\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.5101, Train Acc: 0.8066 | Val Loss: 0.5453, Val Acc: 0.8067, Val F1: 0.8060\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.4459, Train Acc: 0.8349 | Val Loss: 0.5116, Val Acc: 0.8140, Val F1: 0.8140\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.3964, Train Acc: 0.8550 | Val Loss: 0.5037, Val Acc: 0.8254, Val F1: 0.8258\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.3475, Train Acc: 0.8740 | Val Loss: 0.5030, Val Acc: 0.8268, Val F1: 0.8274\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.3050, Train Acc: 0.8912 | Val Loss: 0.5228, Val Acc: 0.8341, Val F1: 0.8341\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.2660, Train Acc: 0.9041 | Val Loss: 0.5517, Val Acc: 0.8344, Val F1: 0.8340\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.2317, Train Acc: 0.9156 | Val Loss: 0.5547, Val Acc: 0.8309, Val F1: 0.8317\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.1945, Train Acc: 0.9285 | Val Loss: 0.5945, Val Acc: 0.8262, Val F1: 0.8273\n",
            "Training complete. Best Validation Accuracy: 0.8344 at epoch 8.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▆▇▇███▇</td></tr><tr><td>Validation F1</td><td>▁▅▆▆▇▇███▇</td></tr><tr><td>Validation Loss</td><td>█▅▃▁▁▁▂▃▄▅</td></tr><tr><td>Validation Precision</td><td>▁▅▅▇▇█████</td></tr><tr><td>Validation Recall</td><td>▁▅▆▆▇▇███▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.9285</td></tr><tr><td>Train Loss</td><td>0.1945</td></tr><tr><td>Validation Accuracy</td><td>0.82617</td></tr><tr><td>Validation F1</td><td>0.82727</td></tr><tr><td>Validation Loss</td><td>0.59447</td></tr><tr><td>Validation Precision</td><td>0.83056</td></tr><tr><td>Validation Recall</td><td>0.82617</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_6</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/1wrq2s2q' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/1wrq2s2q</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_110138-1wrq2s2q/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 11:34:09,988] Trial 6 finished with value: 0.8344266277939747 and parameters: {'learning_rate': 1.031417927047022e-05, 'weight_decay': 6.48361301935615e-06, 'patience': 6, 'batch_size': 32, 'num_layers': 3}. Best is trial 1 with value: 0.8866618075801749.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_113410-8kyu493a</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/8kyu493a' target=\"_blank\">trial_7</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/8kyu493a' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/8kyu493a</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 7 for 10 epochs with patience 7...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.9565, Train Acc: 0.5469 | Val Loss: 0.8430, Val Acc: 0.6516, Val F1: 0.6527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.8066, Train Acc: 0.6739 | Val Loss: 0.8186, Val Acc: 0.6233, Val F1: 0.6335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.7491, Train Acc: 0.7000 | Val Loss: 0.6855, Val Acc: 0.7263, Val F1: 0.7285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.7946, Train Acc: 0.6705 | Val Loss: 0.7790, Val Acc: 0.7025, Val F1: 0.7027\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.8919, Train Acc: 0.5964 | Val Loss: 0.9881, Val Acc: 0.5159, Val F1: 0.4955\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.9024, Train Acc: 0.5785 | Val Loss: 0.9842, Val Acc: 0.5553, Val F1: 0.5284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.8508, Train Acc: 0.6200 | Val Loss: 0.9105, Val Acc: 0.5703, Val F1: 0.5450\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.8286, Train Acc: 0.6474 | Val Loss: 0.8084, Val Acc: 0.6681, Val F1: 0.6736\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.8091, Train Acc: 0.6611 | Val Loss: 0.7799, Val Acc: 0.6684, Val F1: 0.6665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.8022, Train Acc: 0.6562 | Val Loss: 0.7893, Val Acc: 0.6687, Val F1: 0.6726\n",
            "Training complete. Best Validation Accuracy: 0.7263 at epoch 3.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▇█▇▃▂▄▆▆▆</td></tr><tr><td>Train Loss</td><td>█▃▁▃▆▆▄▄▃▃</td></tr><tr><td>Validation Accuracy</td><td>▆▅█▇▁▂▃▆▆▆</td></tr><tr><td>Validation F1</td><td>▆▅█▇▁▂▂▆▆▆</td></tr><tr><td>Validation Loss</td><td>▅▄▁▃██▆▄▃▃</td></tr><tr><td>Validation Precision</td><td>▄▅█▆▁▄▅▆▆▆</td></tr><tr><td>Validation Recall</td><td>▆▅█▇▁▂▃▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.65619</td></tr><tr><td>Train Loss</td><td>0.80221</td></tr><tr><td>Validation Accuracy</td><td>0.66873</td></tr><tr><td>Validation F1</td><td>0.67262</td></tr><tr><td>Validation Loss</td><td>0.78934</td></tr><tr><td>Validation Precision</td><td>0.69806</td></tr><tr><td>Validation Recall</td><td>0.66873</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_7</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/8kyu493a' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/8kyu493a</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_113410-8kyu493a/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 12:04:31,375] Trial 7 finished with value: 0.7263119533527697 and parameters: {'learning_rate': 0.0009649203802061476, 'weight_decay': 4.0345821974925446e-06, 'patience': 7, 'batch_size': 128, 'num_layers': 3}. Best is trial 1 with value: 0.8866618075801749.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_120431-u8tpgxpa</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/u8tpgxpa' target=\"_blank\">trial_8</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/u8tpgxpa' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/u8tpgxpa</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 8 for 10 epochs with patience 6...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.6301, Train Acc: 0.7490 | Val Loss: 0.4857, Val Acc: 0.8234, Val F1: 0.8237\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.4257, Train Acc: 0.8484 | Val Loss: 0.4224, Val Acc: 0.8587, Val F1: 0.8585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.3302, Train Acc: 0.8876 | Val Loss: 0.4373, Val Acc: 0.8450, Val F1: 0.8451\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.2567, Train Acc: 0.9136 | Val Loss: 0.4368, Val Acc: 0.8619, Val F1: 0.8618\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.2037, Train Acc: 0.9335 | Val Loss: 0.4908, Val Acc: 0.8590, Val F1: 0.8592\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.1635, Train Acc: 0.9467 | Val Loss: 0.5214, Val Acc: 0.8649, Val F1: 0.8645\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.1290, Train Acc: 0.9576 | Val Loss: 0.5072, Val Acc: 0.8717, Val F1: 0.8717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.0939, Train Acc: 0.9691 | Val Loss: 0.5792, Val Acc: 0.8582, Val F1: 0.8584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.0761, Train Acc: 0.9740 | Val Loss: 0.5960, Val Acc: 0.8627, Val F1: 0.8632\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.0635, Train Acc: 0.9787 | Val Loss: 0.6261, Val Acc: 0.8653, Val F1: 0.8653\n",
            "Training complete. Best Validation Accuracy: 0.8717 at epoch 7.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▆▄▇▆▇█▆▇▇</td></tr><tr><td>Validation F1</td><td>▁▆▄▇▆▇█▆▇▇</td></tr><tr><td>Validation Loss</td><td>▃▁▂▁▃▄▄▆▇█</td></tr><tr><td>Validation Precision</td><td>▁▆▅▆▆▇█▆▇▇</td></tr><tr><td>Validation Recall</td><td>▁▆▄▇▆▇█▆▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.97871</td></tr><tr><td>Train Loss</td><td>0.06354</td></tr><tr><td>Validation Accuracy</td><td>0.86528</td></tr><tr><td>Validation F1</td><td>0.86531</td></tr><tr><td>Validation Loss</td><td>0.62607</td></tr><tr><td>Validation Precision</td><td>0.86538</td></tr><tr><td>Validation Recall</td><td>0.86528</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_8</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/u8tpgxpa' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/u8tpgxpa</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_120431-u8tpgxpa/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 12:36:07,878] Trial 8 finished with value: 0.8717201166180758 and parameters: {'learning_rate': 0.00011240088934226435, 'weight_decay': 2.7719520913043273e-06, 'patience': 6, 'batch_size': 64, 'num_layers': 3}. Best is trial 1 with value: 0.8866618075801749.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_123608-6h6fc2be</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/6h6fc2be' target=\"_blank\">trial_9</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/6h6fc2be' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/6h6fc2be</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 9 for 10 epochs with patience 6...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.7149, Train Acc: 0.7038 | Val Loss: 0.5179, Val Acc: 0.8099, Val F1: 0.8107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.4647, Train Acc: 0.8318 | Val Loss: 0.4459, Val Acc: 0.8475, Val F1: 0.8474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.3703, Train Acc: 0.8752 | Val Loss: 0.3942, Val Acc: 0.8711, Val F1: 0.8713\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.3097, Train Acc: 0.8980 | Val Loss: 0.3717, Val Acc: 0.8789, Val F1: 0.8786\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.2596, Train Acc: 0.9151 | Val Loss: 0.3880, Val Acc: 0.8803, Val F1: 0.8801\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.2173, Train Acc: 0.9301 | Val Loss: 0.3845, Val Acc: 0.8786, Val F1: 0.8787\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.1902, Train Acc: 0.9392 | Val Loss: 0.4142, Val Acc: 0.8852, Val F1: 0.8848\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.1613, Train Acc: 0.9489 | Val Loss: 0.3880, Val Acc: 0.8779, Val F1: 0.8785\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.1391, Train Acc: 0.9565 | Val Loss: 0.4702, Val Acc: 0.8788, Val F1: 0.8780\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.1125, Train Acc: 0.9652 | Val Loss: 0.4689, Val Acc: 0.8785, Val F1: 0.8783\n",
            "Training complete. Best Validation Accuracy: 0.8852 at epoch 7.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▇▇█▇█▇▇▇</td></tr><tr><td>Validation F1</td><td>▁▄▇▇█▇█▇▇▇</td></tr><tr><td>Validation Loss</td><td>█▅▂▁▂▂▃▂▆▆</td></tr><tr><td>Validation Precision</td><td>▁▅▇▇█▇█▇▇▇</td></tr><tr><td>Validation Recall</td><td>▁▅▇▇█▇█▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.96522</td></tr><tr><td>Train Loss</td><td>0.11254</td></tr><tr><td>Validation Accuracy</td><td>0.87852</td></tr><tr><td>Validation F1</td><td>0.87834</td></tr><tr><td>Validation Loss</td><td>0.46895</td></tr><tr><td>Validation Precision</td><td>0.8782</td></tr><tr><td>Validation Recall</td><td>0.87852</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_9</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/6h6fc2be' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/6h6fc2be</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_123608-6h6fc2be/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 13:19:31,755] Trial 9 finished with value: 0.8852040816326531 and parameters: {'learning_rate': 1.6096828009161672e-05, 'weight_decay': 3.546000577926727e-05, 'patience': 6, 'batch_size': 128, 'num_layers': 6}. Best is trial 1 with value: 0.8866618075801749.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_131932-j8010bpv</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/j8010bpv' target=\"_blank\">trial_10</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/j8010bpv' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/j8010bpv</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 10 for 10 epochs with patience 7...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.5956, Train Acc: 0.7606 | Val Loss: 0.4466, Val Acc: 0.8401, Val F1: 0.8407\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.3722, Train Acc: 0.8724 | Val Loss: 0.3639, Val Acc: 0.8789, Val F1: 0.8785\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.2783, Train Acc: 0.9078 | Val Loss: 0.3601, Val Acc: 0.8864, Val F1: 0.8861\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.2153, Train Acc: 0.9309 | Val Loss: 0.3655, Val Acc: 0.8887, Val F1: 0.8885\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.1715, Train Acc: 0.9465 | Val Loss: 0.4039, Val Acc: 0.8930, Val F1: 0.8924\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.1352, Train Acc: 0.9573 | Val Loss: 0.3915, Val Acc: 0.8902, Val F1: 0.8900\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.1037, Train Acc: 0.9669 | Val Loss: 0.4273, Val Acc: 0.8852, Val F1: 0.8852\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.0756, Train Acc: 0.9752 | Val Loss: 0.4831, Val Acc: 0.8867, Val F1: 0.8865\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.0577, Train Acc: 0.9817 | Val Loss: 0.5260, Val Acc: 0.8701, Val F1: 0.8718\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.0446, Train Acc: 0.9855 | Val Loss: 0.6351, Val Acc: 0.8857, Val F1: 0.8851\n",
            "Training complete. Best Validation Accuracy: 0.8930 at epoch 5.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▆▇▇██▇▇▅▇</td></tr><tr><td>Validation F1</td><td>▁▆▇▇██▇▇▅▇</td></tr><tr><td>Validation Loss</td><td>▃▁▁▁▂▂▃▄▅█</td></tr><tr><td>Validation Precision</td><td>▁▆▇▇██▇▇▅▇</td></tr><tr><td>Validation Recall</td><td>▁▆▇▇██▇▇▅▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.98548</td></tr><tr><td>Train Loss</td><td>0.04455</td></tr><tr><td>Validation Accuracy</td><td>0.88569</td></tr><tr><td>Validation F1</td><td>0.88515</td></tr><tr><td>Validation Loss</td><td>0.63514</td></tr><tr><td>Validation Precision</td><td>0.88659</td></tr><tr><td>Validation Recall</td><td>0.88569</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_10</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/j8010bpv' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/j8010bpv</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_131932-j8010bpv/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 14:00:05,396] Trial 10 finished with value: 0.8929786200194364 and parameters: {'learning_rate': 4.573793651715024e-05, 'weight_decay': 1.4816634476065716e-05, 'patience': 7, 'batch_size': 64, 'num_layers': 5}. Best is trial 10 with value: 0.8929786200194364.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_140005-f0wydukh</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/f0wydukh' target=\"_blank\">trial_11</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/f0wydukh' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/f0wydukh</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 11 for 10 epochs with patience 7...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.5969, Train Acc: 0.7649 | Val Loss: 0.4294, Val Acc: 0.8567, Val F1: 0.8565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.3680, Train Acc: 0.8736 | Val Loss: 0.3943, Val Acc: 0.8663, Val F1: 0.8660\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.2796, Train Acc: 0.9086 | Val Loss: 0.3440, Val Acc: 0.8899, Val F1: 0.8895\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.2132, Train Acc: 0.9322 | Val Loss: 0.3505, Val Acc: 0.8888, Val F1: 0.8889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.1665, Train Acc: 0.9461 | Val Loss: 0.4135, Val Acc: 0.8788, Val F1: 0.8783\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.1297, Train Acc: 0.9596 | Val Loss: 0.4280, Val Acc: 0.8796, Val F1: 0.8799\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.0994, Train Acc: 0.9692 | Val Loss: 0.4661, Val Acc: 0.8818, Val F1: 0.8822\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.0762, Train Acc: 0.9759 | Val Loss: 0.5326, Val Acc: 0.8844, Val F1: 0.8846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.0556, Train Acc: 0.9825 | Val Loss: 0.5344, Val Acc: 0.8876, Val F1: 0.8877\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.0455, Train Acc: 0.9851 | Val Loss: 0.7120, Val Acc: 0.8782, Val F1: 0.8774\n",
            "Training complete. Best Validation Accuracy: 0.8899 at epoch 3.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃██▆▆▆▇█▆</td></tr><tr><td>Validation F1</td><td>▁▃██▆▆▆▇█▅</td></tr><tr><td>Validation Loss</td><td>▃▂▁▁▂▃▃▅▅█</td></tr><tr><td>Validation Precision</td><td>▁▅██▆▆▇▇█▆</td></tr><tr><td>Validation Recall</td><td>▁▃██▆▆▆▇█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.98515</td></tr><tr><td>Train Loss</td><td>0.04548</td></tr><tr><td>Validation Accuracy</td><td>0.87816</td></tr><tr><td>Validation F1</td><td>0.87743</td></tr><tr><td>Validation Loss</td><td>0.71198</td></tr><tr><td>Validation Precision</td><td>0.88228</td></tr><tr><td>Validation Recall</td><td>0.87816</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_11</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/f0wydukh' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/f0wydukh</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_140005-f0wydukh/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 14:40:35,001] Trial 11 finished with value: 0.8899416909620991 and parameters: {'learning_rate': 4.564216024486099e-05, 'weight_decay': 1.4730883832279522e-05, 'patience': 7, 'batch_size': 64, 'num_layers': 5}. Best is trial 10 with value: 0.8929786200194364.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_144035-2ver1owy</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/2ver1owy' target=\"_blank\">trial_12</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/2ver1owy' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/2ver1owy</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for trial 12 for 10 epochs with patience 7...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.6055, Train Acc: 0.7619 | Val Loss: 0.4393, Val Acc: 0.8466, Val F1: 0.8467\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 | Train Loss: 0.3797, Train Acc: 0.8692 | Val Loss: 0.3726, Val Acc: 0.8801, Val F1: 0.8798\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 | Train Loss: 0.2794, Train Acc: 0.9085 | Val Loss: 0.3584, Val Acc: 0.8847, Val F1: 0.8844\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 | Train Loss: 0.2194, Train Acc: 0.9292 | Val Loss: 0.4168, Val Acc: 0.8827, Val F1: 0.8824\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 | Train Loss: 0.1653, Train Acc: 0.9465 | Val Loss: 0.4206, Val Acc: 0.8748, Val F1: 0.8748\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 | Train Loss: 0.1342, Train Acc: 0.9581 | Val Loss: 0.4090, Val Acc: 0.8705, Val F1: 0.8717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 | Train Loss: 0.0999, Train Acc: 0.9675 | Val Loss: 0.4623, Val Acc: 0.8581, Val F1: 0.8598\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 | Train Loss: 0.0746, Train Acc: 0.9764 | Val Loss: 0.4987, Val Acc: 0.8733, Val F1: 0.8736\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 | Train Loss: 0.0531, Train Acc: 0.9834 | Val Loss: 0.5565, Val Acc: 0.8729, Val F1: 0.8737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-667157387.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 | Train Loss: 0.0466, Train Acc: 0.9848 | Val Loss: 0.5700, Val Acc: 0.8677, Val F1: 0.8688\n",
            "Training complete. Best Validation Accuracy: 0.8847 at epoch 3.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▆▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▇██▆▅▃▆▆▅</td></tr><tr><td>Validation F1</td><td>▁▇██▆▆▃▆▆▅</td></tr><tr><td>Validation Loss</td><td>▄▁▁▃▃▃▄▆██</td></tr><tr><td>Validation Precision</td><td>▁▇▇█▆▆▅▆▆▅</td></tr><tr><td>Validation Recall</td><td>▁▇██▆▅▃▆▆▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.98481</td></tr><tr><td>Train Loss</td><td>0.04659</td></tr><tr><td>Validation Accuracy</td><td>0.86771</td></tr><tr><td>Validation F1</td><td>0.86878</td></tr><tr><td>Validation Loss</td><td>0.56998</td></tr><tr><td>Validation Precision</td><td>0.87099</td></tr><tr><td>Validation Recall</td><td>0.86771</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trial_12</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/2ver1owy' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning/runs/2ver1owy</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/distilbert-full-code-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_144035-2ver1owy/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 15:21:04,336] Trial 12 finished with value: 0.8847181729834791 and parameters: {'learning_rate': 4.0020868952852185e-05, 'weight_decay': 1.2822579672245287e-05, 'patience': 7, 'batch_size': 64, 'num_layers': 5}. Best is trial 10 with value: 0.8929786200194364.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Optuna study for DistilBERT complete.\n",
            "Best trial parameters: {'learning_rate': 4.573793651715024e-05, 'weight_decay': 1.4816634476065716e-05, 'patience': 7, 'batch_size': 64, 'num_layers': 5}\n",
            "Best validation accuracy: 0.8929786200194364\n"
          ]
        }
      ],
      "source": [
        "# Optuna Study for DistilBERT\n",
        "print(\"Running Optuna study for DistilBERT 'full code' training...\")\n",
        "study_distilbert_full_code = optuna.create_study(direction=\"maximize\")\n",
        "study_distilbert_full_code.optimize(objective_distilbert_full_code, n_trials=13) # Adjust n_trials as needed\n",
        "print(\"\\nOptuna study for DistilBERT complete.\")\n",
        "print(f\"Best trial parameters: {study_distilbert_full_code.best_trial.params}\")\n",
        "print(f\"Best validation accuracy: {study_distilbert_full_code.best_trial.value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save to drive (checkpoint)\n"
      ],
      "metadata": {
        "id": "73maOwMvtqpr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI7WqtQPtk4n",
        "outputId": "8b73b165-0ee7-429a-d981-09b9f3525d61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best DistilBERT hyperparameters for 'full code' training saved to: /content/drive/MyDrive/ADV_DL/hyperparams/best_distilbert_full_code_hyperparams.json\n"
          ]
        }
      ],
      "source": [
        "# Define the directory and file path to save the hyperparameters\n",
        "HYPERPARAMS_DIR = os.path.join(BASE_DIR, \"hyperparams\")\n",
        "os.makedirs(HYPERPARAMS_DIR, exist_ok=True)\n",
        "BEST_DISTILBERT_PARAMS_FILE = os.path.join(HYPERPARAMS_DIR, \"best_distilbert_full_code_hyperparams.json\")\n",
        "\n",
        "# Extract and save the best parameters from the Optuna study\n",
        "best_params = study_distilbert_full_code.best_trial.params\n",
        "\n",
        "with open(BEST_DISTILBERT_PARAMS_FILE, 'w') as f:\n",
        "    json.dump(best_params, f, indent=4)\n",
        "\n",
        "print(f\"Best DistilBERT hyperparameters for 'full code' training saved to: {BEST_DISTILBERT_PARAMS_FILE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwzD37Omy61Z",
        "outputId": "f843fa08-fd92-4623-f487-a3e80dc937cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading best DistilBERT model state from local path: /content/best_model_trial_10.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DistilBERT model loaded successfully. Now saving to Google Drive...\n",
            "Final fine-tuned DistilBERT 'full code' model and tokenizer saved to: /content/drive/MyDrive/ADV_DL/final_models/distilbert_full_code\n"
          ]
        }
      ],
      "source": [
        "# Define the local temporary directory where Optuna saves the checkpoint\n",
        "LOCAL_DIR = \"/content\"\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/ADV_DL\"\n",
        "\n",
        "# Get the best trial number from the completed DistilBERT study\n",
        "best_trial_number_distilbert = study_distilbert_full_code.best_trial.number\n",
        "\n",
        "# Construct the file paths\n",
        "LOCAL_MODEL_PATH = os.path.join(LOCAL_DIR, f\"best_model_trial_{best_trial_number_distilbert}.pt\")\n",
        "FINAL_MODEL_DIR_DISTILBERT_FULL = os.path.join(BASE_DIR, \"final_models\", \"distilbert_full_code\")\n",
        "\n",
        "# Ensure the final model directory exists\n",
        "os.makedirs(FINAL_MODEL_DIR_DISTILBERT_FULL, exist_ok=True)\n",
        "\n",
        "# --- Load the model from the local directory and save to Google Drive ---\n",
        "\n",
        "print(f\"Loading best DistilBERT model state from local path: {LOCAL_MODEL_PATH}\")\n",
        "\n",
        "try:\n",
        "    best_model_state_dict_distilbert = torch.load(LOCAL_MODEL_PATH)\n",
        "\n",
        "    # Load the DistilBERT model from Hugging Face and apply the state dictionary\n",
        "    best_distilbert_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        \"distilbert-base-uncased\",\n",
        "        num_labels=3\n",
        "    )\n",
        "    best_distilbert_model.load_state_dict(best_model_state_dict_distilbert)\n",
        "    best_distilbert_model.to(device)\n",
        "\n",
        "    print(\"DistilBERT model loaded successfully. Now saving to Google Drive...\")\n",
        "\n",
        "    # Save the model and tokenizer to the dedicated directory in your Drive\n",
        "    best_distilbert_model.save_pretrained(FINAL_MODEL_DIR_DISTILBERT_FULL)\n",
        "\n",
        "    # Load the DistilBERT tokenizer and save it as well\n",
        "    distilbert_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "    distilbert_tokenizer.save_pretrained(FINAL_MODEL_DIR_DISTILBERT_FULL)\n",
        "\n",
        "    print(f\"Final fine-tuned DistilBERT 'full code' model and tokenizer saved to: {FINAL_MODEL_DIR_DISTILBERT_FULL}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{LOCAL_MODEL_PATH}' was not found in the local Colab directory.\")\n",
        "    print(\"Please check the output of your Optuna run to see the exact name of the saved file.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4jh4Pn9jk-O"
      },
      "source": [
        "## Fine-tuning using the Hugging Face libraries as shown in Tutorial 5 (exercise 5):"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build HF Datasets (BERTweet)**\n",
        "\n",
        "- Convert the pre-tokenized BERTweet features and labels into Hugging Face Datasets for the Trainer:\n",
        "\n",
        "- Uses bertweet encodings ['input_ids'/'attention_mask'] and the integer label columns.\n",
        "\n",
        "- Produces hf_train_dataset_bertweet and hf_val_dataset_bertweet with keys: input_ids, attention_mask, labels.\n",
        "\n",
        "- Ensures shapes align so the Trainer can batch/pad and compute metrics correctly."
      ],
      "metadata": {
        "id": "Txhc-G0Pe7RE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njf9iJlKz54i"
      },
      "source": [
        "**BERTweet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WufZpJVeKD9V",
        "outputId": "b41371e5-a560-4285-feac-952a1caf4b2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hugging Face Datasets created successfully.\n"
          ]
        }
      ],
      "source": [
        "# The Trainer expects a Hugging Face Dataset object.\n",
        "# We convert our tokenized encodings and pandas Series to this format.\n",
        "hf_train_dataset_bertweet = HFDataset.from_dict({\n",
        "    'input_ids': bertweet_train_encodings['input_ids'],\n",
        "    'attention_mask': bertweet_train_encodings['attention_mask'],\n",
        "    'labels': train_df_bertweet['label'].tolist()\n",
        "})\n",
        "\n",
        "hf_val_dataset_bertweet = HFDataset.from_dict({\n",
        "    'input_ids': val_bertweet_encodings['input_ids'],\n",
        "    'attention_mask': val_bertweet_encodings['attention_mask'],\n",
        "    'labels': val_df_bertweet['label'].tolist()\n",
        "})\n",
        "\n",
        "print(\"Hugging Face Datasets created successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the accuracy metric using Hugging Face's evaluate library"
      ],
      "metadata": {
        "id": "YcWVJy-qfMW1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXxKiPxojxQg",
        "outputId": "09ecf0fa-a8db-46d4-80a8-fc6ee56daa45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "'compute_metrics' function defined for Hugging Face Trainer.\n"
          ]
        }
      ],
      "source": [
        "metric_accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"\n",
        "    Computes and returns a dictionary of evaluation metrics for the Hugging Face Trainer.\n",
        "    \"\"\"\n",
        "    logits, labels = eval_pred.predictions, eval_pred.label_ids\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    accuracy_result = metric_accuracy.compute(predictions=predictions, references=labels)\n",
        "\n",
        "    # For multi-class classification, we use 'weighted' average to account for label imbalance.\n",
        "    f1_result = f1_score(labels, predictions, average='weighted', zero_division=0)\n",
        "    precision_result = precision_score(labels, predictions, average='weighted', zero_division=0)\n",
        "    recall_result = recall_score(labels, predictions, average='weighted', zero_division=0)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_result[\"accuracy\"],\n",
        "        \"f1\": f1_result,\n",
        "        \"precision\": precision_result,\n",
        "        \"recall\": recall_result\n",
        "    }\n",
        "\n",
        "print(\"\\n'compute_metrics' function defined for Hugging Face Trainer.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xxmkfs6eaRY"
      },
      "source": [
        "**Run without Optuna (Toy Model)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si5cYhvUkDvb",
        "outputId": "0aa89e3e-6f24-4430-bf69-471e2b2ab1be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "TrainingArguments defined.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./hf_trainer_results\",\n",
        "    eval_strategy=\"epoch\",  # Correct parameter name as noted in exercise 5\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    logging_dir=\"./hf_trainer_logs\",\n",
        "    logging_steps=100,\n",
        "    report_to=\"wandb\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    greater_is_better=True,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=1,\n",
        ")\n",
        "\n",
        "print(\"\\nTrainingArguments defined.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "hbVICHUS8-LP",
        "outputId": "65fa429f-b999-4851-a67c-25a1bd5d0d3c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trainer instantiated. Starting fine-tuning with Hugging Face Trainer...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_152113-o7acq427</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/huggingface/runs/o7acq427' target=\"_blank\">honest-pyramid-1</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/huggingface' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/huggingface/runs/o7acq427' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/huggingface/runs/o7acq427</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10290' max='10290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10290/10290 1:43:21, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.344300</td>\n",
              "      <td>0.304442</td>\n",
              "      <td>0.896744</td>\n",
              "      <td>0.896501</td>\n",
              "      <td>0.898723</td>\n",
              "      <td>0.896744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.242800</td>\n",
              "      <td>0.259169</td>\n",
              "      <td>0.914845</td>\n",
              "      <td>0.914563</td>\n",
              "      <td>0.915826</td>\n",
              "      <td>0.914845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.186800</td>\n",
              "      <td>0.277896</td>\n",
              "      <td>0.912172</td>\n",
              "      <td>0.911370</td>\n",
              "      <td>0.914329</td>\n",
              "      <td>0.912172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.149700</td>\n",
              "      <td>0.350257</td>\n",
              "      <td>0.912415</td>\n",
              "      <td>0.912331</td>\n",
              "      <td>0.913527</td>\n",
              "      <td>0.912415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.102800</td>\n",
              "      <td>0.393914</td>\n",
              "      <td>0.911322</td>\n",
              "      <td>0.910740</td>\n",
              "      <td>0.911667</td>\n",
              "      <td>0.911322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.072700</td>\n",
              "      <td>0.411427</td>\n",
              "      <td>0.907920</td>\n",
              "      <td>0.908030</td>\n",
              "      <td>0.908429</td>\n",
              "      <td>0.907920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.076500</td>\n",
              "      <td>0.376641</td>\n",
              "      <td>0.910593</td>\n",
              "      <td>0.910949</td>\n",
              "      <td>0.911524</td>\n",
              "      <td>0.910593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.038200</td>\n",
              "      <td>0.474169</td>\n",
              "      <td>0.910957</td>\n",
              "      <td>0.912062</td>\n",
              "      <td>0.914555</td>\n",
              "      <td>0.910957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.018500</td>\n",
              "      <td>0.555801</td>\n",
              "      <td>0.906706</td>\n",
              "      <td>0.908419</td>\n",
              "      <td>0.912457</td>\n",
              "      <td>0.906706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.009200</td>\n",
              "      <td>0.568262</td>\n",
              "      <td>0.907434</td>\n",
              "      <td>0.909277</td>\n",
              "      <td>0.913800</td>\n",
              "      <td>0.907434</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fine-tuning with Hugging Face Trainer for BERTweet complete.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load the BERTweet model again for this task\n",
        "bertweet_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"vinai/bertweet-base\",\n",
        "    num_labels=3\n",
        ").to(device)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=bertweet_model,\n",
        "    args=training_args,\n",
        "    train_dataset=hf_train_dataset_bertweet,\n",
        "    eval_dataset=hf_val_dataset_bertweet,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"\\nTrainer instantiated. Starting fine-tuning with Hugging Face Trainer...\")\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\nFine-tuning with Hugging Face Trainer for BERTweet complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i091Hph0eWK8"
      },
      "source": [
        "**Run with Optuna**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eV1m8kPXbpvz"
      },
      "outputs": [],
      "source": [
        "# # Make sure you have the 'optuna' and 'wandb' libraries installed and imported.\n",
        "\n",
        "# def objective_hf_trainer(trial):\n",
        "#     # --- 1. Define the Hyperparameter Search Space ---\n",
        "#     learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True)\n",
        "#     per_device_train_batch_size = trial.suggest_categorical(\"per_device_train_batch_size\", [32, 64, 128])\n",
        "#     num_train_epochs = 10\n",
        "\n",
        "#     # --- 2. Initialize W&B for this trial ---\n",
        "#     wandb.init(\n",
        "#         project=\"hf-trainer-tuning\",\n",
        "#         config={\n",
        "#             \"learning_rate\": learning_rate,\n",
        "#             \"per_device_train_batch_size\": per_device_train_batch_size,\n",
        "#             \"num_train_epochs\": num_train_epochs,\n",
        "#             \"architecture\": \"BERTweet\",\n",
        "#             \"tuning_method\": \"Hugging Face Trainer\",\n",
        "#         },\n",
        "#         name=f\"hf-trainer-trial_{trial.number}\",\n",
        "#         reinit=True\n",
        "#     )\n",
        "\n",
        "#     # --- 3. Load Model and Define Trainer ---\n",
        "#     model = AutoModelForSequenceClassification.from_pretrained(\n",
        "#         \"vinai/bertweet-base\",\n",
        "#         num_labels=3\n",
        "#     ).to(device)\n",
        "\n",
        "#     # Define TrainingArguments for this specific trial\n",
        "#     training_args = TrainingArguments(\n",
        "#         output_dir=f\"./hf_trainer_results_trial_{trial.number}\",\n",
        "#         eval_strategy=\"epoch\",\n",
        "#         num_train_epochs=num_train_epochs,\n",
        "#         per_device_train_batch_size=per_device_train_batch_size,\n",
        "#         per_device_eval_batch_size=per_device_train_batch_size, # Use same batch size for eval\n",
        "#         learning_rate=learning_rate,\n",
        "#         report_to=\"wandb\",\n",
        "#         load_best_model_at_end=False,\n",
        "#         metric_for_best_model=\"accuracy\",\n",
        "#         greater_is_better=True,\n",
        "#         save_strategy=\"no\" # No need to save checkpoints during tuning\n",
        "#     )\n",
        "\n",
        "#     trainer = Trainer(\n",
        "#         model=model,\n",
        "#         args=training_args,\n",
        "#         train_dataset=hf_train_dataset_bertweet,\n",
        "#         eval_dataset=hf_val_dataset_bertweet,\n",
        "#         compute_metrics=compute_metrics,\n",
        "#     )\n",
        "\n",
        "#     # --- 4. Run Training and Get Best Metric ---\n",
        "#     trainer.train()\n",
        "#     eval_results = trainer.evaluate()\n",
        "\n",
        "#     # --- 5. Log final results and finish W&B run ---\n",
        "#     wandb.log(eval_results)\n",
        "#     wandb.finish()\n",
        "\n",
        "#     return eval_results[\"eval_accuracy\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "id": "tpyF1SvKnEPh",
        "outputId": "d69f5974-42a6-4d82-e9a8-9e026a1dd81f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 18:25:21,670] A new study created in memory with name: no-name-351e1683-22ba-4fd9-8d2f-a18432a90d00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Optuna study for Hugging Face Trainer...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnogapaz98\u001b[0m (\u001b[33mnogapaz98-tel-aviv-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_182524-4u41k0a5</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/4u41k0a5' target=\"_blank\">hf-trainer-trial_0</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/4u41k0a5' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/4u41k0a5</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='674' max='5150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 674/5150 11:46 < 1:18:27, 0.95 it/s, Epoch 1.31/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.666700</td>\n",
              "      <td>0.432996</td>\n",
              "      <td>0.845360</td>\n",
              "      <td>0.844243</td>\n",
              "      <td>0.845488</td>\n",
              "      <td>0.845360</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W 2025-08-18 18:37:17,170] Trial 0 failed with parameters: {'learning_rate': 1.5043780233477805e-05, 'per_device_train_batch_size': 64} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-1881323687.py\", line 53, in objective_hf_trainer\n",
            "    trainer.train()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2238, in train\n",
            "    return inner_training_loop(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2587, in _inner_training_loop\n",
            "    and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step))\n",
            "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "[W 2025-08-18 18:37:17,173] Trial 0 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3379745597.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running Optuna study for Hugging Face Trainer...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstudy_hf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mstudy_hf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_hf_trainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nOptuna study complete.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Best trial parameters: {study_hf.best_trial.params}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \"\"\"\n\u001b[0;32m--> 490\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    491\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     ):\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1881323687.py\u001b[0m in \u001b[0;36mobjective_hf_trainer\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# --- 4. Run Training and Get Best Metric ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2236\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2238\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2239\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2240\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2585\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2586\u001b[0m                         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2587\u001b[0;31m                         \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2588\u001b[0m                     ):\n\u001b[1;32m   2589\u001b[0m                         \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# # --- 6. Run the Optuna study ---\n",
        "# print(\"Running Optuna study for Hugging Face Trainer...\")\n",
        "# study_hf = optuna.create_study(direction=\"maximize\")\n",
        "# study_hf.optimize(objective_hf_trainer, n_trials=13)\n",
        "# print(\"\\nOptuna study complete.\")\n",
        "# print(f\"Best trial parameters: {study_hf.best_trial.params}\")\n",
        "# print(f\"Best validation accuracy: {study_hf.best_trial.value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1y2vf0_eRRm"
      },
      "source": [
        "We saw that only the first epoch of the first trial took 10 minutes- which means 21 hours - which we don't have. Therefore, we decided to reduce the number of trials.\n",
        "\n",
        "**Why Reduce Number of Trials and Not Epochs:**\n",
        "\n",
        "The primary goal of hyperparameter tuning with Optuna is to find the best combination of parameters by exploring a range of options. Each trial represents a complete training and evaluation cycle for a different set of hyperparameters.\n",
        "\n",
        "\n",
        "We don't want to reduce the number of epochs cause each epoch is valuable: The validation accuracy usually improves over the first few epochs and then either plateaus or decreases due to overfitting. Reducing the number of epochs might cause the model to stop training before it reaches its best possible performance for that specific trial's hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sBQWVkw7e4Gn",
        "outputId": "62f245dd-c7ca-4e4e-aa44-80f3e9f8f494"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 19:14:29,148] A new study created in memory with name: no-name-0fde3732-dcb7-420a-ab40-474e68a74fda\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Optuna study for Hugging Face Trainer...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to True."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇█</td></tr><tr><td>eval/f1</td><td>▁▇█</td></tr><tr><td>eval/loss</td><td>█▁▂</td></tr><tr><td>eval/precision</td><td>▁▆█</td></tr><tr><td>eval/recall</td><td>▁▇█</td></tr><tr><td>eval/runtime</td><td>▁█▃</td></tr><tr><td>eval/samples_per_second</td><td>█▁▆</td></tr><tr><td>eval/steps_per_second</td><td>█▁▆</td></tr><tr><td>train/epoch</td><td>▁▁▄▅██</td></tr><tr><td>train/global_step</td><td>▁▁▄▅██</td></tr><tr><td>train/grad_norm</td><td>▄▁█</td></tr><tr><td>train/learning_rate</td><td>█▅▁</td></tr><tr><td>train/loss</td><td>█▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.9044</td></tr><tr><td>eval/f1</td><td>0.90429</td></tr><tr><td>eval/loss</td><td>0.29503</td></tr><tr><td>eval/precision</td><td>0.90934</td></tr><tr><td>eval/recall</td><td>0.9044</td></tr><tr><td>eval/runtime</td><td>41.858</td></tr><tr><td>eval/samples_per_second</td><td>196.665</td></tr><tr><td>eval/steps_per_second</td><td>3.082</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>1545</td></tr><tr><td>train/grad_norm</td><td>8.28859</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.206</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">hf-trainer-trial_0</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/fiq0qgra' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/fiq0qgra</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_184154-fiq0qgra/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_191429-j16ftebx</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/j16ftebx' target=\"_blank\">hf-trainer-trial_0</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/j16ftebx' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/j16ftebx</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10290' max='10290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10290/10290 1:38:19, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.486700</td>\n",
              "      <td>0.410059</td>\n",
              "      <td>0.859572</td>\n",
              "      <td>0.858653</td>\n",
              "      <td>0.861277</td>\n",
              "      <td>0.859572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.332400</td>\n",
              "      <td>0.326695</td>\n",
              "      <td>0.889820</td>\n",
              "      <td>0.889074</td>\n",
              "      <td>0.891537</td>\n",
              "      <td>0.889820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.243000</td>\n",
              "      <td>0.305537</td>\n",
              "      <td>0.901603</td>\n",
              "      <td>0.901149</td>\n",
              "      <td>0.902521</td>\n",
              "      <td>0.901603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.193100</td>\n",
              "      <td>0.325957</td>\n",
              "      <td>0.905491</td>\n",
              "      <td>0.905162</td>\n",
              "      <td>0.908929</td>\n",
              "      <td>0.905491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.159100</td>\n",
              "      <td>0.349931</td>\n",
              "      <td>0.908649</td>\n",
              "      <td>0.907966</td>\n",
              "      <td>0.910490</td>\n",
              "      <td>0.908649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.134100</td>\n",
              "      <td>0.326383</td>\n",
              "      <td>0.907920</td>\n",
              "      <td>0.907803</td>\n",
              "      <td>0.908215</td>\n",
              "      <td>0.907920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.110200</td>\n",
              "      <td>0.358598</td>\n",
              "      <td>0.906220</td>\n",
              "      <td>0.905855</td>\n",
              "      <td>0.905770</td>\n",
              "      <td>0.906220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.091200</td>\n",
              "      <td>0.407272</td>\n",
              "      <td>0.906341</td>\n",
              "      <td>0.906130</td>\n",
              "      <td>0.905989</td>\n",
              "      <td>0.906341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.087300</td>\n",
              "      <td>0.409956</td>\n",
              "      <td>0.906341</td>\n",
              "      <td>0.906459</td>\n",
              "      <td>0.906767</td>\n",
              "      <td>0.906341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.071800</td>\n",
              "      <td>0.428130</td>\n",
              "      <td>0.907070</td>\n",
              "      <td>0.907088</td>\n",
              "      <td>0.907186</td>\n",
              "      <td>0.907070</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='258' max='258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [258/258 00:41]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/accuracy</td><td>▁▅▇████████</td></tr><tr><td>eval/f1</td><td>▁▅▇████████</td></tr><tr><td>eval/loss</td><td>▇▂▁▂▄▂▄▇▇██</td></tr><tr><td>eval/precision</td><td>▁▅▇███▇▇▇██</td></tr><tr><td>eval/recall</td><td>▁▅▇████████</td></tr><tr><td>eval/runtime</td><td>▅▁█▆▃▅▅██▅▁</td></tr><tr><td>eval/samples_per_second</td><td>▄█▁▃▆▄▄▁▁▄█</td></tr><tr><td>eval/steps_per_second</td><td>▄█▂▃▆▄▄▁▁▄█</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>▅▄▆▄▆▄▃▄▁▇█▁▂▄▂▅▁▂▁▂</td></tr><tr><td>train/learning_rate</td><td>██▇▇▇▆▆▅▅▅▄▄▄▃▃▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▅▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>eval/accuracy</td><td>0.90707</td></tr><tr><td>eval/f1</td><td>0.90709</td></tr><tr><td>eval/loss</td><td>0.42813</td></tr><tr><td>eval/precision</td><td>0.90719</td></tr><tr><td>eval/recall</td><td>0.90707</td></tr><tr><td>eval/runtime</td><td>42.1929</td></tr><tr><td>eval/samples_per_second</td><td>195.104</td></tr><tr><td>eval/steps_per_second</td><td>6.115</td></tr><tr><td>eval_accuracy</td><td>0.90707</td></tr><tr><td>eval_f1</td><td>0.90709</td></tr><tr><td>eval_loss</td><td>0.42813</td></tr><tr><td>eval_precision</td><td>0.90719</td></tr><tr><td>eval_recall</td><td>0.90707</td></tr><tr><td>eval_runtime</td><td>42.1929</td></tr><tr><td>eval_samples_per_second</td><td>195.104</td></tr><tr><td>eval_steps_per_second</td><td>6.115</td></tr><tr><td>total_flos</td><td>1.70891393974245e+16</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>10290</td></tr><tr><td>train/grad_norm</td><td>1.99088</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0718</td></tr><tr><td>train_loss</td><td>0.20495</td></tr><tr><td>train_runtime</td><td>5899.6968</td></tr><tr><td>train_samples_per_second</td><td>55.808</td></tr><tr><td>train_steps_per_second</td><td>1.744</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">hf-trainer-trial_0</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/j16ftebx' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/j16ftebx</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_191429-j16ftebx/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 20:53:39,700] Trial 0 finished with value: 0.907069970845481 and parameters: {'learning_rate': 1.304929253756308e-05, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 0.907069970845481.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_205339-rkpvzli5</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/rkpvzli5' target=\"_blank\">hf-trainer-trial_1</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/rkpvzli5' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/rkpvzli5</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='773' max='5150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 773/5150 13:36 < 1:17:15, 0.94 it/s, Epoch 1.50/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.541800</td>\n",
              "      <td>0.347225</td>\n",
              "      <td>0.878401</td>\n",
              "      <td>0.878417</td>\n",
              "      <td>0.886355</td>\n",
              "      <td>0.878401</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# # --- 6. Run the Optuna study ---\n",
        "# print(\"Running Optuna study for Hugging Face Trainer...\")\n",
        "# study_hf = optuna.create_study(direction=\"maximize\")\n",
        "# study_hf.optimize(objective_hf_trainer, n_trials=3)\n",
        "# print(\"\\nOptuna study complete.\")\n",
        "# print(f\"Best trial parameters: {study_hf.best_trial.params}\")\n",
        "# print(f\"Best validation accuracy: {study_hf.best_trial.value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0vXkWQdCMmy"
      },
      "source": [
        "The runtime stopped in the middle after 2 hours running. We will also remove the batch size option of 32 to make it run faster:\n",
        "\n",
        "A larger batch size processes more data at once, which reduces the total number of training steps required per epoch, leading to a faster overall training process. By removing 32, the Optuna trials will only run with batch sizes of 64 and 128, which will be significantly faster on average."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igcpDV2YCEbu"
      },
      "outputs": [],
      "source": [
        "def objective_hf_trainer(trial):\n",
        "    # --- 1. Define the Hyperparameter Search Space ---\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True)\n",
        "    per_device_train_batch_size = trial.suggest_categorical(\"per_device_train_batch_size\", [ 64, 128])\n",
        "    num_train_epochs = 10\n",
        "\n",
        "    # --- 2. Initialize W&B for this trial ---\n",
        "    wandb.init(\n",
        "        project=\"hf-trainer-tuning\",\n",
        "        config={\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"per_device_train_batch_size\": per_device_train_batch_size,\n",
        "            \"num_train_epochs\": num_train_epochs,\n",
        "            \"architecture\": \"BERTweet\",\n",
        "            \"tuning_method\": \"Hugging Face Trainer\",\n",
        "        },\n",
        "        name=f\"hf-trainer-trial_{trial.number}\",\n",
        "        reinit=True\n",
        "    )\n",
        "\n",
        "    # --- 3. Load Model and Define Trainer ---\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        \"vinai/bertweet-base\",\n",
        "        num_labels=3\n",
        "    ).to(device)\n",
        "\n",
        "    # Define TrainingArguments for this specific trial\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./hf_trainer_results_trial_{trial.number}\",\n",
        "        eval_strategy=\"epoch\",\n",
        "        num_train_epochs=num_train_epochs,\n",
        "        per_device_train_batch_size=per_device_train_batch_size,\n",
        "        per_device_eval_batch_size=per_device_train_batch_size, # Use same batch size for eval\n",
        "        learning_rate=learning_rate,\n",
        "        report_to=\"wandb\",\n",
        "        load_best_model_at_end=False,\n",
        "        metric_for_best_model=\"accuracy\",\n",
        "        greater_is_better=True,\n",
        "        save_strategy=\"no\" # No need to save checkpoints during tuning\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=hf_train_dataset_bertweet,\n",
        "        eval_dataset=hf_val_dataset_bertweet,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    # --- 4. Run Training and Get Best Metric ---\n",
        "    trainer.train()\n",
        "    eval_results = trainer.evaluate()\n",
        "\n",
        "    # --- 5. Log final results and finish W&B run ---\n",
        "    wandb.log(eval_results)\n",
        "    wandb.finish()\n",
        "\n",
        "    return eval_results[\"eval_accuracy\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NEnkmKQAB7LA",
        "outputId": "b8d3e494-43ee-4d1a-eab4-1c42d1abbd01"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 21:36:00,031] A new study created in memory with name: no-name-8c753201-8a8b-4f2a-8002-6b342c55b78c\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Optuna study for Hugging Face Trainer...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to True."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">hf-trainer-trial_0</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/onxzvqmi' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/onxzvqmi</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_213442-onxzvqmi/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_213600-fsigsv2t</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/fsigsv2t' target=\"_blank\">hf-trainer-trial_0</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/fsigsv2t' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/fsigsv2t</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2580/2580 1:31:10, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.575535</td>\n",
              "      <td>0.783406</td>\n",
              "      <td>0.781666</td>\n",
              "      <td>0.791918</td>\n",
              "      <td>0.783406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.620200</td>\n",
              "      <td>0.416345</td>\n",
              "      <td>0.851919</td>\n",
              "      <td>0.849919</td>\n",
              "      <td>0.853697</td>\n",
              "      <td>0.851919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.620200</td>\n",
              "      <td>0.383118</td>\n",
              "      <td>0.869534</td>\n",
              "      <td>0.869151</td>\n",
              "      <td>0.873252</td>\n",
              "      <td>0.869534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.318300</td>\n",
              "      <td>0.339404</td>\n",
              "      <td>0.887998</td>\n",
              "      <td>0.887452</td>\n",
              "      <td>0.889948</td>\n",
              "      <td>0.887998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.318300</td>\n",
              "      <td>0.332991</td>\n",
              "      <td>0.895773</td>\n",
              "      <td>0.894845</td>\n",
              "      <td>0.896784</td>\n",
              "      <td>0.895773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.224200</td>\n",
              "      <td>0.319206</td>\n",
              "      <td>0.903912</td>\n",
              "      <td>0.903327</td>\n",
              "      <td>0.904006</td>\n",
              "      <td>0.903912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.224200</td>\n",
              "      <td>0.336659</td>\n",
              "      <td>0.900024</td>\n",
              "      <td>0.899314</td>\n",
              "      <td>0.902663</td>\n",
              "      <td>0.900024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.173000</td>\n",
              "      <td>0.334623</td>\n",
              "      <td>0.904519</td>\n",
              "      <td>0.903962</td>\n",
              "      <td>0.904591</td>\n",
              "      <td>0.904519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.173000</td>\n",
              "      <td>0.338253</td>\n",
              "      <td>0.903183</td>\n",
              "      <td>0.902376</td>\n",
              "      <td>0.903551</td>\n",
              "      <td>0.903183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.145500</td>\n",
              "      <td>0.342578</td>\n",
              "      <td>0.904033</td>\n",
              "      <td>0.903355</td>\n",
              "      <td>0.904424</td>\n",
              "      <td>0.904033</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [65/65 00:41]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/accuracy</td><td>▁▅▆▇▇██████</td></tr><tr><td>eval/f1</td><td>▁▅▆▇▇██████</td></tr><tr><td>eval/loss</td><td>█▄▃▂▁▁▁▁▂▂▂</td></tr><tr><td>eval/precision</td><td>▁▅▆▇███████</td></tr><tr><td>eval/recall</td><td>▁▅▆▇▇██████</td></tr><tr><td>eval/runtime</td><td>▇▅▄▄▄▂▆▅▃█▁</td></tr><tr><td>eval/samples_per_second</td><td>▂▄▅▅▅▇▃▄▆▁█</td></tr><tr><td>eval/steps_per_second</td><td>▂▄▅▅▅▇▃▄▆▁█</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▃▃▄▅▅▆▆▆▇████</td></tr><tr><td>train/global_step</td><td>▁▂▂▃▃▃▄▅▅▆▆▆▇█████</td></tr><tr><td>train/grad_norm</td><td>▁▃▃▄█</td></tr><tr><td>train/learning_rate</td><td>█▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▄▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>eval/accuracy</td><td>0.90403</td></tr><tr><td>eval/f1</td><td>0.90335</td></tr><tr><td>eval/loss</td><td>0.34258</td></tr><tr><td>eval/precision</td><td>0.90442</td></tr><tr><td>eval/recall</td><td>0.90403</td></tr><tr><td>eval/runtime</td><td>42.2221</td></tr><tr><td>eval/samples_per_second</td><td>194.969</td></tr><tr><td>eval/steps_per_second</td><td>1.539</td></tr><tr><td>eval_accuracy</td><td>0.90403</td></tr><tr><td>eval_f1</td><td>0.90335</td></tr><tr><td>eval_loss</td><td>0.34258</td></tr><tr><td>eval_precision</td><td>0.90442</td></tr><tr><td>eval_recall</td><td>0.90403</td></tr><tr><td>eval_runtime</td><td>42.2221</td></tr><tr><td>eval_samples_per_second</td><td>194.969</td></tr><tr><td>eval_steps_per_second</td><td>1.539</td></tr><tr><td>total_flos</td><td>1.70891393974245e+16</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>2580</td></tr><tr><td>train/grad_norm</td><td>8.66444</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1455</td></tr><tr><td>train_loss</td><td>0.29114</td></tr><tr><td>train_runtime</td><td>5472.527</td></tr><tr><td>train_samples_per_second</td><td>60.164</td></tr><tr><td>train_steps_per_second</td><td>0.471</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">hf-trainer-trial_0</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/fsigsv2t' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/fsigsv2t</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_213600-fsigsv2t/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-18 23:07:58,780] Trial 0 finished with value: 0.9040330417881438 and parameters: {'learning_rate': 1.383021013359748e-05, 'per_device_train_batch_size': 128}. Best is trial 0 with value: 0.9040330417881438.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250818_230758-digefkhl</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/digefkhl' target=\"_blank\">hf-trainer-trial_1</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/digefkhl' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/digefkhl</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2580/2580 1:31:08, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.607853</td>\n",
              "      <td>0.763848</td>\n",
              "      <td>0.761321</td>\n",
              "      <td>0.765609</td>\n",
              "      <td>0.763848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.662000</td>\n",
              "      <td>0.435008</td>\n",
              "      <td>0.841958</td>\n",
              "      <td>0.838329</td>\n",
              "      <td>0.847508</td>\n",
              "      <td>0.841958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.662000</td>\n",
              "      <td>0.367859</td>\n",
              "      <td>0.875850</td>\n",
              "      <td>0.875017</td>\n",
              "      <td>0.877914</td>\n",
              "      <td>0.875850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.331900</td>\n",
              "      <td>0.326616</td>\n",
              "      <td>0.892979</td>\n",
              "      <td>0.892439</td>\n",
              "      <td>0.893186</td>\n",
              "      <td>0.892979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.331900</td>\n",
              "      <td>0.329258</td>\n",
              "      <td>0.894315</td>\n",
              "      <td>0.893359</td>\n",
              "      <td>0.895357</td>\n",
              "      <td>0.894315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.236800</td>\n",
              "      <td>0.317731</td>\n",
              "      <td>0.900024</td>\n",
              "      <td>0.899353</td>\n",
              "      <td>0.900291</td>\n",
              "      <td>0.900024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.236800</td>\n",
              "      <td>0.327384</td>\n",
              "      <td>0.900510</td>\n",
              "      <td>0.899775</td>\n",
              "      <td>0.902731</td>\n",
              "      <td>0.900510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.182900</td>\n",
              "      <td>0.325752</td>\n",
              "      <td>0.902940</td>\n",
              "      <td>0.902108</td>\n",
              "      <td>0.903363</td>\n",
              "      <td>0.902940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.182900</td>\n",
              "      <td>0.330959</td>\n",
              "      <td>0.904640</td>\n",
              "      <td>0.903914</td>\n",
              "      <td>0.905036</td>\n",
              "      <td>0.904640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.154200</td>\n",
              "      <td>0.339136</td>\n",
              "      <td>0.903183</td>\n",
              "      <td>0.902309</td>\n",
              "      <td>0.903965</td>\n",
              "      <td>0.903183</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [65/65 00:41]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/accuracy</td><td>▁▅▇▇▇██████</td></tr><tr><td>eval/f1</td><td>▁▅▇▇▇██████</td></tr><tr><td>eval/loss</td><td>█▄▂▁▁▁▁▁▁▂▂</td></tr><tr><td>eval/precision</td><td>▁▅▇▇███████</td></tr><tr><td>eval/recall</td><td>▁▅▇▇▇██████</td></tr><tr><td>eval/runtime</td><td>▅▁█▁▂▁▄▂▄▅▇</td></tr><tr><td>eval/samples_per_second</td><td>▄█▁█▇█▅▇▅▄▂</td></tr><tr><td>eval/steps_per_second</td><td>▅█▁█▇█▅▇▅▅▂</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▃▃▄▅▅▆▆▆▇████</td></tr><tr><td>train/global_step</td><td>▁▂▂▃▃▃▄▅▅▆▆▆▇█████</td></tr><tr><td>train/grad_norm</td><td>▃▆▁█▆</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>eval/accuracy</td><td>0.90318</td></tr><tr><td>eval/f1</td><td>0.90231</td></tr><tr><td>eval/loss</td><td>0.33914</td></tr><tr><td>eval/precision</td><td>0.90396</td></tr><tr><td>eval/recall</td><td>0.90318</td></tr><tr><td>eval/runtime</td><td>42.4122</td></tr><tr><td>eval/samples_per_second</td><td>194.095</td></tr><tr><td>eval/steps_per_second</td><td>1.533</td></tr><tr><td>eval_accuracy</td><td>0.90318</td></tr><tr><td>eval_f1</td><td>0.90231</td></tr><tr><td>eval_loss</td><td>0.33914</td></tr><tr><td>eval_precision</td><td>0.90396</td></tr><tr><td>eval_recall</td><td>0.90318</td></tr><tr><td>eval_runtime</td><td>42.4122</td></tr><tr><td>eval_samples_per_second</td><td>194.095</td></tr><tr><td>eval_steps_per_second</td><td>1.533</td></tr><tr><td>total_flos</td><td>1.70891393974245e+16</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>2580</td></tr><tr><td>train/grad_norm</td><td>5.04015</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1542</td></tr><tr><td>train_loss</td><td>0.30833</td></tr><tr><td>train_runtime</td><td>5470.5937</td></tr><tr><td>train_samples_per_second</td><td>60.185</td></tr><tr><td>train_steps_per_second</td><td>0.472</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">hf-trainer-trial_1</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/digefkhl' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/digefkhl</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250818_230758-digefkhl/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-19 00:39:55,451] Trial 1 finished with value: 0.9031827016520894 and parameters: {'learning_rate': 1.2649740817992602e-05, 'per_device_train_batch_size': 128}. Best is trial 0 with value: 0.9040330417881438.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250819_003955-jll8x6pc</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/jll8x6pc' target=\"_blank\">hf-trainer-trial_2</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/jll8x6pc' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/jll8x6pc</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5150' max='5150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5150/5150 1:34:17, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.536300</td>\n",
              "      <td>0.327733</td>\n",
              "      <td>0.890792</td>\n",
              "      <td>0.890579</td>\n",
              "      <td>0.893384</td>\n",
              "      <td>0.890792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.267300</td>\n",
              "      <td>0.275678</td>\n",
              "      <td>0.909378</td>\n",
              "      <td>0.908935</td>\n",
              "      <td>0.912806</td>\n",
              "      <td>0.909378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.177300</td>\n",
              "      <td>0.266215</td>\n",
              "      <td>0.919218</td>\n",
              "      <td>0.918506</td>\n",
              "      <td>0.920159</td>\n",
              "      <td>0.919218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.126400</td>\n",
              "      <td>0.266900</td>\n",
              "      <td>0.917153</td>\n",
              "      <td>0.917771</td>\n",
              "      <td>0.919094</td>\n",
              "      <td>0.917153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.099500</td>\n",
              "      <td>0.289135</td>\n",
              "      <td>0.922255</td>\n",
              "      <td>0.921885</td>\n",
              "      <td>0.923120</td>\n",
              "      <td>0.922255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.076800</td>\n",
              "      <td>0.304069</td>\n",
              "      <td>0.917881</td>\n",
              "      <td>0.918094</td>\n",
              "      <td>0.918589</td>\n",
              "      <td>0.917881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.054800</td>\n",
              "      <td>0.364325</td>\n",
              "      <td>0.918003</td>\n",
              "      <td>0.918084</td>\n",
              "      <td>0.918483</td>\n",
              "      <td>0.918003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.040700</td>\n",
              "      <td>0.400726</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.917217</td>\n",
              "      <td>0.918191</td>\n",
              "      <td>0.916667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.026100</td>\n",
              "      <td>0.476065</td>\n",
              "      <td>0.913387</td>\n",
              "      <td>0.914322</td>\n",
              "      <td>0.916286</td>\n",
              "      <td>0.913387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.017100</td>\n",
              "      <td>0.467258</td>\n",
              "      <td>0.918246</td>\n",
              "      <td>0.919007</td>\n",
              "      <td>0.920516</td>\n",
              "      <td>0.918246</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:42]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/accuracy</td><td>▁▅▇▇█▇▇▇▆▇▇</td></tr><tr><td>eval/f1</td><td>▁▅▇▇█▇▇▇▆▇▇</td></tr><tr><td>eval/loss</td><td>▃▁▁▁▂▂▄▅███</td></tr><tr><td>eval/precision</td><td>▁▆▇▇█▇▇▇▆▇▇</td></tr><tr><td>eval/recall</td><td>▁▅▇▇█▇▇▇▆▇▇</td></tr><tr><td>eval/runtime</td><td>▄▄█▅▄▁▆▄▆▅▅</td></tr><tr><td>eval/samples_per_second</td><td>▅▅▁▄▅█▃▅▃▄▄</td></tr><tr><td>eval/steps_per_second</td><td>▅▅▁▃▅█▃▅▃▃▄</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/grad_norm</td><td>▄▇▅▄▂█▅▃▂▁</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▄▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>eval/accuracy</td><td>0.91825</td></tr><tr><td>eval/f1</td><td>0.91901</td></tr><tr><td>eval/loss</td><td>0.46726</td></tr><tr><td>eval/precision</td><td>0.92052</td></tr><tr><td>eval/recall</td><td>0.91825</td></tr><tr><td>eval/runtime</td><td>43.1484</td></tr><tr><td>eval/samples_per_second</td><td>190.783</td></tr><tr><td>eval/steps_per_second</td><td>2.99</td></tr><tr><td>eval_accuracy</td><td>0.91825</td></tr><tr><td>eval_f1</td><td>0.91901</td></tr><tr><td>eval_loss</td><td>0.46726</td></tr><tr><td>eval_precision</td><td>0.92052</td></tr><tr><td>eval_recall</td><td>0.91825</td></tr><tr><td>eval_runtime</td><td>43.1484</td></tr><tr><td>eval_samples_per_second</td><td>190.783</td></tr><tr><td>eval_steps_per_second</td><td>2.99</td></tr><tr><td>total_flos</td><td>1.70891393974245e+16</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>5150</td></tr><tr><td>train/grad_norm</td><td>1.34002</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0171</td></tr><tr><td>train_loss</td><td>0.13845</td></tr><tr><td>train_runtime</td><td>5658.046</td></tr><tr><td>train_samples_per_second</td><td>58.191</td></tr><tr><td>train_steps_per_second</td><td>0.91</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">hf-trainer-trial_2</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/jll8x6pc' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning/runs/jll8x6pc</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250819_003955-jll8x6pc/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-19 02:15:00,013] Trial 2 finished with value: 0.918245869776482 and parameters: {'learning_rate': 4.899898884731738e-05, 'per_device_train_batch_size': 64}. Best is trial 2 with value: 0.918245869776482.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Optuna study complete.\n",
            "Best trial parameters: {'learning_rate': 4.899898884731738e-05, 'per_device_train_batch_size': 64}\n",
            "Best validation accuracy: 0.918245869776482\n"
          ]
        }
      ],
      "source": [
        "# --- 6. Run the Optuna study ---\n",
        "print(\"Running Optuna study for Hugging Face Trainer...\")\n",
        "study_hf = optuna.create_study(direction=\"maximize\")\n",
        "study_hf.optimize(objective_hf_trainer, n_trials=3)\n",
        "print(\"\\nOptuna study complete.\")\n",
        "print(f\"Best trial parameters: {study_hf.best_trial.params}\")\n",
        "print(f\"Best validation accuracy: {study_hf.best_trial.value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save to drive (checkpoint)\n",
        "\n",
        "*Note: We accidentely ran the cells again after runtime has disconnected- so we got an error.\n",
        "We leave these cells so you see we saved it and also so you could run it if running the train again."
      ],
      "metadata": {
        "id": "G9PlmwJIuTwi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "MQ8TKERproeW",
        "outputId": "c59a9485-3ed6-4824-d830-5ca0f5d19e4a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'study_hf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3324139040.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Extract and save the best parameters from the Optuna study\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mbest_params_bertweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy_hf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBEST_BERTWEET_PARAMS_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'study_hf' is not defined"
          ]
        }
      ],
      "source": [
        "# Define the directory to save the hyperparameters file\n",
        "HYPERPARAMS_DIR = os.path.join(BASE_DIR, \"hyperparams\")\n",
        "os.makedirs(HYPERPARAMS_DIR, exist_ok=True)\n",
        "BEST_BERTWEET_PARAMS_FILE = os.path.join(HYPERPARAMS_DIR, \"best_bertweet_hyperparams.json\")\n",
        "\n",
        "# Extract and save the best parameters from the Optuna study\n",
        "best_params_bertweet = study_hf.best_trial.params\n",
        "\n",
        "with open(BEST_BERTWEET_PARAMS_FILE, 'w') as f:\n",
        "    json.dump(best_params_bertweet, f, indent=4)\n",
        "\n",
        "print(f\"Best BERTweet hyperparameters saved to: {BEST_BERTWEET_PARAMS_FILE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "o3vJzKwPxO1a",
        "outputId": "6e3fab55-1316-4725-c561-9e85761dc9cc"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'final_trainer_bertweet' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2266423097.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Save the model and tokenizer to a directory in your Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfinal_trainer_bertweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFINAL_MODEL_DIR_BERTWEET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mbertweet_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFINAL_MODEL_DIR_BERTWEET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'final_trainer_bertweet' is not defined"
          ]
        }
      ],
      "source": [
        "FINAL_MODEL_DIR_BERTWEET = os.path.join(BASE_DIR, \"final_models\", \"bertweet\")\n",
        "\n",
        "# Save the model and tokenizer to a directory in your Drive\n",
        "final_trainer_bertweet.save_model(FINAL_MODEL_DIR_BERTWEET)\n",
        "bertweet_tokenizer.save_pretrained(FINAL_MODEL_DIR_BERTWEET)\n",
        "\n",
        "print(f\"Final fine-tuned BERTweet model saved to: {FINAL_MODEL_DIR_BERTWEET}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHU57Z61kdZ5"
      },
      "source": [
        "The saving didn't work (the runtime disconnected in the middle). We will test the reslts of each model and compare between them. Then, we will choose the best 2 models and compress them.\n",
        "If this model (BERTweet finetuned with HF) is one of the best models- we will extract the best parameters and will fine tune it with the best parameters again (it saved only the hyperparametes and disconnected at the next cell)- then we will save it and can use it later to compress it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omkyz4Tq0APY"
      },
      "source": [
        "**DistilBERT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3YdMhovwd7C",
        "outputId": "f89c49e5-a872-44a8-f51f-7b1d2d06b936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hugging Face Datasets created successfully for DistilBERT.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# The Trainer expects a Hugging Face Dataset object.\n",
        "# We convert our tokenized encodings and pandas Series to this format.\n",
        "hf_train_dataset_distilbert = HFDataset.from_dict({\n",
        "    'input_ids': distilbert_train_encodings['input_ids'],\n",
        "    'attention_mask': distilbert_train_encodings['attention_mask'],\n",
        "    'labels': train_df_distilbert['label'].tolist()\n",
        "})\n",
        "\n",
        "hf_val_dataset_distilbert = HFDataset.from_dict({\n",
        "    'input_ids': val_distilbert_encodings['input_ids'],\n",
        "    'attention_mask': val_distilbert_encodings['attention_mask'],\n",
        "    'labels': val_df_distilbert['label'].tolist()\n",
        "})\n",
        "\n",
        "print(\"Hugging Face Datasets created successfully for DistilBERT.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYGD5JnZQ4pz"
      },
      "source": [
        "Finetune without using Optuna (Toy Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "EOFMkLhmQ4Vs",
        "outputId": "374f29c2-ee0b-44c7-bd6a-f44ceb765faf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting DistilBERT fine-tuning (HF Trainer)...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250819_090312-432jdq9i</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/huggingface/runs/432jdq9i' target=\"_blank\">firm-bush-2</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/huggingface' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/huggingface/runs/432jdq9i' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/huggingface/runs/432jdq9i</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4116' max='4116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4116/4116 21:05, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.338300</td>\n",
              "      <td>0.303833</td>\n",
              "      <td>0.895408</td>\n",
              "      <td>0.894866</td>\n",
              "      <td>0.895983</td>\n",
              "      <td>0.895408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.238500</td>\n",
              "      <td>0.279941</td>\n",
              "      <td>0.909864</td>\n",
              "      <td>0.909025</td>\n",
              "      <td>0.911076</td>\n",
              "      <td>0.909864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.139600</td>\n",
              "      <td>0.305041</td>\n",
              "      <td>0.909985</td>\n",
              "      <td>0.909622</td>\n",
              "      <td>0.911400</td>\n",
              "      <td>0.909985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.102200</td>\n",
              "      <td>0.337910</td>\n",
              "      <td>0.913508</td>\n",
              "      <td>0.913638</td>\n",
              "      <td>0.913794</td>\n",
              "      <td>0.913508</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='258' max='258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [258/258 00:22]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Done. DistilBERT eval: {'eval_loss': 0.3379097878932953, 'eval_accuracy': 0.9135082604470359, 'eval_f1': 0.9136380881194262, 'eval_precision': 0.9137941173387312, 'eval_recall': 0.9135082604470359, 'eval_runtime': 22.2874, 'eval_samples_per_second': 369.356, 'eval_steps_per_second': 11.576, 'epoch': 4.0}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./hf_trainer_results_distilbert\",\n",
        "    eval_strategy=\"epoch\",              # <-- older versions expect this\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    logging_dir=\"./hf_trainer_logs_distilbert\",\n",
        "    logging_steps=100,\n",
        "    report_to=\"wandb\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    greater_is_better=True,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=1,\n",
        ")\n",
        "\n",
        "distilbert_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\",\n",
        "    num_labels=NUM_LABELS\n",
        ").to(device)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=distilbert_model,\n",
        "    args=training_args,\n",
        "    train_dataset=hf_train_dataset_distilbert,\n",
        "    eval_dataset=hf_val_dataset_distilbert,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"\\nStarting DistilBERT fine-tuning (HF Trainer)...\")\n",
        "trainer.train()\n",
        "print(\"\\nDone. DistilBERT eval:\", trainer.evaluate())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbz5lWXDQ-yS"
      },
      "source": [
        "Finetune Using Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bTV3Crp0nMr"
      },
      "outputs": [],
      "source": [
        "def objective_distilbert_hf_trainer(trial):\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True)\n",
        "    per_device_train_batch_size = trial.suggest_categorical(\"per_device_train_batch_size\", [64, 128])\n",
        "    num_train_epochs = 10\n",
        "\n",
        "    wandb.init(\n",
        "        project=\"hf-trainer-distilbert\",\n",
        "        config={\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"per_device_train_batch_size\": per_device_train_batch_size,\n",
        "            \"num_train_epochs\": num_train_epochs,\n",
        "            \"architecture\": \"DistilBERT\",\n",
        "            \"tuning_method\": \"Hugging Face Trainer\",\n",
        "        },\n",
        "        name=f\"hf-trainer-distilbert-trial_{trial.number}\",\n",
        "        reinit=True\n",
        "    )\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        \"distilbert-base-uncased\",\n",
        "        num_labels=3\n",
        "    ).to(device)\n",
        "\n",
        "    y_train = np.array(train_df_distilbert['label'].tolist(), dtype=int)\n",
        "    classes = np.array(sorted(np.unique(y_train)))\n",
        "    weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
        "    class_weights = torch.tensor(weights, dtype=torch.float, device=device)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./hf_trainer_distilbert_results_trial_{trial.number}\",\n",
        "        eval_strategy=\"epoch\",\n",
        "        num_train_epochs=num_train_epochs,\n",
        "        per_device_train_batch_size=per_device_train_batch_size,\n",
        "        per_device_eval_batch_size=per_device_train_batch_size,\n",
        "        learning_rate=learning_rate,\n",
        "        report_to=\"wandb\",\n",
        "        load_best_model_at_end=False,\n",
        "        metric_for_best_model=\"accuracy\",\n",
        "        greater_is_better=True,\n",
        "        save_strategy=\"no\",\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=hf_train_dataset_distilbert,\n",
        "        eval_dataset=hf_val_dataset_distilbert,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    eval_results = trainer.evaluate()\n",
        "\n",
        "    wandb.log(eval_results)\n",
        "    wandb.finish()\n",
        "\n",
        "    return eval_results[\"eval_accuracy\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Rpwa2vIn1GXb",
        "outputId": "d1b48d00-9f67-4367-e2b8-225e735c0a86"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-19 06:41:21,199] A new study created in memory with name: no-name-81e67889-3b60-437d-8df2-cb225f45be97\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Optuna study for DistilBERT with Hugging Face Trainer...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to True."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">hf-trainer-distilbert-trial_0</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert/runs/5pfzjdu7' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert/runs/5pfzjdu7</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250819_064023-5pfzjdu7/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250819_064121-zeyt4pyh</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert/runs/zeyt4pyh' target=\"_blank\">hf-trainer-distilbert-trial_0</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert/runs/zeyt4pyh' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert/runs/zeyt4pyh</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2580/2580 44:41, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.475723</td>\n",
              "      <td>0.820943</td>\n",
              "      <td>0.820678</td>\n",
              "      <td>0.833370</td>\n",
              "      <td>0.820943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.510100</td>\n",
              "      <td>0.350946</td>\n",
              "      <td>0.876336</td>\n",
              "      <td>0.875520</td>\n",
              "      <td>0.877562</td>\n",
              "      <td>0.876336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.510100</td>\n",
              "      <td>0.310938</td>\n",
              "      <td>0.893950</td>\n",
              "      <td>0.893510</td>\n",
              "      <td>0.894444</td>\n",
              "      <td>0.893950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.244000</td>\n",
              "      <td>0.316340</td>\n",
              "      <td>0.899052</td>\n",
              "      <td>0.898747</td>\n",
              "      <td>0.899240</td>\n",
              "      <td>0.899052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.244000</td>\n",
              "      <td>0.326855</td>\n",
              "      <td>0.902697</td>\n",
              "      <td>0.902087</td>\n",
              "      <td>0.902809</td>\n",
              "      <td>0.902697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.151500</td>\n",
              "      <td>0.340340</td>\n",
              "      <td>0.901482</td>\n",
              "      <td>0.900794</td>\n",
              "      <td>0.901409</td>\n",
              "      <td>0.901482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.151500</td>\n",
              "      <td>0.359673</td>\n",
              "      <td>0.900632</td>\n",
              "      <td>0.900276</td>\n",
              "      <td>0.900462</td>\n",
              "      <td>0.900632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.106600</td>\n",
              "      <td>0.368290</td>\n",
              "      <td>0.894679</td>\n",
              "      <td>0.894770</td>\n",
              "      <td>0.894956</td>\n",
              "      <td>0.894679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.106600</td>\n",
              "      <td>0.384328</td>\n",
              "      <td>0.894679</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>0.895556</td>\n",
              "      <td>0.894679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.080600</td>\n",
              "      <td>0.393740</td>\n",
              "      <td>0.895651</td>\n",
              "      <td>0.895657</td>\n",
              "      <td>0.895677</td>\n",
              "      <td>0.895651</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [65/65 00:21]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/accuracy</td><td>▁▆▇████▇▇▇▇</td></tr><tr><td>eval/f1</td><td>▁▆▇████▇▇▇▇</td></tr><tr><td>eval/loss</td><td>█▃▁▁▂▂▃▃▄▅▅</td></tr><tr><td>eval/precision</td><td>▁▅▇████▇▇▇▇</td></tr><tr><td>eval/recall</td><td>▁▆▇████▇▇▇▇</td></tr><tr><td>eval/runtime</td><td>▃▆██▄▃▂▂▄▁▃</td></tr><tr><td>eval/samples_per_second</td><td>▆▃▁▁▅▆▇▇▅█▆</td></tr><tr><td>eval/steps_per_second</td><td>▆▃▁▁▅▆▇▇▅█▆</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▃▃▄▅▅▆▆▆▇████</td></tr><tr><td>train/global_step</td><td>▁▂▂▃▃▃▄▅▅▆▆▆▇█████</td></tr><tr><td>train/grad_norm</td><td>▂█▂▂▁</td></tr><tr><td>train/learning_rate</td><td>█▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▄▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>eval/accuracy</td><td>0.89565</td></tr><tr><td>eval/f1</td><td>0.89566</td></tr><tr><td>eval/loss</td><td>0.39374</td></tr><tr><td>eval/precision</td><td>0.89568</td></tr><tr><td>eval/recall</td><td>0.89565</td></tr><tr><td>eval/runtime</td><td>21.8792</td></tr><tr><td>eval/samples_per_second</td><td>376.248</td></tr><tr><td>eval/steps_per_second</td><td>2.971</td></tr><tr><td>eval_accuracy</td><td>0.89565</td></tr><tr><td>eval_f1</td><td>0.89566</td></tr><tr><td>eval_loss</td><td>0.39374</td></tr><tr><td>eval_precision</td><td>0.89568</td></tr><tr><td>eval_recall</td><td>0.89565</td></tr><tr><td>eval_runtime</td><td>21.8792</td></tr><tr><td>eval_samples_per_second</td><td>376.248</td></tr><tr><td>eval_steps_per_second</td><td>2.971</td></tr><tr><td>total_flos</td><td>8603872169008500.0</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>2580</td></tr><tr><td>train/grad_norm</td><td>3.28145</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0806</td></tr><tr><td>train_loss</td><td>0.21395</td></tr><tr><td>train_runtime</td><td>2683.7624</td></tr><tr><td>train_samples_per_second</td><td>122.682</td></tr><tr><td>train_steps_per_second</td><td>0.961</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">hf-trainer-distilbert-trial_0</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert/runs/zeyt4pyh' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert/runs/zeyt4pyh</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250819_064121-zeyt4pyh/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-19 07:26:30,242] Trial 0 finished with value: 0.8956511175898931 and parameters: {'learning_rate': 2.34317423559625e-05, 'per_device_train_batch_size': 128}. Best is trial 0 with value: 0.8956511175898931.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250819_072630-9gbcurvc</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert/runs/9gbcurvc' target=\"_blank\">hf-trainer-distilbert-trial_1</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert/runs/9gbcurvc' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert/runs/9gbcurvc</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2580/2580 44:41, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.492489</td>\n",
              "      <td>0.814504</td>\n",
              "      <td>0.813932</td>\n",
              "      <td>0.823141</td>\n",
              "      <td>0.814504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.549900</td>\n",
              "      <td>0.367527</td>\n",
              "      <td>0.867833</td>\n",
              "      <td>0.867089</td>\n",
              "      <td>0.868200</td>\n",
              "      <td>0.867833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.549900</td>\n",
              "      <td>0.325955</td>\n",
              "      <td>0.888605</td>\n",
              "      <td>0.887886</td>\n",
              "      <td>0.889231</td>\n",
              "      <td>0.888605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.268000</td>\n",
              "      <td>0.324936</td>\n",
              "      <td>0.892979</td>\n",
              "      <td>0.892804</td>\n",
              "      <td>0.892832</td>\n",
              "      <td>0.892979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.268000</td>\n",
              "      <td>0.326515</td>\n",
              "      <td>0.897473</td>\n",
              "      <td>0.896857</td>\n",
              "      <td>0.897749</td>\n",
              "      <td>0.897473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.174300</td>\n",
              "      <td>0.338155</td>\n",
              "      <td>0.897109</td>\n",
              "      <td>0.896165</td>\n",
              "      <td>0.897899</td>\n",
              "      <td>0.897109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.174300</td>\n",
              "      <td>0.353406</td>\n",
              "      <td>0.896501</td>\n",
              "      <td>0.895925</td>\n",
              "      <td>0.896621</td>\n",
              "      <td>0.896501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.126700</td>\n",
              "      <td>0.366804</td>\n",
              "      <td>0.894922</td>\n",
              "      <td>0.894515</td>\n",
              "      <td>0.894457</td>\n",
              "      <td>0.894922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.126700</td>\n",
              "      <td>0.384643</td>\n",
              "      <td>0.892979</td>\n",
              "      <td>0.892870</td>\n",
              "      <td>0.892812</td>\n",
              "      <td>0.892979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.097600</td>\n",
              "      <td>0.390733</td>\n",
              "      <td>0.893829</td>\n",
              "      <td>0.893503</td>\n",
              "      <td>0.893380</td>\n",
              "      <td>0.893829</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [65/65 00:21]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/accuracy</td><td>▁▅▇████████</td></tr><tr><td>eval/f1</td><td>▁▅▇████████</td></tr><tr><td>eval/loss</td><td>█▃▁▁▁▂▂▃▃▄▄</td></tr><tr><td>eval/precision</td><td>▁▅▇████████</td></tr><tr><td>eval/recall</td><td>▁▅▇████████</td></tr><tr><td>eval/runtime</td><td>▂▁▄▆▂▃▂▇▄█▃</td></tr><tr><td>eval/samples_per_second</td><td>▇█▅▃▇▆▇▂▅▁▆</td></tr><tr><td>eval/steps_per_second</td><td>▇█▅▃▇▆▇▂▅▁▆</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▃▃▄▅▅▆▆▆▇████</td></tr><tr><td>train/global_step</td><td>▁▂▂▃▃▃▄▅▅▆▆▆▇█████</td></tr><tr><td>train/grad_norm</td><td>▁▄▁█▄</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▄▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>eval/accuracy</td><td>0.89383</td></tr><tr><td>eval/f1</td><td>0.8935</td></tr><tr><td>eval/loss</td><td>0.39073</td></tr><tr><td>eval/precision</td><td>0.89338</td></tr><tr><td>eval/recall</td><td>0.89383</td></tr><tr><td>eval/runtime</td><td>21.8708</td></tr><tr><td>eval/samples_per_second</td><td>376.393</td></tr><tr><td>eval/steps_per_second</td><td>2.972</td></tr><tr><td>eval_accuracy</td><td>0.89383</td></tr><tr><td>eval_f1</td><td>0.8935</td></tr><tr><td>eval_loss</td><td>0.39073</td></tr><tr><td>eval_precision</td><td>0.89338</td></tr><tr><td>eval_recall</td><td>0.89383</td></tr><tr><td>eval_runtime</td><td>21.8708</td></tr><tr><td>eval_samples_per_second</td><td>376.393</td></tr><tr><td>eval_steps_per_second</td><td>2.972</td></tr><tr><td>total_flos</td><td>8603872169008500.0</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>2580</td></tr><tr><td>train/grad_norm</td><td>4.61366</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0976</td></tr><tr><td>train_loss</td><td>0.23849</td></tr><tr><td>train_runtime</td><td>2682.7856</td></tr><tr><td>train_samples_per_second</td><td>122.727</td></tr><tr><td>train_steps_per_second</td><td>0.962</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">hf-trainer-distilbert-trial_1</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert/runs/9gbcurvc' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert/runs/9gbcurvc</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250819_072630-9gbcurvc/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-19 08:11:37,531] Trial 1 finished with value: 0.8938289601554907 and parameters: {'learning_rate': 2.03342834585215e-05, 'per_device_train_batch_size': 128}. Best is trial 0 with value: 0.8956511175898931.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250819_081137-87v6v3jh</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert/runs/87v6v3jh' target=\"_blank\">hf-trainer-distilbert-trial_2</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert/runs/87v6v3jh' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert/runs/87v6v3jh</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2580/2580 44:38, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.411424</td>\n",
              "      <td>0.847668</td>\n",
              "      <td>0.847606</td>\n",
              "      <td>0.854591</td>\n",
              "      <td>0.847668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.471300</td>\n",
              "      <td>0.311478</td>\n",
              "      <td>0.892614</td>\n",
              "      <td>0.891912</td>\n",
              "      <td>0.894254</td>\n",
              "      <td>0.892614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.471300</td>\n",
              "      <td>0.289540</td>\n",
              "      <td>0.904397</td>\n",
              "      <td>0.903966</td>\n",
              "      <td>0.904887</td>\n",
              "      <td>0.904397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.190600</td>\n",
              "      <td>0.297515</td>\n",
              "      <td>0.905248</td>\n",
              "      <td>0.904978</td>\n",
              "      <td>0.905520</td>\n",
              "      <td>0.905248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.190600</td>\n",
              "      <td>0.338712</td>\n",
              "      <td>0.906584</td>\n",
              "      <td>0.905848</td>\n",
              "      <td>0.906999</td>\n",
              "      <td>0.906584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.107900</td>\n",
              "      <td>0.344253</td>\n",
              "      <td>0.899295</td>\n",
              "      <td>0.899611</td>\n",
              "      <td>0.900319</td>\n",
              "      <td>0.899295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.107900</td>\n",
              "      <td>0.384518</td>\n",
              "      <td>0.898445</td>\n",
              "      <td>0.898969</td>\n",
              "      <td>0.900295</td>\n",
              "      <td>0.898445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.069500</td>\n",
              "      <td>0.399610</td>\n",
              "      <td>0.895165</td>\n",
              "      <td>0.895852</td>\n",
              "      <td>0.897051</td>\n",
              "      <td>0.895165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.069500</td>\n",
              "      <td>0.441154</td>\n",
              "      <td>0.891521</td>\n",
              "      <td>0.892856</td>\n",
              "      <td>0.895758</td>\n",
              "      <td>0.891521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.041700</td>\n",
              "      <td>0.446114</td>\n",
              "      <td>0.893707</td>\n",
              "      <td>0.894645</td>\n",
              "      <td>0.896401</td>\n",
              "      <td>0.893707</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [65/65 00:21]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/accuracy</td><td>▁▆███▇▇▇▆▆▆</td></tr><tr><td>eval/f1</td><td>▁▆███▇▇▇▆▇▇</td></tr><tr><td>eval/loss</td><td>▆▂▁▁▃▃▅▆███</td></tr><tr><td>eval/precision</td><td>▁▆███▇▇▇▆▇▇</td></tr><tr><td>eval/recall</td><td>▁▆███▇▇▇▆▆▆</td></tr><tr><td>eval/runtime</td><td>▃▁▄▄▅▅▄█▁▆▁</td></tr><tr><td>eval/samples_per_second</td><td>▆█▅▅▄▄▅▁█▃█</td></tr><tr><td>eval/steps_per_second</td><td>▆█▅▅▄▄▅▁█▃█</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_precision</td><td>▁</td></tr><tr><td>eval_recall</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▃▃▄▅▅▆▆▆▇████</td></tr><tr><td>train/global_step</td><td>▁▂▂▃▃▃▄▅▅▆▆▆▇█████</td></tr><tr><td>train/grad_norm</td><td>▅█▅▇▁</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>eval/accuracy</td><td>0.89371</td></tr><tr><td>eval/f1</td><td>0.89465</td></tr><tr><td>eval/loss</td><td>0.44611</td></tr><tr><td>eval/precision</td><td>0.8964</td></tr><tr><td>eval/recall</td><td>0.89371</td></tr><tr><td>eval/runtime</td><td>21.8215</td></tr><tr><td>eval/samples_per_second</td><td>377.243</td></tr><tr><td>eval/steps_per_second</td><td>2.979</td></tr><tr><td>eval_accuracy</td><td>0.89371</td></tr><tr><td>eval_f1</td><td>0.89465</td></tr><tr><td>eval_loss</td><td>0.44611</td></tr><tr><td>eval_precision</td><td>0.8964</td></tr><tr><td>eval_recall</td><td>0.89371</td></tr><tr><td>eval_runtime</td><td>21.8215</td></tr><tr><td>eval_samples_per_second</td><td>377.243</td></tr><tr><td>eval_steps_per_second</td><td>2.979</td></tr><tr><td>total_flos</td><td>8603872169008500.0</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>2580</td></tr><tr><td>train/grad_norm</td><td>1.05418</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0417</td></tr><tr><td>train_loss</td><td>0.17177</td></tr><tr><td>train_runtime</td><td>2679.5604</td></tr><tr><td>train_samples_per_second</td><td>122.875</td></tr><tr><td>train_steps_per_second</td><td>0.963</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">hf-trainer-distilbert-trial_2</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert/runs/87v6v3jh' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert/runs/87v6v3jh</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/hf-trainer-distilbert</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250819_081137-87v6v3jh/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-19 08:56:41,669] Trial 2 finished with value: 0.8937074829931972 and parameters: {'learning_rate': 3.6924719336468674e-05, 'per_device_train_batch_size': 128}. Best is trial 0 with value: 0.8956511175898931.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Optuna study complete.\n",
            "Best trial parameters: {'learning_rate': 2.34317423559625e-05, 'per_device_train_batch_size': 128}\n",
            "Best validation accuracy: 0.8956511175898931\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- 4. Run the Optuna study ---\n",
        "print(\"Running Optuna study for DistilBERT with Hugging Face Trainer...\")\n",
        "study_distilbert_hf = optuna.create_study(direction=\"maximize\")\n",
        "study_distilbert_hf.optimize(objective_distilbert_hf_trainer, n_trials=3)\n",
        "print(\"\\nOptuna study complete.\")\n",
        "print(f\"Best trial parameters: {study_distilbert_hf.best_trial.params}\")\n",
        "print(f\"Best validation accuracy: {study_distilbert_hf.best_trial.value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save to drive (checkpoint)"
      ],
      "metadata": {
        "id": "cR0RW7GGftag"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5JSZu-zrrR8",
        "outputId": "05fa69ab-fa7e-47a3-cf00-933553c0da22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best DistilBERT hyperparameters saved to: /content/drive/MyDrive/ADV_DL/hyperparams/best_distilbert_hyperparams.json\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define the directory to save the hyperparameters file\n",
        "HYPERPARAMS_DIR = os.path.join(BASE_DIR, \"hyperparams\")\n",
        "os.makedirs(HYPERPARAMS_DIR, exist_ok=True)\n",
        "BEST_DISTILBERT_PARAMS_FILE = os.path.join(HYPERPARAMS_DIR, \"best_distilbert_hyperparams.json\")\n",
        "\n",
        "# Extract and save the best parameters from the Optuna study\n",
        "best_params_distilbert = study_distilbert_hf.best_trial.params\n",
        "\n",
        "with open(BEST_DISTILBERT_PARAMS_FILE, 'w') as f:\n",
        "    json.dump(best_params_distilbert, f, indent=4)\n",
        "\n",
        "print(f\"Best DistilBERT hyperparameters saved to: {BEST_DISTILBERT_PARAMS_FILE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpsC1E-WxWNY",
        "outputId": "46f88676-6af4-48df-e15f-5386d34c3689"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading or saving the best model from trial 0's output directory: Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory ./hf_trainer_distilbert_results_trial_0.\n",
            "Attempted to load from: ./hf_trainer_distilbert_results_trial_0\n",
            "Please ensure the Optuna study completed successfully and verify the contents of the output directory.\n"
          ]
        }
      ],
      "source": [
        "# Assuming study_distilbert_hf is your completed Optuna study for DistilBERT\n",
        "if 'study_distilbert_hf' not in locals():\n",
        "    print(\"Error: Optuna study for DistilBERT not found. Please run the Optuna study cell first.\")\n",
        "else:\n",
        "    # Get the directory of the best trial's checkpoint\n",
        "    best_trial = study_distilbert_hf.best_trial\n",
        "    best_trial_output_dir = f\"./hf_trainer_distilbert_results_trial_{best_trial.number}\"\n",
        "\n",
        "    # Define the final save directory on Google Drive\n",
        "    FINAL_MODEL_DIR_DISTILBERT = os.path.join(BASE_DIR, \"final_models\", \"distilbert_hf_trainer\")\n",
        "    os.makedirs(FINAL_MODEL_DIR_DISTILBERT, exist_ok=True)\n",
        "\n",
        "    # Load the model from the best trial's output directory and save it\n",
        "    try:\n",
        "        # Load the model from the final state of the best trial\n",
        "        final_distilbert_model = AutoModelForSequenceClassification.from_pretrained(best_trial_output_dir)\n",
        "        final_distilbert_model.to(device) # Ensure model is on the correct device\n",
        "\n",
        "        # Load the DistilBERT tokenizer and save it as well\n",
        "        distilbert_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "        final_distilbert_model.save_pretrained(FINAL_MODEL_DIR_DISTILBERT)\n",
        "        distilbert_tokenizer.save_pretrained(FINAL_MODEL_DIR_DISTILBERT)\n",
        "\n",
        "        print(f\"Final fine-tuned DistilBERT model saved to: {FINAL_MODEL_DIR_DISTILBERT}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading or saving the best model from trial {best_trial.number}'s output directory: {e}\")\n",
        "        print(f\"Attempted to load from: {best_trial_output_dir}\")\n",
        "        print(\"Please ensure the Optuna study completed successfully and verify the contents of the output directory.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2meF_J8p916"
      },
      "source": [
        "# Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0qljN9uHkZy"
      },
      "source": [
        "# \"Full Code\" Fine-Tuning - Model Comparison: DistilBERT vs. BERTweet\n",
        "\n",
        "---\n",
        "First, we wanted to check the entire process of the model runs, Trying to analyze it to see whether we achieve any helpful information about our models.\n",
        "## 1. Aggregate Statistics Across Runs\n",
        "\n",
        "| Model      | Avg. Val. Acc | Median Val. Acc | Std Dev (Val. Acc) | Avg. Val. F1 | Median Val. F1 | Std Dev (Val. F1) |\n",
        "|------------|---------------|-----------------|---------------------|--------------|----------------|-------------------|\n",
        "| DistilBERT | **0.832**     | 0.806           | 0.043               | **0.832**    | 0.807          | 0.043             |\n",
        "| BERTweet   | 0.829         | 0.830           | 0.010               | 0.828        | 0.830          | 0.010             |\n",
        "\n",
        "**Interpretation**  \n",
        "- **DistilBERT** shows higher **average accuracy/F1 (~83.2%)**, but with higher variance (std ~4.3%).  \n",
        "- **BERTweet** achieves slightly lower **average accuracy (~82.9%)**, but with much **tighter variance (std ~1%)**, indicating stable convergence across trials.  \n",
        "- DistilBERT may benefit more from careful hyperparameter tuning, while BERTweet provides robustness across different trials.\n",
        "\n",
        "---\n",
        "Then, we wanted to investigate our peaks, the best trial of each model, to achieve broader perspective on our model results.\n",
        "\n",
        "## 2. Best Trial per Model\n",
        "\n",
        "### DistilBERT – Best Trial (Trial 1)\n",
        " **Validation Accuracy:** 0.887  \n",
        " **Validation F1:** 0.886  \n",
        " **Precision:** 0.874  \n",
        " **Recall:** 0.887  \n",
        " **Train Accuracy:** 0.978  \n",
        " **Train Loss:** 0.067  \n",
        "\n",
        "### BERTweet – Best Trial (Trial 0)\n",
        " **Validation Accuracy:** 0.844  \n",
        " **Validation F1:** 0.843  \n",
        " **Precision:** 0.844  \n",
        " **Recall:** 0.844  \n",
        " **Train Accuracy:** 0.935  \n",
        " **Train Loss:** 0.191  \n",
        "\n",
        "**Comparison & Insights**  \n",
        "- DistilBERT outperforms BERTweet in **raw metrics** (Acc/F1 ≈ 88.7% vs. 84.4%).  \n",
        "- DistilBERT shows **heavier overfitting** (train acc 97.8% vs val acc 88.7%), while BERTweet generalizes slightly smoother (train acc 93.5% vs val acc 84.4%).  \n",
        "- DistilBERT can reach higher peak performance but requires **strong regularization**.  \n",
        "- BERTweet, although weaker in ceiling performance, is **less prone to overfitting** and could generalize better to noisy domains, which fits our intuition of it being a tweet-reading model (tweets).\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Best Hyperparameters\n",
        "\n",
        "### DistilBERT (Best Trial)\n",
        "  learning_rate: 0.000108,\n",
        "  weight_decay: 3.32e-05,\n",
        "  patience: 7,\n",
        "  batch_size: 32,\n",
        "  num_layers: 4\n",
        "\n",
        "### BERTweet (Best Trial)\n",
        "  learning_rate: 0.000507,\n",
        "  weight_decay: 4.38e-05,\n",
        "  patience: 6,\n",
        "  batch_size: 128,\n",
        "  num_layers: 3\n",
        "\n",
        "  **Interpretation of Hyperparameters**\n",
        "\n",
        "**Learning rate**:\n",
        "\n",
        "DistilBERT → **1.08e-4.**\n",
        "DistilBERT is a lighter, distilled version of BERT with fewer parameters.\n",
        "Smaller LR suggests the model required gentler, more stable updates. Large updates may have disrupted its compressed architecture, which is already tuned to general-domain patterns.This indicates that DistilBERT’s pretrained weights are sensitive: it “remembers” its distilled knowledge and fine-tunes best when nudged slowly.\n",
        "\n",
        "BERTweet → **5.07e-4.** - larger then DistilBERT.\n",
        "BERTweet is pretrained on noisy Twitter data. Its embeddings are well adapted to slang, hashtags, emojis. A larger LR here helps shake the model out of its strong priors and adapt faster to your specific labeled dataset (COVID-related sentiment).\n",
        "\n",
        "Coclusion: BERTweet was robust enough to tolerate aggressive updates, which matches its need to “unlearn some noise” and realign with your labels. Smaller models (DistilBERT) are fragile and benefit from conservative updates. Larger, domain-pretrained models (BERTweet) can absorb bigger steps, but only when batch size is also large.\n",
        "\n",
        "**Batch size**: DistilBERT → **32**\n",
        "\n",
        "Small batch size = noisier gradient estimates, but that noise can regularize training and prevent overfitting on a small dataset.\n",
        "DistilBERT seems to thrive with this noise, possibly because it prevents the model from collapsing into oversimplified decision boundaries.\n",
        "\n",
        "BERTweet → **128**\n",
        "\n",
        "Larger batch size smooths the gradient estimate, making learning more stable.\n",
        "With ~135M parameters, BERTweet likely needs the stability of larger batches to prevent noisy updates from pushing weights in conflicting directions.\n",
        "This explains why BERTweet’s variance across trials was high when batches were small, but its best run was with the largest batch.\n",
        "Model size and pretraining corpus scale interact with batch size.\n",
        "Small, distilled models: benefit from noise in the gradients (smaller batches).\n",
        "Large, specialized models: require stability (larger batches).\n",
        "\n",
        "**Layers**: DistilBERT best run stacked **4 layers**, BERTweet stabilized at **3 layers**.  \n",
        "\n",
        "---\n",
        "\n",
        "### Key Takeaways\n",
        "**1. Comparison of Performance**  \n",
        "Our initial intuition was that BERTweet performance was going to beat DistilBERT's performance. We fear that maybe DistilBERT may benefit from its distilled nature - learning faster on small datasets. BERTweet requires longer training or stronger regularization to fully shine. Additionally, BERTweet’s large capacity (135M parameters) may need more data or stronger regularization to fully leverage its pretraining. DistilBERT, being smaller (~66M params), may generalize better with limited labeled data - avoiding overfitting and showing steadier validation curves in some trials.\n",
        "\n",
        "**2. Performance vs. Stability**  \n",
        "DistilBERT achieves **higher peak performance (~88.7%)** but is **less stable** across trials.  \n",
        "BERTweet is **more consistent (~83% ±1%)**, making it safer when robustness matters.  \n",
        "\n",
        "**3. Overfitting Risk**  \n",
        "DistilBERT shows **stronger overfitting patterns**, requiring **regularization**.  \n",
        "BERTweet generalizes **more smoothly**, making it reliable for noisy, short-text data.  \n",
        "\n",
        "**4. Hyperparameter Sensitivity**  \n",
        "DistilBERT requires **careful tuning (low LR, small batch)**.  \n",
        "BERTweet tolerates **larger LR and batch sizes**, making training more forgiving.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ub7pW1-2D6u"
      },
      "source": [
        "## What could we do to improve the results?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX_UEk5u2KgK"
      },
      "source": [
        "We didn't rerun improvements cause the project already consumed significant compute time (several days).\n",
        "\n",
        "Improvements we would do if we had time and plenty of GPU:\n",
        "\n",
        "1.  **Change the Max Length Tokenizer we have set:**\n",
        "  - **What we did:** We have set a data-driven cap (p99 + buffer) using a json file from part A and padded everything to that cap.\n",
        "  - **What we should have done:** we should have change the padding to dynamic padding instead of a \"fixed\" number. Also, we should have choose different padding for each model which we haven't (we wanted to keep things simple at first, but then we understood we won't be able to run this again).\n",
        "\n",
        "2.  **Increase the number of epochs:**\n",
        "  - We would increase the number of epochs to at least 20 to give the model more chance to learn as at each epoch, the model \"sees\" every training example again, so if there's a underfitting (the model hasn't fully fit the patterns yet), maybe a few extra passes would have reduce the training loss and MAYBE lift validation accuracy (if we wouldn't pass the \"sweetspot\" of the tradeoff between low training loss to low val loss).\n",
        "\n",
        "3. **Increase the number of trials and add a smaller batch size**\n",
        "  - We would increase the number of trials and add a smaller batch size to cover more combinations, which means higher chance to get a better hyper parameters --> better model.\n",
        "  - We could add a smaller batch size to help with generalization (we can call it even a type of \"regularization\").\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Okrw66ns1k93"
      },
      "source": [
        "# Fine-Tuned Model Comparison\n",
        "\n",
        "We evaluated four model variants (BERTweet and DistilBERT), each trained with two approaches: Hugging Face Trainer and a custom \"Full Code\" pipeline.  \n",
        "The following table summarizes their best runs:\n",
        "\n",
        "| Model Variant                  | Train Loss | Val. Loss | Best Val. Accuracy | Overfitting Tendency                |\n",
        "|--------------------------------|------------|-----------|--------------------|-------------------------------------|\n",
        "| **BERTweet w/ Hugging Face**   | 0.1455     | 0.3426    | **0.9040**         | Very low gap → Low overfitting      |\n",
        "| **DistilBERT w/ Hugging Face** | 0.0806     | 0.3937    | 0.8957             | Larger gap → Moderate overfitting   |\n",
        "| **DistilBERT w/ Full Code**    | 0.0671     | 0.5823    | 0.8867             | Big gap → High overfitting          |\n",
        "| **BERTweet w/ Full Code**      | 0.1915     | 0.4915    | 0.8439             | Noticeable gap → Moderate overfitting |\n",
        "\n",
        "---\n",
        "\n",
        "## Selection of the Two Best Models\n",
        "\n",
        "1. **BERTweet w/ Hugging Face Trainer**  \n",
        "   - **Best accuracy (90.4%)** and lowest validation loss.  \n",
        "   - Smallest train–val gap → most robust generalization.  \n",
        "   - Excellent F1, precision, and recall.\n",
        "\n",
        "2. **DistilBERT w/ Hugging Face Trainer**  \n",
        "   - **Second-best accuracy (89.6%)**.  \n",
        "   - Train loss is very low (0.0806), but the larger train–val gap indicates more overfitting risk than BERTweet.  \n",
        "   - Still strong, and more efficient for deployment.\n",
        "\n",
        "---\n",
        "\n",
        "## Final Conclusion\n",
        "\n",
        "The **two chosen models** are:  \n",
        "- **BERTweet (Hugging Face Trainer)** → Best performing overall, strongest generalization.  \n",
        "- **DistilBERT (Hugging Face Trainer)** → Competitive accuracy, lighter model for production efficiency.  \n",
        "\n",
        "Together, they balance **accuracy** and **efficiency**, making them the best candidates.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndSSDhjp8V7F"
      },
      "source": [
        "# **Test Run**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Eval + Utilities Setup**\n",
        "\n",
        "Sets W&B config, derives max sequence lengths from length_stats.json, validation checks for text/label columns, and builds tokenized Hugging Face Datasets. Includes a collate for padding, a forward_pass to get probs/preds/loss in eval mode, gives confusion matrix, one-vs-rest ROC."
      ],
      "metadata": {
        "id": "x0FaftR3gIOi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-41ZDCi8kOO"
      },
      "outputs": [],
      "source": [
        "WANDB_PROJECT = \"adv-dl-sentiment\"   # TODO: set\n",
        "WANDB_ENTITY  = None                 # or your entity\n",
        "WANDB_TAGS    = [\"test-eval\", \"multiclass\"]\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def get_max_len(default_bert=96, default_roberta=96):\n",
        "    path = globals().get(\"LENGTH_STATS_FILE\") or (globals().get(\"BASE_DIR\") and os.path.join(BASE_DIR,\"length_stats.json\"))\n",
        "    if path and os.path.exists(path):\n",
        "        try:\n",
        "            with open(path,\"r\") as f: s = json.load(f)\n",
        "            return int(s.get(\"bert\",{}).get(\"overall\",{}).get(\"p99\",default_bert)), \\\n",
        "                   int(s.get(\"roberta\",{}).get(\"overall\",{}).get(\"p99\",default_roberta))\n",
        "        except Exception: pass\n",
        "    return default_bert, default_roberta\n",
        "\n",
        "CAND_TEXT_COLS = [\"text\",\"clean_text\",\"OriginalTweet\",\"Tweet\",\"tweet\",\"original_tweet\"]\n",
        "def pick_text_col(df):\n",
        "    for c in CAND_TEXT_COLS:\n",
        "        if c in df.columns: return c\n",
        "    obj = [c for c in df.columns if df[c].dtype==\"object\"]\n",
        "    if obj: return obj[0]\n",
        "    raise ValueError(\"No text column found.\")\n",
        "\n",
        "def ensure_label_col(df):\n",
        "    if \"label\" in df.columns: return df.rename(columns={\"label\":\"label\"})\n",
        "    for alt in [\"labels\",\"sentiment_std\",\"SentimentId\",\"y\",\"target\"]:\n",
        "        if alt in df.columns: return df.rename(columns={alt:\"label\"})\n",
        "    raise ValueError(\"No label column; need ints {0,1,2}.\")\n",
        "\n",
        "def build_hf_dataset(df, tokenizer, max_length, text_col):\n",
        "    tmp = df[[text_col, \"label\"]].dropna().rename(columns={text_col: \"text\"})\n",
        "    ds  = HFDataset.from_pandas(tmp, preserve_index=False)   # <-- change here\n",
        "\n",
        "    def _tok(batch):\n",
        "        enc = tokenizer(batch[\"text\"], padding=False, truncation=True, max_length=max_length)\n",
        "        return enc\n",
        "    ds = ds.map(_tok, batched=True, remove_columns=[\"text\"])\n",
        "    ds = ds.rename_column(\"label\", \"labels\")\n",
        "    ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "    return ds\n",
        "\n",
        "def make_collate(tokenizer):\n",
        "    pad_id = tokenizer.pad_token_id or 0\n",
        "    def collate(batch):\n",
        "        keys = {k for b in batch for k in b}\n",
        "        out = {}\n",
        "        for k in keys:\n",
        "            arr = [b[k] for b in batch]\n",
        "            if k == \"labels\":\n",
        "                out[k] = torch.tensor(arr)\n",
        "            else:\n",
        "                out[k] = torch.nn.utils.rnn.pad_sequence(\n",
        "                    [torch.tensor(v) for v in arr], batch_first=True, padding_value=pad_id\n",
        "                )\n",
        "        return out\n",
        "    return collate\n",
        "\n",
        "def forward_pass(model, loader, num_labels=3, compute_loss=True):\n",
        "    model.eval()\n",
        "    logits_all, labels_all, ce = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = {k:v.to(device) for k,v in batch.items()}\n",
        "            out   = model(input_ids=batch[\"input_ids\"], attention_mask=batch.get(\"attention_mask\"))\n",
        "            logits_all.append(out.logits.detach().cpu())\n",
        "            labels_all.append(batch[\"labels\"].detach().cpu())\n",
        "            if compute_loss:\n",
        "                ce.append(torch.nn.functional.cross_entropy(out.logits, batch[\"labels\"]).item())\n",
        "    logits = torch.cat(logits_all, dim=0) if logits_all else torch.empty((0,num_labels))\n",
        "    labels = torch.cat(labels_all, dim=0) if labels_all else torch.empty((0,),dtype=torch.long)\n",
        "    probs  = torch.softmax(logits, dim=-1).numpy() if logits.numel() else np.zeros((0,num_labels))\n",
        "    preds  = probs.argmax(-1) if probs.size else np.array([],dtype=int)\n",
        "    loss   = float(np.mean(ce)) if ce else float(\"nan\")\n",
        "    return probs, preds, labels.numpy(), loss\n",
        "\n",
        "def plot_conf_mat(y_true, y_pred, labels, title, save_path):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    fig = plt.figure(figsize=(5.2,4.4), dpi=140)\n",
        "    ax  = fig.add_subplot(111)\n",
        "    im  = ax.imshow(cm, interpolation=\"nearest\")\n",
        "    ax.set_title(title); ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
        "    ax.set_xticks(range(len(labels))); ax.set_yticks(range(len(labels)))\n",
        "    ax.set_xticklabels(labels); ax.set_yticklabels(labels)\n",
        "    for i in range(len(labels)):\n",
        "        for j in range(len(labels)):\n",
        "            ax.text(j, i, cm[i,j], ha=\"center\", va=\"center\")\n",
        "    fig.tight_layout(); fig.savefig(save_path, bbox_inches=\"tight\"); plt.close(fig)\n",
        "    return cm\n",
        "\n",
        "def plot_roc_ovr(y_true, probs, labels, title, save_path):\n",
        "    fig = plt.figure(figsize=(5.8,4.8), dpi=140)\n",
        "    ax  = fig.add_subplot(111)\n",
        "    for i, lab in enumerate(labels):\n",
        "        y_bin = (y_true==lab).astype(int)\n",
        "        if len(np.unique(y_bin)) < 2: continue\n",
        "        fpr, tpr, _ = roc_curve(y_bin, probs[:, i])\n",
        "        ax.plot(fpr, tpr, label=f\"class {lab}\")\n",
        "    ax.plot([0,1],[0,1],\"--\",linewidth=1)\n",
        "    ax.set_title(title); ax.set_xlabel(\"FPR\"); ax.set_ylabel(\"TPR\"); ax.legend(fontsize=8, loc=\"lower right\")\n",
        "    fig.tight_layout(); fig.savefig(save_path, bbox_inches=\"tight\"); plt.close(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRs3Sohpz_g-"
      },
      "source": [
        "Get test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y32Yh9DMz0Qh"
      },
      "outputs": [],
      "source": [
        "# validation check: Uses existing variables if present; otherwise reads from your paths.\n",
        "def _get_df(obj_name, path_name):\n",
        "    if obj_name in globals(): return globals()[obj_name].copy()\n",
        "    p = globals().get(path_name)\n",
        "    if p and os.path.exists(p):\n",
        "        try: return pd.read_excel(p)\n",
        "        except Exception: return pd.read_csv(p, encoding=\"ISO-8859-1\")\n",
        "    return None\n",
        "\n",
        "df_distilbert_test = _get_df(\"df_distilbert_test\", \"DISTILBERT_TEST_FILE\")\n",
        "df_bertweet_test   = _get_df(\"df_bertweet_test\",   \"BERTWEET_TEST_FILE\")\n",
        "if df_distilbert_test is None and df_bertweet_test is None:\n",
        "    raise RuntimeError(\"No test data found. Ensure df_*_test exist or *_TEST_FILE paths are valid.\")\n",
        "\n",
        "dfd = ensure_label_col(df_distilbert_test) if df_distilbert_test is not None else None\n",
        "dfb = ensure_label_col(df_bertweet_test)   if df_bertweet_test   is not None else None\n",
        "text_col_d = pick_text_col(dfd) if dfd is not None else None\n",
        "text_col_b = pick_text_col(dfb) if dfb is not None else None\n",
        "MAXLEN_BERT, MAXLEN_ROBERTA = get_max_len()\n",
        "\n",
        "os.makedirs(\"eval_plots\", exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsaAGB6n0blx"
      },
      "source": [
        "Evaluateion function"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "picks the best HF directory per model using trainer_state.json."
      ],
      "metadata": {
        "id": "QHSQ5dnYjfhK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pjqx9SYDJIvw",
        "outputId": "b689e2dd-6297-4d3a-dd2b-00baeb5810ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resolved checkpoints:\n",
            " - DistilBERT (HF): /content/drive/MyDrive/ADV_DL/hf_best/distilbert/checkpoint-2580\n",
            " - BERTweet  (HF): /content/drive/MyDrive/ADV_DL/hf_best/bertweet/checkpoint-5150\n"
          ]
        }
      ],
      "source": [
        "# Base directory\n",
        "if \"BASE_DIR\" not in globals():\n",
        "    BASE_DIR = \".\"\n",
        "\n",
        "def _is_hf_dir(d):\n",
        "    return d and os.path.isfile(os.path.join(d, \"config.json\")) and (\n",
        "        os.path.isfile(os.path.join(d, \"model.safetensors\")) or\n",
        "        os.path.isfile(os.path.join(d, \"pytorch_model.bin\"))\n",
        "    )\n",
        "\n",
        "def pick_best_checkpoint(root_dir):\n",
        "    \"\"\"Return a loadable HF dir: best recorded in trainer_state.json, else highest-step checkpoint, else root (if loadable).\"\"\"\n",
        "    if not root_dir or not os.path.isdir(root_dir):\n",
        "        return None\n",
        "    ts = os.path.join(root_dir, \"trainer_state.json\")\n",
        "    if os.path.exists(ts):\n",
        "        try:\n",
        "            with open(ts, \"r\") as f:\n",
        "                j = json.load(f)\n",
        "            b = j.get(\"best_model_checkpoint\")\n",
        "            if _is_hf_dir(b):\n",
        "                return b\n",
        "        except Exception:\n",
        "            pass\n",
        "    cands = sorted(glob.glob(os.path.join(root_dir, \"checkpoint-*\")))\n",
        "    if cands:\n",
        "        def _step(p):\n",
        "            try: return int(os.path.basename(p).split(\"-\")[-1])\n",
        "            except: return -1\n",
        "        best = max(cands, key=_step)\n",
        "        if _is_hf_dir(best):\n",
        "            return best\n",
        "    return root_dir if _is_hf_dir(root_dir) else None\n",
        "\n",
        "# Folders as in your Drive screenshots\n",
        "HF_DISTILBERT_ROOT = os.path.join(BASE_DIR, \"hf_best\", \"distilbert\")   # has checkpoint-500..2580 + model.safetensors\n",
        "HF_BERTWEET_ROOT   = os.path.join(BASE_DIR, \"hf_best\", \"bertweet\")     # has checkpoint-5150 + model.safetensors\n",
        "FM_DISTILBERT_DIR  = os.path.join(BASE_DIR, \"final_models\", \"distilbert_full_code\")  # full saved HF dir\n",
        "FM_BERTWEET_DIR    = os.path.join(BASE_DIR, \"final_models\", \"bertweet_full_code\")    # full saved HF dir\n",
        "\n",
        "# Pick the best available directories\n",
        "DISTILBERT_HF_DIR = pick_best_checkpoint(HF_DISTILBERT_ROOT) or (_is_hf_dir(FM_DISTILBERT_DIR) and FM_DISTILBERT_DIR) or None\n",
        "BERTWEET_HF_DIR   = pick_best_checkpoint(HF_BERTWEET_ROOT)   or (_is_hf_dir(FM_BERTWEET_DIR)   and FM_BERTWEET_DIR)   or None\n",
        "\n",
        "print(\"Resolved checkpoints:\")\n",
        "print(\" - DistilBERT (HF):\", DISTILBERT_HF_DIR)\n",
        "print(\" - BERTweet  (HF):\", BERTWEET_HF_DIR)\n",
        "\n",
        "# What your evaluator expects:\n",
        "MODEL_DIRS = {\n",
        "    \"distilbert_hf\": DISTILBERT_HF_DIR,\n",
        "    \"bertweet_hf\":   BERTWEET_HF_DIR,\n",
        "}\n",
        "MODEL_FILES = {}  # no raw .pt files needed since you saved full HF dirs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Final Model Directories**\n",
        "\n",
        "We set up variables that point to the saved model directories for evaluation:  \n",
        "- **HF-Trainer checkpoints** (DistilBERT & BERTweet).  \n",
        "- **Full-code checkpoints** (DistilBERT & BERTweet).  \n"
      ],
      "metadata": {
        "id": "AbZ-lYKVkSDX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90DV7RziKFCx",
        "outputId": "f34be496-0756-4d99-d5b4-87fc3051be49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL_MODEL_DIR_DISTILBERT      = /content/drive/MyDrive/ADV_DL/hf_best/distilbert/checkpoint-2580\n",
            "FINAL_MODEL_DIR_BERTWEET        = /content/drive/MyDrive/ADV_DL/hf_best/bertweet/checkpoint-5150\n",
            "FINAL_MODEL_DIR_DISTILBERT_FULL = /content/drive/MyDrive/ADV_DL/final_models/distilbert_full_code\n",
            "FINAL_MODEL_DIR_BERTWEET_FULL   = /content/drive/MyDrive/ADV_DL/final_models/bertweet_full_code\n"
          ]
        }
      ],
      "source": [
        "# Cell C — feed paths into your evaluation block variables\n",
        "\n",
        "# Requires Cell B to have defined these:\n",
        "#   DISTILBERT_HF_DIR, BERTWEET_HF_DIR, FM_DISTILBERT_DIR, FM_BERTWEET_DIR\n",
        "\n",
        "FINAL_MODEL_DIR_DISTILBERT       = DISTILBERT_HF_DIR         # HF-Trainer DistilBERT (best ckpt or root)\n",
        "FINAL_MODEL_DIR_BERTWEET         = BERTWEET_HF_DIR           # HF-Trainer BERTweet  (best ckpt or root)\n",
        "FINAL_MODEL_DIR_DISTILBERT_FULL  = FM_DISTILBERT_DIR         # “full_code” final HF dir\n",
        "FINAL_MODEL_DIR_BERTWEET_FULL    = FM_BERTWEET_DIR           # “full_code” final HF dir\n",
        "\n",
        "# Optional: quick sanity prints (helps if anything still skips)\n",
        "print(\"FINAL_MODEL_DIR_DISTILBERT      =\", FINAL_MODEL_DIR_DISTILBERT)\n",
        "print(\"FINAL_MODEL_DIR_BERTWEET        =\", FINAL_MODEL_DIR_BERTWEET)\n",
        "print(\"FINAL_MODEL_DIR_DISTILBERT_FULL =\", FINAL_MODEL_DIR_DISTILBERT_FULL)\n",
        "print(\"FINAL_MODEL_DIR_BERTWEET_FULL   =\", FINAL_MODEL_DIR_BERTWEET_FULL)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation & W&B\n",
        "\n",
        "steps:\n",
        "- **Loads** the trained model and tokenizer\n",
        "- **Builds a test dataset and DataLoader**   \n",
        "- Runs a forward pass to compute:  \n",
        "  - Accuracy, Precision, Recall, F1 (weighted).  \n",
        "  - Cross-Entropy loss (test + post-hoc train/val).  \n",
        "  - ROC-AUC (OvR & OvO).  \n",
        "- **Logs results (W&B)** metrics, plots, and a per-class classification report.  \n",
        "- **Prints summary** of results and runtime stats\n"
      ],
      "metadata": {
        "id": "RiAZ3AYalAP9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8qE5nQ60lkB"
      },
      "outputs": [],
      "source": [
        "# === Single-model evaluate + W&B log (compact) ===\n",
        "def evaluate_and_log(model_label, model_dir):\n",
        "    if not model_dir or not os.path.isdir(model_dir):\n",
        "        print(f\"skip: {model_label} (dir missing) -> {model_dir}\"); return None\n",
        "\n",
        "    tok  = AutoTokenizer.from_pretrained(model_dir, use_fast=False)\n",
        "    mdl  = AutoModelForSequenceClassification.from_pretrained(model_dir).to(device)\n",
        "    is_rob = (\"roberta\" in tok.__class__.__name__.lower()) or (\"bertweet\" in mdl.name_or_path.lower())\n",
        "\n",
        "    use_df  = dfb if is_rob and dfb is not None else dfd\n",
        "    txtcol  = text_col_b if is_rob and text_col_b is not None else text_col_d\n",
        "    max_len = MAXLEN_ROBERTA if is_rob else MAXLEN_BERT\n",
        "    if use_df is None:\n",
        "        use_df, txtcol, max_len = (dfb, text_col_b, MAXLEN_ROBERTA) if dfb is not None else (dfd, text_col_d, MAXLEN_BERT)\n",
        "\n",
        "    ds_test = build_hf_dataset(use_df, tok, max_len, txtcol)\n",
        "    loader  = DataLoader(ds_test, batch_size=64, shuffle=False, collate_fn=make_collate(tok))\n",
        "\n",
        "    t0 = time.time()\n",
        "    probs, y_pred, y_true, test_ce = forward_pass(mdl, loader, num_labels=mdl.config.num_labels, compute_loss=True)\n",
        "    spb = (time.time() - t0) / max(1, len(loader))\n",
        "\n",
        "    acc  = accuracy_score(y_true, y_pred) if y_true.size else float(\"nan\")\n",
        "    f1w  = f1_score(y_true, y_pred, average=\"weighted\", zero_division=0) if y_true.size else float(\"nan\")\n",
        "    pw   = precision_score(y_true, y_pred, average=\"weighted\", zero_division=0) if y_true.size else float(\"nan\")\n",
        "    rw   = recall_score(y_true, y_pred, average=\"weighted\", zero_division=0) if y_true.size else float(\"nan\")\n",
        "\n",
        "    roc_ovr = roc_ovo = float(\"nan\")\n",
        "    if y_true.size and probs.shape[0]==y_true.shape[0]:\n",
        "        try: roc_ovr = roc_auc_score(y_true, probs, multi_class=\"ovr\")\n",
        "        except Exception: pass\n",
        "        try: roc_ovo = roc_auc_score(y_true, probs, multi_class=\"ovo\")\n",
        "        except Exception: pass\n",
        "\n",
        "    labs = sorted(set(y_true.tolist()+y_pred.tolist()))\n",
        "    base = model_label.lower().replace(\" \",\"_\").replace(\"—\",\"-\")\n",
        "    cm_path  = f\"eval_plots/{base}_cm.png\"\n",
        "    roc_path = f\"eval_plots/{base}_roc.png\"\n",
        "    plot_conf_mat(y_true, y_pred, labs, f\"{model_label} — Confusion Matrix\", cm_path)\n",
        "    plot_roc_ovr(y_true, probs, labs, f\"{model_label} — ROC (OvR)\", roc_path)\n",
        "\n",
        "    # post-hoc CE on train/val (if your HF splits exist)\n",
        "    tr = locals().get(\"hf_train_dataset_bertweet\") if is_rob else locals().get(\"hf_train_dataset_distilbert\")\n",
        "    va = locals().get(\"hf_val_dataset_bertweet\")   if is_rob else locals().get(\"hf_val_dataset_distilbert\")\n",
        "    train_ce = val_ce = float(\"nan\")\n",
        "    if tr is not None:\n",
        "        tr_loader = DataLoader(tr, batch_size=64, shuffle=False, collate_fn=make_collate(tok))\n",
        "        _,_,_,train_ce = forward_pass(mdl, tr_loader, mdl.config.num_labels, True)\n",
        "    if va is not None:\n",
        "        va_loader = DataLoader(va, batch_size=64, shuffle=False, collate_fn=make_collate(tok))\n",
        "        _,_,_,val_ce = forward_pass(mdl, va_loader, mdl.config.num_labels, True)\n",
        "\n",
        "    # W&B\n",
        "    run = wandb.init(project=WANDB_PROJECT, entity=WANDB_ENTITY, name=f\"Test — {model_label}\", tags=WANDB_TAGS, reinit=True,\n",
        "                     config={\"model_dir\":model_dir,\"is_roberta_family\":is_rob,\"max_length\":max_len,\"num_labels\":mdl.config.num_labels})\n",
        "    wandb.log({\n",
        "        \"test/accuracy\":acc, \"test/f1_weighted\":f1w, \"test/precision_weighted\":pw, \"test/recall_weighted\":rw,\n",
        "        \"test/roc_auc_ovr\":roc_ovr, \"test/roc_auc_ovo\":roc_ovo, \"test/cross_entropy\":test_ce,\n",
        "        \"posthoc/train_cross_entropy\":train_ce, \"posthoc/val_cross_entropy\":val_ce, \"speed/sec_per_batch\":spb,\n",
        "        \"counts/test_n\": int(y_true.size),\n",
        "        \"plots/confusion_matrix\": wandb.Image(cm_path),\n",
        "        \"plots/roc_curves\":       wandb.Image(roc_path),\n",
        "    })\n",
        "    # per-class report (table)\n",
        "    try:\n",
        "        rep = classification_report(y_true, y_pred, digits=4, output_dict=True)\n",
        "        rep_df = pd.DataFrame(rep).T.reset_index().rename(columns={\"index\":\"class\"})\n",
        "        wandb.log({\"tables/classification_report\": wandb.Table(dataframe=rep_df)})\n",
        "    except Exception:\n",
        "        pass\n",
        "    run.finish()\n",
        "\n",
        "    # print numeric scores\n",
        "    print(f\"\\n=== {model_label} ===\")\n",
        "    print(f\"Dir: {model_dir}\")\n",
        "    print(f\"N: {y_true.size} | Acc {acc:.4f} | F1w {f1w:.4f} | Precw {pw:.4f} | Recallw {rw:.4f}\")\n",
        "    print(f\"ROC-AUC OvR: {('%.4f'%roc_ovr) if not math.isnan(roc_ovr) else '—'} | OvO: {('%.4f'%roc_ovo) if not math.isnan(roc_ovo) else '—'}\")\n",
        "    print(f\"CE test: {test_ce:.4f} | CE train: {train_ce if not math.isnan(train_ce) else '—'} | CE val: {val_ce if not math.isnan(val_ce) else '—'}\")\n",
        "    print(f\"Sec/Batch: {spb:.4f} | Plots: {cm_path}, {roc_path}\")\n",
        "\n",
        "    return {\n",
        "        \"Model\": model_label, \"Dir\": model_dir, \"Test Acc\": acc, \"F1(w)\": f1w,\n",
        "        \"Prec(w)\": pw, \"Rec(w)\": rw, \"ROC-AUC OvR\": roc_ovr, \"ROC-AUC OvO\": roc_ovo,\n",
        "        \"Test CE\": test_ce, \"Train CE\": train_ce, \"Val CE\": val_ce, \"Sec/Batch\": spb, \"N\": int(y_true.size)\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ckg_ZEg0s4f"
      },
      "source": [
        "RUN TEST"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate All Four Models\n",
        "\n",
        "We run the function for the four trained variants:  \n",
        "- DistilBERT (HF-Trainer)  \n",
        "- BERTweet (HF-Trainer)  \n",
        "- DistilBERT (Full-Code)  \n",
        "- BERTweet (Full-Code)  \n",
        "\n",
        "The results are collected into a summary DataFrame, printed in a table, and exported to `test_results_summary.csv` in Drive.  \n",
        "This provides a comparison of accuracy, F1, precision/recall, ROC-AUC, cross-entropy, and runtime speed.\n"
      ],
      "metadata": {
        "id": "imimGeFyluUL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9edba1042804479a82b136f9b313e56a",
            "bb8cfa34a1e344228e29687dc7b1c831",
            "af7b6a3739284bb3b27b2060f95b02e7",
            "62a755e72fee41baa738db4243c8fc90",
            "c14268ad55b6467d981216d9fbce126b",
            "e848b0e977834aa2bd1de69722ea19b4",
            "c44a27d2b2084e8c87388e387b74b01e",
            "1dc7b9bc81754949bd593863fc220030",
            "e9a130692d7c44bc85393a4d0bb60826",
            "038350758df3424397a311ce652983d0",
            "ed4547ffcf8c41afad7684c92fb58f97",
            "6cdadaafc85646c983be4526c98703a8",
            "5ec092ab8281471e8a92a6023de28cbe",
            "d5b75e465aed4c858983c61ad42f4029",
            "9b136e6e56464ecbb41814ca5dcb4128",
            "b86e02f28254405f9ce5b717bd24c2a6",
            "4caa457727fc4374a6db2e6618a03f6f",
            "6913377a7b4a4be6b298ff756df7cd99",
            "b95d00887ed54536bfac15262cf1a0ac",
            "16876b19211e417096d3671a9bb7fbf5",
            "1e7b0eb1961c429eaf614ca8d87e1164",
            "02ea210080964d6ba8256e7b11fc5ea3",
            "bed0b4983b9b4576a6600a880bb76e21",
            "d1ad405014644da5b8980847af95304c",
            "5eed99b6222b413fb4b5ced076525938",
            "adeecb142c604009b2964b6394054510",
            "51cd25ce78ee4bffa33b80b75cb1af7d",
            "4a96ab8116fd43609576a5d31778cd1e",
            "1f9fdb59945049689281eb420b5d6653",
            "7eefd945d51e4b94934f1a008dbefbfc",
            "70bc96cccabd4bf588fd09f423207839",
            "1e29f45ec71c4acb960e62540f663c58",
            "aea447e1b47147eaa20464cbebfe2e14",
            "f318c7c4382847d5b19c240459ac5b7b",
            "8dddca5bb871409796c0cad41d85a7b0",
            "51379ca15a394e058cf0ed34c84cf26c",
            "d9aad16632a7499db1a98a63c7c6367e",
            "550727572e1b4a51bafe7d0426180e26",
            "6f44219bb029476585533087bdc03179",
            "e64e56b74ecf4137b2b8ec6f7da61c26",
            "96bcb75ff5dc416eae938d31ab50b153",
            "592d2522d832464ba606fc2843f0e23a",
            "8bf785f725994a5bbd4fe86bc942410c",
            "b681f8802978478daa029bf61792b9e8"
          ]
        },
        "id": "J9B5IAol0oWX",
        "outputId": "c4f6f3cd-95e3-45a3-dfc0-398b8cda6977"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3798 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9edba1042804479a82b136f9b313e56a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1331062942.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(v) for v in arr], batch_first=True, padding_value=pad_id\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250820_163743-wa0tho05</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/wa0tho05' target=\"_blank\">Test — DistilBERT — HF Trainer</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/wa0tho05' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/wa0tho05</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>counts/test_n</td><td>▁</td></tr><tr><td>speed/sec_per_batch</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/cross_entropy</td><td>▁</td></tr><tr><td>test/f1_weighted</td><td>▁</td></tr><tr><td>test/precision_weighted</td><td>▁</td></tr><tr><td>test/recall_weighted</td><td>▁</td></tr><tr><td>test/roc_auc_ovo</td><td>▁</td></tr><tr><td>test/roc_auc_ovr</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>counts/test_n</td><td>3798</td></tr><tr><td>posthoc/train_cross_entropy</td><td>nan</td></tr><tr><td>posthoc/val_cross_entropy</td><td>nan</td></tr><tr><td>speed/sec_per_batch</td><td>0.13794</td></tr><tr><td>test/accuracy</td><td>0.87704</td></tr><tr><td>test/cross_entropy</td><td>0.46366</td></tr><tr><td>test/f1_weighted</td><td>0.8774</td></tr><tr><td>test/precision_weighted</td><td>0.87798</td></tr><tr><td>test/recall_weighted</td><td>0.87704</td></tr><tr><td>test/roc_auc_ovo</td><td>0.95906</td></tr><tr><td>test/roc_auc_ovr</td><td>0.96233</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Test — DistilBERT — HF Trainer</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/wa0tho05' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/wa0tho05</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment</a><br>Synced 5 W&B file(s), 3 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250820_163743-wa0tho05/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== DistilBERT — HF Trainer ===\n",
            "Dir: /content/drive/MyDrive/ADV_DL/hf_best/distilbert/checkpoint-2580\n",
            "N: 3798 | Acc 0.8770 | F1w 0.8774 | Precw 0.8780 | Recallw 0.8770\n",
            "ROC-AUC OvR: 0.9623 | OvO: 0.9591\n",
            "CE test: 0.4637 | CE train: — | CE val: —\n",
            "Sec/Batch: 0.1379 | Plots: eval_plots/distilbert_-_hf_trainer_cm.png, eval_plots/distilbert_-_hf_trainer_roc.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3798 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cdadaafc85646c983be4526c98703a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1331062942.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(v) for v in arr], batch_first=True, padding_value=pad_id\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250820_163829-91ryfh02</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/91ryfh02' target=\"_blank\">Test — BERTweet   — HF Trainer</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/91ryfh02' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/91ryfh02</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>counts/test_n</td><td>▁</td></tr><tr><td>speed/sec_per_batch</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/cross_entropy</td><td>▁</td></tr><tr><td>test/f1_weighted</td><td>▁</td></tr><tr><td>test/precision_weighted</td><td>▁</td></tr><tr><td>test/recall_weighted</td><td>▁</td></tr><tr><td>test/roc_auc_ovo</td><td>▁</td></tr><tr><td>test/roc_auc_ovr</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>counts/test_n</td><td>3798</td></tr><tr><td>posthoc/train_cross_entropy</td><td>nan</td></tr><tr><td>posthoc/val_cross_entropy</td><td>nan</td></tr><tr><td>speed/sec_per_batch</td><td>0.27642</td></tr><tr><td>test/accuracy</td><td>0.62033</td></tr><tr><td>test/cross_entropy</td><td>2.2841</td></tr><tr><td>test/f1_weighted</td><td>0.66253</td></tr><tr><td>test/precision_weighted</td><td>0.85064</td></tr><tr><td>test/recall_weighted</td><td>0.62033</td></tr><tr><td>test/roc_auc_ovo</td><td>0.89182</td></tr><tr><td>test/roc_auc_ovr</td><td>0.89583</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Test — BERTweet   — HF Trainer</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/91ryfh02' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/91ryfh02</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment</a><br>Synced 5 W&B file(s), 3 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250820_163829-91ryfh02/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== BERTweet   — HF Trainer ===\n",
            "Dir: /content/drive/MyDrive/ADV_DL/hf_best/bertweet/checkpoint-5150\n",
            "N: 3798 | Acc 0.6203 | F1w 0.6625 | Precw 0.8506 | Recallw 0.6203\n",
            "ROC-AUC OvR: 0.8958 | OvO: 0.8918\n",
            "CE test: 2.2841 | CE train: — | CE val: —\n",
            "Sec/Batch: 0.2764 | Plots: eval_plots/bertweet___-_hf_trainer_cm.png, eval_plots/bertweet___-_hf_trainer_roc.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3798 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bed0b4983b9b4576a6600a880bb76e21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1331062942.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(v) for v in arr], batch_first=True, padding_value=pad_id\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250820_163854-dstbusgg</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/dstbusgg' target=\"_blank\">Test — DistilBERT — Full Code</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/dstbusgg' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/dstbusgg</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>counts/test_n</td><td>▁</td></tr><tr><td>speed/sec_per_batch</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/cross_entropy</td><td>▁</td></tr><tr><td>test/f1_weighted</td><td>▁</td></tr><tr><td>test/precision_weighted</td><td>▁</td></tr><tr><td>test/recall_weighted</td><td>▁</td></tr><tr><td>test/roc_auc_ovo</td><td>▁</td></tr><tr><td>test/roc_auc_ovr</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>counts/test_n</td><td>3798</td></tr><tr><td>posthoc/train_cross_entropy</td><td>nan</td></tr><tr><td>posthoc/val_cross_entropy</td><td>nan</td></tr><tr><td>speed/sec_per_batch</td><td>0.13582</td></tr><tr><td>test/accuracy</td><td>0.87204</td></tr><tr><td>test/cross_entropy</td><td>0.42154</td></tr><tr><td>test/f1_weighted</td><td>0.8715</td></tr><tr><td>test/precision_weighted</td><td>0.87195</td></tr><tr><td>test/recall_weighted</td><td>0.87204</td></tr><tr><td>test/roc_auc_ovo</td><td>0.95786</td></tr><tr><td>test/roc_auc_ovr</td><td>0.95939</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Test — DistilBERT — Full Code</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/dstbusgg' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/dstbusgg</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment</a><br>Synced 5 W&B file(s), 3 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250820_163854-dstbusgg/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== DistilBERT — Full Code ===\n",
            "Dir: /content/drive/MyDrive/ADV_DL/final_models/distilbert_full_code\n",
            "N: 3798 | Acc 0.8720 | F1w 0.8715 | Precw 0.8719 | Recallw 0.8720\n",
            "ROC-AUC OvR: 0.9594 | OvO: 0.9579\n",
            "CE test: 0.4215 | CE train: — | CE val: —\n",
            "Sec/Batch: 0.1358 | Plots: eval_plots/distilbert_-_full_code_cm.png, eval_plots/distilbert_-_full_code_roc.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3798 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f318c7c4382847d5b19c240459ac5b7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1331062942.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(v) for v in arr], batch_first=True, padding_value=pad_id\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250820_163942-7ngv5sjl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/7ngv5sjl' target=\"_blank\">Test — BERTweet   — Full Code</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/7ngv5sjl' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/7ngv5sjl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>counts/test_n</td><td>▁</td></tr><tr><td>speed/sec_per_batch</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/cross_entropy</td><td>▁</td></tr><tr><td>test/f1_weighted</td><td>▁</td></tr><tr><td>test/precision_weighted</td><td>▁</td></tr><tr><td>test/recall_weighted</td><td>▁</td></tr><tr><td>test/roc_auc_ovo</td><td>▁</td></tr><tr><td>test/roc_auc_ovr</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>counts/test_n</td><td>3798</td></tr><tr><td>posthoc/train_cross_entropy</td><td>nan</td></tr><tr><td>posthoc/val_cross_entropy</td><td>nan</td></tr><tr><td>speed/sec_per_batch</td><td>0.28104</td></tr><tr><td>test/accuracy</td><td>0.63402</td></tr><tr><td>test/cross_entropy</td><td>1.53463</td></tr><tr><td>test/f1_weighted</td><td>0.65401</td></tr><tr><td>test/precision_weighted</td><td>0.73846</td></tr><tr><td>test/recall_weighted</td><td>0.63402</td></tr><tr><td>test/roc_auc_ovo</td><td>0.77372</td></tr><tr><td>test/roc_auc_ovr</td><td>0.77163</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Test — BERTweet   — Full Code</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/7ngv5sjl' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/7ngv5sjl</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment</a><br>Synced 5 W&B file(s), 3 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250820_163942-7ngv5sjl/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== BERTweet   — Full Code ===\n",
            "Dir: /content/drive/MyDrive/ADV_DL/final_models/bertweet_full_code\n",
            "N: 3798 | Acc 0.6340 | F1w 0.6540 | Precw 0.7385 | Recallw 0.6340\n",
            "ROC-AUC OvR: 0.7716 | OvO: 0.7737\n",
            "CE test: 1.5346 | CE train: — | CE val: —\n",
            "Sec/Batch: 0.2810 | Plots: eval_plots/bertweet___-_full_code_cm.png, eval_plots/bertweet___-_full_code_roc.png\n",
            "\n",
            "=== Test Summary ===\n",
            "                  Model Test Acc  F1(w) Prec(w) Rec(w) ROC-AUC OvR ROC-AUC OvO Test CE Sec/Batch    N\n",
            "DistilBERT — HF Trainer   0.8770 0.8774  0.8780 0.8770      0.9623      0.9591  0.4637    0.1379 3798\n",
            "BERTweet   — HF Trainer   0.6203 0.6625  0.8506 0.6203      0.8958      0.8918  2.2841    0.2764 3798\n",
            " DistilBERT — Full Code   0.8720 0.8715  0.8719 0.8720      0.9594      0.9579  0.4215    0.1358 3798\n",
            " BERTweet   — Full Code   0.6340 0.6540  0.7385 0.6340      0.7716      0.7737  1.5346    0.2810 3798\n",
            "Saved: /content/drive/MyDrive/ADV_DL/test_results_summary.csv\n"
          ]
        }
      ],
      "source": [
        "# === Run all 4 models (HF-Trainer & Full-Code for DistilBERT/BERTweet) ===\n",
        "MODEL_DIRS = {\n",
        "    \"DistilBERT — HF Trainer\":  locals().get(\"FINAL_MODEL_DIR_DISTILBERT\") or locals().get(\"DISTIL_PATH\"),\n",
        "    \"BERTweet   — HF Trainer\":  locals().get(\"FINAL_MODEL_DIR_BERTWEET\") or locals().get(\"BERTWEET_PATH\"),\n",
        "    \"DistilBERT — Full Code\":   locals().get(\"FINAL_MODEL_DIR_DISTILBERT_FULL\"),\n",
        "    \"BERTweet   — Full Code\":   locals().get(\"FINAL_MODEL_DIR_BERTWEET_FULL\"),\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for name, mdir in MODEL_DIRS.items():\n",
        "    res = evaluate_and_log(name, mdir)\n",
        "    if res: rows.append(res)\n",
        "\n",
        "if rows:\n",
        "    df = pd.DataFrame(rows)\n",
        "    show = df.copy()\n",
        "    for c in [\"Test Acc\",\"F1(w)\",\"Prec(w)\",\"Rec(w)\",\"ROC-AUC OvR\",\"ROC-AUC OvO\",\"Test CE\",\"Train CE\",\"Val CE\",\"Sec/Batch\"]:\n",
        "        if c in show.columns:\n",
        "            show[c] = show[c].apply(lambda v: \"—\" if (v is None or (isinstance(v,float) and np.isnan(v))) else (f\"{v:.4f}\" if isinstance(v,(int,float)) else v))\n",
        "    print(\"\\n=== Test Summary ===\")\n",
        "    print(show[[\"Model\",\"Test Acc\",\"F1(w)\",\"Prec(w)\",\"Rec(w)\",\"ROC-AUC OvR\",\"ROC-AUC OvO\",\"Test CE\",\"Sec/Batch\",\"N\"]].to_string(index=False))\n",
        "    out_csv = os.path.join(BASE_DIR,\"test_results_summary.csv\") if \"BASE_DIR\" in globals() else \"test_results_summary.csv\"\n",
        "    df.to_csv(out_csv, index=False)\n",
        "    print(f\"Saved: {out_csv}\")\n",
        "else:\n",
        "    print(\"No models evaluated (check directories).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPKSDqEi1glc"
      },
      "source": [
        "# Compression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ys_P1837fFe"
      },
      "source": [
        "As said before- when trynig to save the BERTweet HF finetuned model- the runtime disconnected. Because it's one of our best models, we will need to load the best finetuned model again (feeding to it the best hyper parameters that were saved) in order to make compression to this model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoYrbxErvH2I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37bbc801-b9c4-47a7-ead5-8ea9190b1e8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# run once (top of the notebook or right before tokenizer):\n",
        "!pip -q install emoji==0.6.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQYeMlYqC8Xq"
      },
      "outputs": [],
      "source": [
        "# === BERTweet: retrain ONCE using saved best Optuna hyperparams ===\n",
        "# ---- Load best hyperparams JSON ----\n",
        "BEST_HP_PATH = os.path.join(BASE_DIR, \"hyperparams\", \"best_bertweet_hyperparams.json\")\n",
        "with open(BEST_HP_PATH, \"r\") as f:\n",
        "    best_params = json.load(f)\n",
        "\n",
        "best_lr = float(best_params[\"learning_rate\"])\n",
        "best_bs = int(best_params[\"per_device_train_batch_size\"])\n",
        "\n",
        "# ---- Output dir ----\n",
        "OUTDIR = os.path.join(BASE_DIR, \"hf_best\", \"bertweet\")\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "\n",
        "# ---- Tokenizer & Model ----\n",
        "bertweet_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"vinai/bertweet-base\", use_fast=True, normalization=True\n",
        ")\n",
        "bertweet_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"vinai/bertweet-base\", num_labels=NUM_LABELS\n",
        ")\n",
        "\n",
        "# ---- Collator ----\n",
        "data_collator = DataCollatorWithPadding(tokenizer=bertweet_tokenizer)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTDIR,\n",
        "    learning_rate=best_lr,\n",
        "    per_device_train_batch_size=best_bs,\n",
        "    per_device_eval_batch_size=max(32, best_bs),\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=100,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    seed=42,\n",
        "    do_eval=True,        # enables evaluation each epoch\n",
        "    save_steps=500,      # checkpoint every N steps (set N to what fits your data/compute)\n",
        "    eval_steps=500,      # run eval every N steps (must match save_steps if you want best model later)\n",
        "    save_total_limit=1,  # keep only the most recent checkpoint\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=bertweet_model,\n",
        "    args=training_args,  # same as above (metric_* can stay or be removed)\n",
        "    train_dataset=hf_train_dataset_bertweet,\n",
        "    eval_dataset=hf_val_dataset_bertweet,\n",
        "    tokenizer=bertweet_tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# ---- Train / Eval / Save ----\n",
        "trainer.train()\n",
        "print(trainer.evaluate())\n",
        "\n",
        "trainer.save_model(OUTDIR)\n",
        "bertweet_tokenizer.save_pretrained(OUTDIR)\n",
        "\n",
        "print(f\"\\nSaved fine-tuned BERTweet to: {OUTDIR}\\nReady for compression.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MY6Wcs5xRZTh",
        "outputId": "4b81c37f-973a-409e-bc2a-02887d2eb4ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ BERTweet model restored successfully\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Path to your fine-tuned BERTweet folder\n",
        "BERTWEET_PATH = f\"{BASE_DIR}/hf_best/bertweet\"\n",
        "\n",
        "# Load fine-tuned BERTweet\n",
        "bertweet_tokenizer = AutoTokenizer.from_pretrained(BERTWEET_PATH)\n",
        "bertweet_model = AutoModelForSequenceClassification.from_pretrained(BERTWEET_PATH)\n",
        "\n",
        "print(\"✅ BERTweet model restored successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3aHWdJYJGSI"
      },
      "source": [
        "We now see that it also didn't save the distilBERT best model (cause the drive storage was full). We will now do the same for distilBERT after buying more drive storage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dAXK6HZqKvIg",
        "outputId": "907ab7a5-15e5-49e4-ca8c-fb89819eb623"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1896632055.py:45: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2580/2580 16:20, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.818600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.568300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.445400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.385100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.351100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.287000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.282100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.252700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.208000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.208000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.181300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.160000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.159100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.130900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.130200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.121600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.120800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.112100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.102700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.093000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.090300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.077800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.086000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.075900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.078300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [65/65 00:05]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.3942674994468689, 'eval_accuracy': 0.8933430515063168, 'eval_f1': 0.8935220792099944, 'eval_precision': 0.8937617669796839, 'eval_recall': 0.8933430515063168, 'eval_runtime': 6.1132, 'eval_samples_per_second': 1346.593, 'eval_steps_per_second': 10.633, 'epoch': 10.0}\n",
            "\n",
            "✅ DistilBERT retrained with best hyperparams and saved to: /content/drive/MyDrive/ADV_DL/hf_best/distilbert\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ---- Load best hyperparams (from Optuna JSON) ----\n",
        "BEST_HP_PATH = os.path.join(BASE_DIR, \"hyperparams\", \"best_distilbert_hyperparams.json\")\n",
        "with open(BEST_HP_PATH, \"r\") as f:\n",
        "    best_params = json.load(f)\n",
        "\n",
        "best_lr = float(best_params[\"learning_rate\"])\n",
        "best_bs = int(best_params[\"per_device_train_batch_size\"])\n",
        "\n",
        "# ---- Output dir ----\n",
        "OUTDIR = os.path.join(BASE_DIR, \"hf_best\", \"distilbert\")\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "\n",
        "# ---- Tokenizer & Model ----\n",
        "distilbert_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "distilbert_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\", num_labels=NUM_LABELS\n",
        ")\n",
        "\n",
        "# ---- Collator ----\n",
        "data_collator = DataCollatorWithPadding(tokenizer=distilbert_tokenizer)\n",
        "\n",
        "# ---- TrainingArguments ----\n",
        "# Use only arguments that work across old/new transformers versions\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTDIR,\n",
        "    learning_rate=best_lr,\n",
        "    per_device_train_batch_size=best_bs,\n",
        "    per_device_eval_batch_size=max(32, best_bs),\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=100,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    seed=42,\n",
        "    do_eval=True  # ensures evaluation happens during training\n",
        ")\n",
        "\n",
        "# ---- Trainer ----\n",
        "trainer = Trainer(\n",
        "    model=distilbert_model,\n",
        "    args=training_args,\n",
        "    train_dataset=hf_train_dataset_distilbert,\n",
        "    eval_dataset=hf_val_dataset_distilbert,\n",
        "    tokenizer=distilbert_tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# ---- Train ONCE and Save ----\n",
        "trainer.train()\n",
        "print(trainer.evaluate())\n",
        "\n",
        "trainer.save_model(OUTDIR)\n",
        "distilbert_tokenizer.save_pretrained(OUTDIR)\n",
        "\n",
        "print(f\"\\n✅ DistilBERT retrained with best hyperparams and saved to: {OUTDIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo5ocZmmNvC1",
        "outputId": "257b77f2-b63b-44dc-d417-aab4e74b79e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ distilbert model restored successfully\n"
          ]
        }
      ],
      "source": [
        "DISTIL_PATH = f\"{BASE_DIR}/hf_best/distilbert\"\n",
        "\n",
        "distilbert_model = AutoModelForSequenceClassification.from_pretrained(DISTIL_PATH)\n",
        "distilbert_tokenizer = AutoTokenizer.from_pretrained(DISTIL_PATH)\n",
        "print(\"✅ distilbert model restored successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the best 2 models:"
      ],
      "metadata": {
        "id": "uouE8t5tvHvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = \"/content/drive/MyDrive/ADV_DL\"\n",
        "HF_BEST = f\"{BASE_DIR}/hf_best\"\n",
        "os.makedirs(HF_BEST, exist_ok=True)\n",
        "\n",
        "# Load fine-tuned teachers *from Drivae*\n",
        "DISTIL_PATH   = f\"{HF_BEST}/distilbert\"\n",
        "BERTWEET_PATH = f\"{HF_BEST}/bertweet\""
      ],
      "metadata": {
        "id": "wHTCGcdRn-sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGOoZDF6ArTP"
      },
      "source": [
        "# Model Compression — DistilBERT & BERTweet\n",
        "\n",
        "In this section we apply three different compression methods to our fine-tuned models:\n",
        "\n",
        "1. **Dynamic Quantization** — reduces model size by converting weights to int8.  \n",
        "2. **Pruning** — zeroes out less important weights to sparsify the model.  \n",
        "3. **Knowledge Distillation** — trains a smaller student model using predictions (soft labels) from the teacher model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DL-VUe9XIF0"
      },
      "source": [
        "### 1. Dynamic Quantization\n",
        "We first apply dynamic quantization to both fine-tuned models.  \n",
        "This is the fastest compression method — it converts linear layers to 8-bit integers, reducing size and improving inference speed.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Force CPU + eval (dynamic quantization is CPU-only)\n",
        "distilbert_model = distilbert_model.to(\"cpu\").eval()\n",
        "bertweet_model   = bertweet_model.to(\"cpu\").eval()"
      ],
      "metadata": {
        "id": "izHRSqcSiHhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dynamic INT8 quantization on Linear layers\n",
        "quantized_distilbert = torch.quantization.quantize_dynamic(\n",
        "    distilbert_model, {nn.Linear}, dtype=torch.qint8\n",
        ").eval()\n",
        "\n",
        "quantized_bertweet = torch.quantization.quantize_dynamic(\n",
        "    bertweet_model, {nn.Linear}, dtype=torch.qint8\n",
        ").eval()"
      ],
      "metadata": {
        "id": "QesAOlW9tVyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save quantized models for *your* local comparison runs (not required for submission)\n",
        "Q_OUT_DIR = f\"{BASE_DIR}/hf_best\"\n",
        "import os; os.makedirs(Q_OUT_DIR, exist_ok=True)\n",
        "\n",
        "torch.save(quantized_distilbert, f\"{Q_OUT_DIR}/distilbert_quantized.pth\")\n",
        "torch.save(quantized_bertweet,   f\"{Q_OUT_DIR}/bertweet_quantized.pth\")\n",
        "\n",
        "print(\"Saved quantized models to:\")\n",
        "print(f\"- {Q_OUT_DIR}/distilbert_quantized.pth\")\n",
        "print(f\"- {Q_OUT_DIR}/bertweet_quantized.pth\")\n"
      ],
      "metadata": {
        "id": "TsAg0kgXdc93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rN_4-uZrUZO7"
      },
      "source": [
        "#### Evaluation of Models\n",
        "After each compression method, we will evaluate the effect of the compression on both DistilBERT and BERTweet:\n",
        "\n",
        "- **Model size** on disk (before vs. after compression).  \n",
        "- **Validation accuracy** using the same evaluation function.  \n",
        "- **Inference speed** on a small batch of validation data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zw8aXgFTJrk",
        "outputId": "af063209-a508-451e-f1b4-2dcaac8d894e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DistilBERT: Original = 255.43 MB | Quantized = 132.29 MB\n",
            "BERTweet  : Original = 514.63 MB | Quantized = 270.06 MB\n"
          ]
        }
      ],
      "source": [
        "# Define quantized model file paths (already saved as .pth earlier)\n",
        "quant_distil_path   = \"/content/drive/MyDrive/ADV_DL/hf_best/distilbert_quantized.pth\"\n",
        "quant_bertweet_path = \"/content/drive/MyDrive/ADV_DL/hf_best/bertweet_quantized.pth\"\n",
        "\n",
        "def get_model_file(path):\n",
        "    \"\"\"Return model weight file (safetensors or bin)\"\"\"\n",
        "    if os.path.exists(os.path.join(path, \"pytorch_model.bin\")):\n",
        "        return os.path.join(path, \"pytorch_model.bin\")\n",
        "    elif os.path.exists(os.path.join(path, \"model.safetensors\")):\n",
        "        return os.path.join(path, \"model.safetensors\")\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"No model weight file found in {path}\")\n",
        "\n",
        "def get_size(path):\n",
        "    return os.path.getsize(path) / (1024 * 1024)  # MB\n",
        "\n",
        "# Original model sizes\n",
        "orig_distil_file   = get_model_file(DISTIL_PATH)\n",
        "orig_bertweet_file = get_model_file(BERTWEET_PATH)\n",
        "\n",
        "orig_distil_size   = get_size(orig_distil_file)\n",
        "orig_bertweet_size = get_size(orig_bertweet_file)\n",
        "\n",
        "# Quantized model sizes (saved as .pth)\n",
        "quant_distil_size   = get_size(quant_distil_path)\n",
        "quant_bertweet_size = get_size(quant_bertweet_path)\n",
        "\n",
        "print(f\"DistilBERT: Original = {orig_distil_size:.2f} MB | Quantized = {quant_distil_size:.2f} MB\")\n",
        "print(f\"BERTweet  : Original = {orig_bertweet_size:.2f} MB | Quantized = {quant_bertweet_size:.2f} MB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-ZFZdm9UdmO",
        "outputId": "1bef5b36-e5d1-4711-bc01-3ae15d372671"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Quantized DistilBERT Accuracy: 0.8860\n",
            " Quantized BERTweet  Accuracy: 0.2100\n"
          ]
        }
      ],
      "source": [
        "def evaluate_model(model, tokenizer, dataset, n_samples=500):\n",
        "    \"\"\"\n",
        "    Evaluate accuracy of a model on a subset of dataset for speed.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "    dataloader = DataLoader(dataset, batch_size=32, collate_fn=data_collator)\n",
        "\n",
        "    preds, labels = [], []\n",
        "    seen = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        labels_batch = batch.pop(\"labels\")\n",
        "        batch = {k: v.to(model.device) for k, v in batch.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        batch_preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "        preds.extend(batch_preds)\n",
        "        labels.extend(labels_batch.numpy())\n",
        "\n",
        "        seen += len(labels_batch)\n",
        "        if seen >= n_samples:\n",
        "            break\n",
        "\n",
        "    return accuracy_score(labels[:n_samples], preds[:n_samples])\n",
        "\n",
        "# --- Run eval on quantized models ---\n",
        "acc_distil_q = evaluate_model(quantized_distilbert, distilbert_tokenizer, hf_val_dataset_distilbert)\n",
        "acc_bertweet_q = evaluate_model(quantized_bertweet, bertweet_tokenizer, hf_val_dataset_bertweet)\n",
        "\n",
        "print(f\" Quantized DistilBERT Accuracy: {acc_distil_q:.4f}\")\n",
        "print(f\" Quantized BERTweet  Accuracy: {acc_bertweet_q:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwreenqLUhA1",
        "outputId": "8deb2f1a-bda7-4c39-86c7-55e31bbe0fd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantized DistilBERT Inference time per batch: 2.6154 sec\n",
            "Quantized BERTweet  Inference time per batch: 5.0927 sec\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def measure_inference_time(model, tokenizer, dataset, n_batches=20):\n",
        "    \"\"\"\n",
        "    Measure average inference time per batch.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "    dataloader = DataLoader(dataset, batch_size=32, collate_fn=data_collator)\n",
        "\n",
        "    start = time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(dataloader):\n",
        "            _labels = batch.pop(\"labels\")  # remove labels\n",
        "            batch = {k: v.to(model.device) for k, v in batch.items()}\n",
        "            _ = model(**batch)\n",
        "            if i + 1 >= n_batches:\n",
        "                break\n",
        "    end = time.time()\n",
        "\n",
        "    return (end - start) / n_batches  # seconds per batch\n",
        "\n",
        "time_distil_q = measure_inference_time(quantized_distilbert, distilbert_tokenizer, hf_val_dataset_distilbert)\n",
        "time_bertweet_q = measure_inference_time(quantized_bertweet, bertweet_tokenizer, hf_val_dataset_bertweet)\n",
        "\n",
        "print(f\"Quantized DistilBERT Inference time per batch: {time_distil_q:.4f} sec\")\n",
        "print(f\"Quantized BERTweet  Inference time per batch: {time_bertweet_q:.4f} sec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNZEr7mYVpzS"
      },
      "source": [
        "### 2. Pruning (Unstructured L1)\n",
        "\n",
        "We prune the smallest-magnitude weights in all `Linear` layers (global unstructured pruning).\n",
        "- **Goal:** induce sparsity (fewer effective parameters) → potential speedups and regularization.\n",
        "- **Note:** Disk size usually doesn’t shrink with plain pruning, because weights are stored densely; we’ll report **sparsity** and **runtime** changes.  \n",
        "- **Optional:** a brief post-pruning fine-tune (1 epoch) can help recover accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQq9ku3mWQcJ"
      },
      "source": [
        "Utilities + pick layers to prune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoZZTWp3U-KX"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def get_linear_modules(model):\n",
        "    \"\"\"\n",
        "    Return a list of (module_ref, 'weight') for all Linear layers in the model,\n",
        "    which is what global_unstructured expects.\n",
        "    \"\"\"\n",
        "    params_to_prune = []\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, Linear):\n",
        "            params_to_prune.append((module, \"weight\"))\n",
        "    return params_to_prune\n",
        "\n",
        "def apply_global_pruning(model, amount=0.30):\n",
        "    \"\"\"\n",
        "    Apply global unstructured L1 pruning to all Linear weights.\n",
        "    `amount` is the fraction of connections to prune globally.\n",
        "    \"\"\"\n",
        "    params_to_prune = get_linear_modules(model)\n",
        "    prune.global_unstructured(\n",
        "        params_to_prune,\n",
        "        pruning_method=prune.L1Unstructured,\n",
        "        amount=amount,\n",
        "    )\n",
        "    return params_to_prune\n",
        "\n",
        "def make_pruning_permanent(params_to_prune):\n",
        "    \"\"\"\n",
        "    Remove pruning reparametrizations to make zeros permanent in the weights.\n",
        "    \"\"\"\n",
        "    for module, param_name in params_to_prune:\n",
        "        prune.remove(module, param_name)\n",
        "\n",
        "def tensor_sparsity(t):\n",
        "    num_zeros = torch.sum(t == 0).item()\n",
        "    num_elems = t.numel()\n",
        "    return num_zeros / max(1, num_elems)\n",
        "\n",
        "def model_sparsity(model):\n",
        "    total_zeros, total_params = 0, 0\n",
        "    for p in model.parameters():\n",
        "        if p is not None and p.data is not None:\n",
        "            total_zeros += torch.sum(p.data == 0).item()\n",
        "            total_params += p.data.numel()\n",
        "    return total_zeros / max(1, total_params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj4vLzE3WUDr"
      },
      "source": [
        "Prune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBPNdDvuWPy0",
        "outputId": "011f72b6-fec1-48b9-ed06-1730ecd189ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Applied global L1 pruning @ 30%\n",
            "DistilBERT sparsity: 0.00%\n",
            "BERTweet  sparsity: 0.00%\n"
          ]
        }
      ],
      "source": [
        "# Choose pruning amount (start moderate; you can sweep later: 0.2, 0.3, 0.5)\n",
        "PRUNE_AMOUNT = 0.30\n",
        "\n",
        "# --- DistilBERT pruning ---\n",
        "distil_params = apply_global_pruning(distilbert_model, amount=PRUNE_AMOUNT)\n",
        "distil_sparsity = model_sparsity(distilbert_model)\n",
        "make_pruning_permanent(distil_params)  # bake zeros into weights\n",
        "\n",
        "# --- BERTweet pruning ---\n",
        "bertweet_params = apply_global_pruning(bertweet_model, amount=PRUNE_AMOUNT)\n",
        "bertweet_sparsity = model_sparsity(bertweet_model)\n",
        "make_pruning_permanent(bertweet_params)\n",
        "\n",
        "print(f\"✅ Applied global L1 pruning @ {PRUNE_AMOUNT*100:.0f}%\")\n",
        "print(f\"DistilBERT sparsity: {distil_sparsity*100:.2f}%\")\n",
        "print(f\"BERTweet  sparsity: {bertweet_sparsity*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-yIeql2Wtzt"
      },
      "source": [
        "Save Pruned Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-oxq4mtWr2v",
        "outputId": "5ae1b220-5052-46db-ea43-e06849a9999d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Pruned models saved:\n",
            " - /content/drive/MyDrive/ADV_DL/hf_best/distilbert_pruned_30\n",
            " - /content/drive/MyDrive/ADV_DL/hf_best/bertweet_pruned_30\n"
          ]
        }
      ],
      "source": [
        "PRUNED_DISTIL_PATH = f\"{DISTIL_PATH}_pruned_{int(PRUNE_AMOUNT*100)}\"\n",
        "PRUNED_BERTWEET_PATH = f\"{BERTWEET_PATH}_pruned_{int(PRUNE_AMOUNT*100)}\"\n",
        "\n",
        "distilbert_model.save_pretrained(PRUNED_DISTIL_PATH)\n",
        "distilbert_tokenizer.save_pretrained(PRUNED_DISTIL_PATH)\n",
        "\n",
        "bertweet_model.save_pretrained(PRUNED_BERTWEET_PATH)\n",
        "bertweet_tokenizer.save_pretrained(PRUNED_BERTWEET_PATH)\n",
        "\n",
        "print(\"✅ Pruned models saved:\")\n",
        "print(f\" - {PRUNED_DISTIL_PATH}\")\n",
        "print(f\" - {PRUNED_BERTWEET_PATH}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6fJUisnYNQc"
      },
      "source": [
        "Pruning Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPaGvorAWvnF",
        "outputId": "3b6618fe-7a0a-4b94-e4f3-ab66f52da2e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DistilBERT sparsity now: 19.29%\n",
            "BERTweet  sparsity now: 19.02%\n",
            "Pruned DistilBERT Accuracy: 0.8980\n",
            "Pruned BERTweet  Accuracy: 0.9080\n",
            "Pruned DistilBERT Inference time per batch: 2.9027 sec\n",
            "Pruned BERTweet  Inference time per batch: 5.5222 sec\n"
          ]
        }
      ],
      "source": [
        "# Sparsity already printed; we re-run just in case of recovery\n",
        "print(f\"DistilBERT sparsity now: {model_sparsity(distilbert_model)*100:.2f}%\")\n",
        "print(f\"BERTweet  sparsity now: {model_sparsity(bertweet_model)*100:.2f}%\")\n",
        "\n",
        "# Accuracy (use a smaller sample for speed; bump to full for final report)\n",
        "acc_distil_pruned = evaluate_model(distilbert_model, distilbert_tokenizer, hf_val_dataset_distilbert, n_samples=1000)\n",
        "acc_bertweet_pruned = evaluate_model(bertweet_model, bertweet_tokenizer, hf_val_dataset_bertweet, n_samples=1000)\n",
        "\n",
        "print(f\"Pruned DistilBERT Accuracy: {acc_distil_pruned:.4f}\")\n",
        "print(f\"Pruned BERTweet  Accuracy: {acc_bertweet_pruned:.4f}\")\n",
        "\n",
        "# Inference speed (same batch sizing as quant)\n",
        "time_distil_pruned = measure_inference_time(distilbert_model, distilbert_tokenizer, hf_val_dataset_distilbert, n_batches=20)\n",
        "time_bertweet_pruned = measure_inference_time(bertweet_model, bertweet_tokenizer, hf_val_dataset_bertweet, n_batches=20)\n",
        "\n",
        "print(f\"Pruned DistilBERT Inference time per batch: {time_distil_pruned:.4f} sec\")\n",
        "print(f\"Pruned BERTweet  Inference time per batch: {time_bertweet_pruned:.4f} sec\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkKXP3tsY54g"
      },
      "source": [
        "### 3. Knowledge Distillation (Teacher → Student)\n",
        "Train a smaller student model that mimics a larger fine-tuned teacher, reducing model size and inference cost while retaining accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_472Tl4VcbmO"
      },
      "source": [
        "**3.1 Knowledge Distillation for DistilBERT**\n",
        "\n",
        "- **Teacher:** fine-tuned `distilbert-base-uncased` (already loaded as `distilbert_model`)\n",
        "- **Student:** `prajjwal1/bert-tiny` (a compact BERT variant, much faster)\n",
        "- **Datasets:** reuse `hf_train_dataset_distilbert` and `hf_val_dataset_distilbert`  \n",
        "  (compatible tokenizer families, no need for re-tokenization)\n",
        "- **Objective:** Compress the fine-tuned DistilBERT into a tiny model while keeping reasonable accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KD hyperparameters (optional read)**\n",
        "\n",
        "KD_TEMPERATURE softens the teacher’s probabilities so the student learns class similarities, not just the top class. Values around 2–4 usually work well.\n",
        "\n",
        "ALPHA_CE vs ALPHA_KD balance “learn from ground-truth labels” (CE) and “match the teacher” (KD); 0.5/0.5 is a solid default—raise CE if labels are very reliable, raise KD if you trust the teacher more.\n",
        "\n",
        "STUDENT_NAME picks a small model (prajjwal1/bert-tiny) for speed; we use the matching BERT vocab tokenizer (bert-base-uncased).\n",
        "\n",
        "DataCollatorWithPadding pads batches on the fly with the student tokenizer so inputs are shaped correctly for training."
      ],
      "metadata": {
        "id": "AseArvs5oJ_m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244,
          "referenced_widgets": [
            "96044298938747a1a09156c9e1228e6a",
            "6b9af207d4ec4fe38d20ad1e857fe9c7",
            "68eaed5efd1f4a02994f84d1eab2a81e",
            "84120f445d3f48b999edbcde57f039e6",
            "08b9d4279323448d9e08a9d2c6fdd657",
            "24faffb0f2cc493b81be853e98d15c32",
            "9f7e50698a994055bd579c027eeb6f83",
            "09559db97be845618bf6ee17a03fcc06",
            "0956bce2899a4ebabc94385057f7df46",
            "7bac0ee1fac24534a5508edb5b95b13b",
            "4ee32d87b5e441a3addf947884e0adaf",
            "69badcd6913c417f861ab43d14d83ecf",
            "031142b2e3ac482094d50bb23b4a7002",
            "9114a982a3d9491a9f9a91e9a08b2a2d",
            "e3b512a6bf08468998b627672ffae1d2",
            "d18bd629a3b7439e8b540a42d0e531b3",
            "b574a0bad93548d7b674966cda3cd628",
            "00e37e0f93754189828201a2d8b41851",
            "6a0e67332816456a8b8958b6ec655ba7",
            "4b97034662c24ae5b2fc47806cae5624",
            "c7dbfeab2af744729285168187bf164d",
            "2354cf539d8e442ab6cd96da6bf250df",
            "71bfa449a40446169ead01da5ff90f66",
            "ec96dfc4dc3240b882b477f4d13ac9bc",
            "ec554037107d43a6a38c3f99b2fe0385",
            "10590409029146caa83437d477e78e1b",
            "041edde5a8bd4b569993f53d3cf26fdd",
            "b3e3507ed2214f13ac060547936d75e9",
            "0ed6ab84876949b3ba6c42dae4da0af9",
            "27c9fd3f410a4f499214833a91490f5d",
            "fe849d3c0cb843faa080bea83a0e6963",
            "3444008a5fae481eae6115d1e641def7",
            "162e14b7200e48dba8825aaeebc7a36d",
            "924732cc80d3413cad8073893b910798",
            "f0a445082eb843728c6774a311013bf4",
            "65c8a3e82db3421b8f9d6df299ce3b9c",
            "5bd46bdebba14971991dcf895d95db67",
            "b0d836922c274d19bad1ad786004c440",
            "bfbb99e1654b497c801256f6cfe59ecf",
            "f83d081c31984c19b819bdd147f68f75",
            "add0cfe5e3bf461995759a8574c96968",
            "93f2c56396a54e7eace17c59eb56814a",
            "e9b5c06104994b0f93f2e27a68ac4791",
            "d0f0e65a087145bfbd03fad72350b471",
            "0f80026ec6c748cbbcfac2fdce479fab",
            "33c0114e93eb403aa62960f1c1afeaed",
            "c05ae15a3d3249da845a07b90214a039",
            "5d197134c6d44f9cae581d9f86b6e49d",
            "2e4fa6c2c36846e095b80b7c5af2698e",
            "2ba82261caac44268478b80a419c533e",
            "d559e7a6bd1a49efa03ad4fbf6c2a88a",
            "b37d4a10643f4e57adea9f7f5757620c",
            "8cf43d98a7754984a33a899b8f6fd99a",
            "17aa28ae0025453d91d3a55a6874e25e",
            "e07bdd6d77bd42e598a6f7fee72ea3a1",
            "1b72cbddf36148198432bdd3c0c189be",
            "2f344c3a023842738909224226992cae",
            "77d7ebc6ae8542399c0be50ca9d9467f",
            "282373747e57472687a6b935bacdd2db",
            "5961190ae3b74ce484bd9a3bcc7a1143",
            "ab1a364d1eee4127ac3d7d3de675f6cf",
            "28eeb00e66254e219cb07c5e6de951bb",
            "dbb4600683f4483a849e92eff04eadd4",
            "64b33ac07d9247f49e85a4da2d81aa4f",
            "29e88278615d4f4bbd62ff69da848e73",
            "3298f42445a84befb7be6a74bdc6994d"
          ]
        },
        "id": "WU3iE_j5YL8A",
        "outputId": "66929dd4-2b3b-4888-afe7-9218aab2b935"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96044298938747a1a09156c9e1228e6a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69badcd6913c417f861ab43d14d83ecf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71bfa449a40446169ead01da5ff90f66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "924732cc80d3413cad8073893b910798",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f80026ec6c748cbbcfac2fdce479fab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/285 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b72cbddf36148198432bdd3c0c189be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/17.8M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# ---- KD hyperparameters ----\n",
        "KD_TEMPERATURE = 2.0     # softening factor for logits\n",
        "ALPHA_CE      = 0.5      # weight for hard-label cross-entropy\n",
        "ALPHA_KD      = 0.5      # weight for KL(student || teacher_soft)\n",
        "\n",
        "# ---- Student: tiny BERT (compatible tokenizer family with distilbert) ----\n",
        "STUDENT_NAME = \"prajjwal1/bert-tiny\"\n",
        "student_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")  # tiny-bert uses bert-base-uncased vocab\n",
        "student_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    STUDENT_NAME, num_labels=NUM_LABELS\n",
        ")\n",
        "\n",
        "# ---- Data collator (same as training/eval) ----\n",
        "data_collator_distil = DataCollatorWithPadding(tokenizer=student_tokenizer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Distillation Trainer**\n",
        "\n",
        "* Wraps Hugging Face Trainer to do knowledge distillation.\n",
        "\n",
        "* Freezes the teacher (no gradients) and keeps it on the same device as the student for safe mixed-GPU/CPU setups.\n",
        "\n",
        "- In compute_loss:\n",
        "\n",
        "  - Separates labels from the student inputs and re-asserts device alignment.\n",
        "\n",
        "  - Runs student and teacher forward passes (teacher under no_grad).\n",
        "\n",
        "  - Computes two losses:\n",
        "\n",
        "    - CE loss: student vs. ground-truth labels.\n",
        "\n",
        "    - KD loss: KL divergence between temperature-softened student and teacher logits (T = temperature, with the standard T² scaling).\n",
        "  \n",
        "- Returns the weighted sum: alpha_ce * CE + alpha_kd * KD."
      ],
      "metadata": {
        "id": "leNP5PJYojdt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTQX4Jy0aLcp"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DistillationTrainer(Trainer):\n",
        "    def __init__(self, teacher_model=None, temperature=2.0, alpha_ce=0.5, alpha_kd=0.5, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Keep teacher frozen and ON THE SAME DEVICE as the student/Trainer\n",
        "        self.teacher = teacher_model\n",
        "        for p in self.teacher.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        # Use Trainer's device (GPU if available)\n",
        "        device = self.args.device if hasattr(self, \"args\") else (\n",
        "            torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        )\n",
        "        self.teacher.to(device).eval()\n",
        "\n",
        "        self.temperature = temperature\n",
        "        self.alpha_ce = alpha_ce\n",
        "        self.alpha_kd = alpha_kd\n",
        "\n",
        "    # Accept extra kwargs like num_items_in_batch from newer HF\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs[\"labels\"]\n",
        "        student_inputs = {k: v for k, v in inputs.items() if k != \"labels\"}\n",
        "\n",
        "        # Ensure teacher is still on the same device as model/inputs (robustness)\n",
        "        # (If accelerate moves model later, this keeps them aligned)\n",
        "        self.teacher.to(next(model.parameters()).device)\n",
        "\n",
        "        # Student forward\n",
        "        outputs_s = model(**student_inputs)\n",
        "        logits_s = outputs_s.logits\n",
        "\n",
        "        # Teacher forward (no grad)\n",
        "        with torch.no_grad():\n",
        "            outputs_t = self.teacher(**student_inputs)\n",
        "            logits_t = outputs_t.logits\n",
        "\n",
        "        # Losses\n",
        "        loss_ce = F.cross_entropy(logits_s, labels)\n",
        "        T = self.temperature\n",
        "        loss_kd = F.kl_div(\n",
        "            F.log_softmax(logits_s / T, dim=-1),\n",
        "            F.softmax(logits_t / T, dim=-1),\n",
        "            reduction=\"batchmean\"\n",
        "        ) * (T * T)\n",
        "\n",
        "        loss = self.alpha_ce * loss_ce + self.alpha_kd * loss_kd\n",
        "        return (loss, outputs_s) if return_outputs else loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Knowledge Distillation — Train & Save bert-tiny (student) from DistilBERT (teacher)**\n",
        "\n",
        "- Sets TrainingArguments for a short KD run (3 epochs, bs=32, LR=2e-4, no W&B logging).\n",
        "\n",
        "- Uses the custom DistillationTrainer with:\n",
        "\n",
        "  - Teacher: your fine-tuned distilbert_model (frozen).\n",
        "\n",
        "  - Student: prajjwal1/bert-tiny.\n",
        "  \n",
        "  - Loss mix: alpha_ce=0.5 (hard labels) + alpha_kd=0.5 (teacher soft targets) at temperature=2.0.\n",
        "\n",
        "- Datasets: hf_train_dataset_distilbert / hf_val_dataset_distilbert; padding handled by DataCollatorWithPadding.\n",
        "\n",
        "- Metrics: compute_metrics on the eval-split each epoch.\n",
        "\n",
        "- After training, prints the evaluation dict and saves the distilled student (model + tokenizer) to drive."
      ],
      "metadata": {
        "id": "P7Tvyv1gptbV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j-yvfAH9aN8R",
        "outputId": "841dc773-e4fb-47a6-db68-870ba6baf721"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3087' max='3087' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3087/3087 04:54, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.219700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.182100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.217600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.201300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.220500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.195200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.214600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.224800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.186500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.201400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.171300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.178900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.162100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.167100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.181000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.164300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.200200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.187500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.192800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.180700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.154200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.142800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.153100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.146500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.191500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.185000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.193900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.173300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.197900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='258' max='258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [258/258 00:22]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Distillation Student Results:\n",
            "{'eval_loss': 0.543489396572113, 'eval_accuracy': 0.8526482021379981, 'eval_f1': 0.8519710288825878, 'eval_precision': 0.8535263308933317, 'eval_recall': 0.8526482021379981, 'eval_runtime': 22.8267, 'eval_samples_per_second': 360.63, 'eval_steps_per_second': 11.303, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/ADV_DL/kd_student_distilbert/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/ADV_DL/kd_student_distilbert/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/ADV_DL/kd_student_distilbert/vocab.txt',\n",
              " '/content/drive/MyDrive/ADV_DL/kd_student_distilbert/added_tokens.json',\n",
              " '/content/drive/MyDrive/ADV_DL/kd_student_distilbert/tokenizer.json')"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "kd_args = TrainingArguments(\n",
        "    output_dir=f\"{DISTIL_PATH}_kd_bert_tiny\",\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.0,\n",
        "    logging_steps=100,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    seed=42,\n",
        "    do_eval=True,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "kd_trainer = DistillationTrainer(\n",
        "    teacher_model=distilbert_model,            # TEACHER (fine-tuned DistilBERT)\n",
        "    temperature=2.0,\n",
        "    alpha_ce=0.5,\n",
        "    alpha_kd=0.5,\n",
        "    model=student_model,                       # STUDENT (bert-tiny)\n",
        "    args=kd_args,\n",
        "    train_dataset=hf_train_dataset_distilbert,\n",
        "    eval_dataset=hf_val_dataset_distilbert,\n",
        "    processing_class=student_tokenizer,        # <- deprecation-safe (instead of tokenizer=)\n",
        "    data_collator=data_collator_distil,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train\n",
        "kd_trainer.train()\n",
        "\n",
        "# Evaluate and store results\n",
        "results = kd_trainer.evaluate()\n",
        "print(\"📊 Distillation Student Results:\")\n",
        "print(results)\n",
        "\n",
        "# Save student (distilled) model\n",
        "student_model.save_pretrained(\"/content/drive/MyDrive/ADV_DL/kd_student_distilbert\")\n",
        "student_tokenizer.save_pretrained(\"/content/drive/MyDrive/ADV_DL/kd_student_distilbert\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXrVXrIVcrFl"
      },
      "source": [
        "**3.2 Knowledge Distillation for BERTweet**\n",
        "\n",
        "- **Teacher:** fine-tuned `vinai/bertweet-base`\n",
        "- **Student:** `distilroberta-base` (smaller RoBERTa variant, good match since BERTweet is RoBERTa-based)\n",
        "- **Tokenizer handling:**\n",
        "  - Teacher and student tokenizers differ → need raw text + labels dataset\n",
        "  - Student inputs: tokenized with student tokenizer\n",
        "  - Teacher logits: computed dynamically inside the trainer\n",
        "- **Objective:** Transfer BERTweet’s knowledge into a smaller, more efficient RoBERTa student"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "qmDIcpEkjYCD"
      },
      "outputs": [],
      "source": [
        "# ---- Paths ----\n",
        "TEACHER_PATH = f\"{BASE_DIR}/hf_best/bertweet\"              # fine-tuned BERTweet teacher\n",
        "STUDENT_NAME = \"distilroberta-base\"                        # student model\n",
        "KD_SAVE_DIR  = f\"{BASE_DIR}/hf_best/bertweet_kd_student\"   # distilled student"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Need to run this again as runtime disconnected\n",
        "# ---- KD hyperparameters ----\n",
        "KD_TEMPERATURE = 2.0\n",
        "ALPHA_CE       = 0.5\n",
        "ALPHA_KD       = 0.5\n",
        "MAX_LENGTH     = MAX_SEQ_LENGTH"
      ],
      "metadata": {
        "id": "HU-P715Jv363"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Freeze Teacher & Precompute Logits (BERTweet → DistilRoBERTa)**\n",
        "\n",
        "- load the fine-tuned BERTweet as the frozen teacher (TEACHER_PATH), pick DistilRoBERTa as the student (STUDENT_NAME), and set KD_SAVE_DIR for outputs.\n",
        "\n",
        "- Freeze teacher- move to device, eval(), and disable grads.\n",
        "\n",
        "- Label mapping from the teacher so student predictions align.\n",
        "\n",
        "- Student tokenizer & init: create a model_init() that builds DistilRoBERTa with the same label mapping.\n",
        "\n",
        "- TeacherOnlyCollator: pads teacher inputs (already BERTweet-tokenized HF datasets) for efficient batching.\n",
        "\n",
        "- Precompute logits: run the teacher over hf_train_dataset_bertweet and hf_val_dataset_bertweet to get soft targets.\n",
        "\n",
        "- Output: t_train_logits and t_val_logits used later by the KD trainer so the student can learn from the teacher’s soft targets.\n"
      ],
      "metadata": {
        "id": "b9_1E6COqegq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Load teacher (use your device), frozen ----\n",
        "teacher_tokenizer = AutoTokenizer.from_pretrained(TEACHER_PATH, use_fast=True)\n",
        "teacher_model = AutoModelForSequenceClassification.from_pretrained(TEACHER_PATH)\n",
        "teacher_model.eval().to(device)\n",
        "for p in teacher_model.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "# ---- Student tokenizer + model init (unchanged) ----\n",
        "num_labels = teacher_model.config.num_labels\n",
        "id2label   = teacher_model.config.id2label\n",
        "label2id   = teacher_model.config.label2id\n",
        "\n",
        "student_tokenizer = AutoTokenizer.from_pretrained(STUDENT_NAME, use_fast=True)\n",
        "\n",
        "def model_init():\n",
        "    return AutoModelForSequenceClassification.from_pretrained(\n",
        "        STUDENT_NAME, num_labels=num_labels, id2label=id2label, label2id=label2id\n",
        "    )\n",
        "\n",
        "# ---------- Collator to feed the teacher ONLY (pads BERTweet ids/masks) ----------\n",
        "from torch.utils.data import DataLoader\n",
        "class TeacherOnlyCollator:\n",
        "    def __init__(self, tok):\n",
        "        self.tok = tok\n",
        "    def __call__(self, feats):\n",
        "        batch = {\n",
        "            \"input_ids\":      [f[\"input_ids\"]      for f in feats],\n",
        "            \"attention_mask\": [f[\"attention_mask\"] for f in feats],\n",
        "        }\n",
        "        return self.tok.pad(batch, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "# ---------- Precompute teacher logits (GPU if available, AMP on CUDA) ----------\n",
        "@torch.no_grad()\n",
        "def compute_teacher_logits(hf_ds, batch_size=128):\n",
        "    dl = DataLoader(\n",
        "        hf_ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=TeacherOnlyCollator(teacher_tokenizer),\n",
        "        num_workers=2,\n",
        "        pin_memory=(device.type == \"cuda\"),\n",
        "    )\n",
        "    all_logits = []\n",
        "    use_amp = (device.type == \"cuda\")\n",
        "    for b in dl:\n",
        "        b = {k: v.to(device, non_blocking=True) for k, v in b.items()}\n",
        "        if use_amp:\n",
        "            with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "                logits = teacher_model(**b).logits\n",
        "        else:\n",
        "            logits = teacher_model(**b).logits\n",
        "        all_logits.append(logits.float().cpu())\n",
        "    return torch.cat(all_logits, dim=0)\n",
        "\n",
        "print(\"Precomputing teacher logits (fast path)…\")\n",
        "t_train_logits = compute_teacher_logits(hf_train_dataset_bertweet, batch_size=128)\n",
        "t_val_logits   = compute_teacher_logits(hf_val_dataset_bertweet,   batch_size=128)\n",
        "print(f\"Teacher logits: train {tuple(t_train_logits.shape)}, val {tuple(t_val_logits.shape)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxCFcpOHjeKT",
        "outputId": "e3743cf2-e49f-41c2-930b-e22badaa98ef"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precomputing teacher logits (fast path)…\n",
            "Teacher logits: train (32925, 3), val (8232, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _build_kd_student_ds(hf_ds, t_logits_tensor, teacher_tok, student_tok):\n",
        "    # 1) Reconstruct raw texts from the teacher-tokenized dataset\n",
        "    texts = teacher_tok.batch_decode(hf_ds[\"input_ids\"], skip_special_tokens=True)\n",
        "    # 2) Tokenize for the *student*\n",
        "    enc = student_tok(texts, truncation=True, padding=False)\n",
        "    # 3) Labels and teacher logits\n",
        "    labels = hf_ds[\"labels\"]\n",
        "    t_logits = t_logits_tensor.detach().cpu().float().tolist()\n",
        "    # 4) Sanity alignment\n",
        "    n = len(labels)\n",
        "    assert len(enc[\"input_ids\"]) == n and len(t_logits) == n, \\\n",
        "        f\"KD alignment error: student tokens ({len(enc['input_ids'])}) / logits ({len(t_logits)}) / labels ({n})\"\n",
        "    # 5) HF Dataset for Trainer\n",
        "    return Dataset.from_dict({\n",
        "        \"input_ids\": enc[\"input_ids\"],\n",
        "        \"attention_mask\": enc[\"attention_mask\"],\n",
        "        \"labels\": labels,\n",
        "        \"t_logits\": t_logits,\n",
        "    })\n",
        "\n",
        "kd_train_ds = _build_kd_student_ds(hf_train_dataset_bertweet, t_train_logits, teacher_tokenizer, student_tokenizer)\n",
        "kd_val_ds   = _build_kd_student_ds(hf_val_dataset_bertweet,   t_val_logits,   teacher_tokenizer, student_tokenizer)\n",
        "\n",
        "# === Collator that the KD trainer expects (pads student inputs + stacks labels & t_logits) ===\n",
        "class DualCollator:\n",
        "    def __init__(self, s_tok):\n",
        "        self.s_tok = s_tok\n",
        "    def __call__(self, feats):\n",
        "        s_batch = {\n",
        "            \"input_ids\":      [f[\"input_ids\"]      for f in feats],\n",
        "            \"attention_mask\": [f[\"attention_mask\"] for f in feats],\n",
        "        }\n",
        "        s_padded = self.s_tok.pad(s_batch, padding=True, return_tensors=\"pt\")\n",
        "        labels   = torch.tensor([f[\"labels\"]   for f in feats], dtype=torch.long)\n",
        "        t_logits = torch.tensor([f[\"t_logits\"] for f in feats], dtype=torch.float32)\n",
        "        s_padded[\"labels\"]   = labels\n",
        "        s_padded[\"t_logits\"] = t_logits\n",
        "        return s_padded\n",
        "\n",
        "dual_collator = DualCollator(student_tokenizer)\n",
        "\n",
        "print(f\"✓ KD datasets built: train={len(kd_train_ds)}, val={len(kd_val_ds)} with 't_logits'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-OWqZirH_J6",
        "outputId": "f04909fe-9054-4848-853a-2048f4c4123c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ KD datasets built: train=32925, val=8232 with 't_logits'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Losses ----\n",
        "_kl = nn.KLDivLoss(reduction=\"batchmean\")\n",
        "ce_loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def kd_loss_fn(student_logits, teacher_logits, T: float):\n",
        "    log_p_s = nn.functional.log_softmax(student_logits / T, dim=-1)\n",
        "    p_t     = nn.functional.softmax(teacher_logits / T, dim=-1)\n",
        "    return (T * T) * _kl(log_p_s, p_t)\n",
        "\n",
        "# ---- KD Trainer (now consumes precomputed teacher logits) ----\n",
        "class KDTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        t_logits = inputs.pop(\"t_logits\")                    # [B, num_labels], float32\n",
        "        outputs  = model(**inputs)\n",
        "        s_logits = outputs.logits\n",
        "        # move to same device for KD term\n",
        "        t_logits = t_logits.to(s_logits.device)\n",
        "        loss_ce  = ce_loss_fn(s_logits, inputs[\"labels\"])\n",
        "        loss_kd  = kd_loss_fn(s_logits, t_logits, KD_TEMPERATURE)\n",
        "        loss     = ALPHA_CE * loss_ce + ALPHA_KD * loss_kd\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Save under the same hf_best/ folder as the teacher (matches later eval cells)\n",
        "KD_SAVE_DIR = str(Path(TEACHER_PATH).parent / \"bertweet_kd_student\")\n",
        "os.makedirs(KD_SAVE_DIR, exist_ok=True)  # safe if it already exists\n",
        "print(\"KD_SAVE_DIR =\", KD_SAVE_DIR)\n",
        "\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f\"{KD_SAVE_DIR}/runs\",\n",
        "    overwrite_output_dir=True,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=False,   # will set True after strategies below\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    greater_is_better=True,\n",
        "    fp16=False,\n",
        "    report_to=[\"none\"],\n",
        "\n",
        "    # keep extra fields (like 't_logits') for the collator & compute_loss:\n",
        "    remove_unused_columns=False,\n",
        ")\n",
        "# (rest of your code the same…)\n",
        "try:\n",
        "    training_args.evaluation_strategy = IntervalStrategy.EPOCH\n",
        "    training_args.save_strategy       = IntervalStrategy.EPOCH\n",
        "except Exception:\n",
        "    training_args.evaluation_strategy = \"epoch\"\n",
        "    training_args.save_strategy       = \"epoch\"\n",
        "try:\n",
        "    training_args.save_total_limit = 1\n",
        "except Exception:\n",
        "    pass\n",
        "training_args.load_best_model_at_end = True\n",
        "\n",
        "# ---- Trainer (use your existing compute_metrics) ----\n",
        "trainer = KDTrainer(\n",
        "    model_init=model_init,\n",
        "    args=training_args,\n",
        "    train_dataset=kd_train_ds,\n",
        "    eval_dataset=kd_val_ds,\n",
        "    data_collator=dual_collator,\n",
        "    compute_metrics=compute_metrics,  # your multi-metric fn\n",
        ")\n",
        "\n",
        "print(\"Starting KD training (teacher logits precomputed)...\")\n",
        "train_result = trainer.train()\n",
        "trainer.save_model(KD_SAVE_DIR)\n",
        "student_tokenizer.save_pretrained(KD_SAVE_DIR)\n",
        "val_metrics = trainer.evaluate()\n",
        "print(\"KD(BERTweet→DistilRoBERTa) | Val metrics:\", val_metrics)"
      ],
      "metadata": {
        "id": "monkj49jyNX0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "outputId": "d97471b7-de9d-40d7-86e1-0bc8c847a3c8"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KD_SAVE_DIR = /content/drive/MyDrive/ADV_DL/hf_best/bertweet_kd_student\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting KD training (teacher logits precomputed)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3087' max='3087' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3087/3087 13:54, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.408500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.964300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.680000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.596000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.447800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.399500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:20]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KD(BERTweet→DistilRoBERTa) | Val metrics: {'eval_loss': 0.6036226749420166, 'eval_accuracy': 0.908041788143829, 'eval_f1': 0.9075559815034498, 'eval_precision': 0.9084999992474658, 'eval_recall': 0.908041788143829, 'eval_runtime': 21.0988, 'eval_samples_per_second': 390.165, 'eval_steps_per_second': 6.114, 'epoch': 3.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Compatibility aliases for any later cells that expected the old names ---\n",
        "BT_KD_PATH      = KD_SAVE_DIR            # old var -> points to the new saved student\n",
        "bt_student_model = None                  # not needed anymore; prevents accidental re-use\n",
        "bt_student_tokenizer = None              # not needed\n",
        "kd_train_ds_bt  = kd_train_ds            # if later cells reference *_bt datasets\n",
        "kd_val_ds_bt    = kd_val_ds"
      ],
      "metadata": {
        "id": "YFyRLidxOlyf"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate KD student vs. teacher (BERTweet)**\n",
        "\n",
        "This cell compares the distilled DistilRoBERTa student to the BERTweet teacher.\n",
        "\n",
        "helpers handle model file lookup (_model_file), size in MB (_mb), safe column drops (_drop_cols, removes KD-only fields like t_logits), and accuracy pass (_quick_acc with DataCollatorWithPadding and GPU/CPU-aware batch size).\n",
        "\n",
        "The student is loaded from KD_SAVE_DIR and evaluated on kd_val_ds after stripping KD-only columns.\n",
        "\n",
        "The teacher is loaded from TEACHER_PATH and evaluated on the original hf_val_dataset_bertweet if present; otherwise it rebuilds an eval set by decoding the student tokens back to text and re-tokenizing with the teacher tokenizer.\n",
        "\n",
        "Finally, it prints [BERTweet] KD student accuracy = … and [BERTweet] teacher accuracy = …. If you define EVAL_MAX_SAMPLES, the accuracy is computed on a capped subset for speed."
      ],
      "metadata": {
        "id": "iktQ7s1ksSre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- helpers (no dependency on your earlier helpers) ----\n",
        "def _model_file(d):\n",
        "    d = Path(d)\n",
        "    for f in (\"pytorch_model.bin\", \"model.safetensors\"):\n",
        "        p = d / f\n",
        "        if p.exists():\n",
        "            return str(p)\n",
        "    raise FileNotFoundError(f\"No weights found in {d}\")\n",
        "\n",
        "def _mb(p):\n",
        "    return os.path.getsize(p) / (1024 * 1024)\n",
        "\n",
        "def _drop_cols(ds, cols=(\"t_logits\",\"raw_texts\")):\n",
        "    try:\n",
        "        have = getattr(ds, \"column_names\", [])\n",
        "        rm = [c for c in cols if c in have]\n",
        "        return ds.remove_columns(rm) if rm else ds\n",
        "    except Exception:\n",
        "        return ds\n",
        "\n",
        "def _quick_acc(model, tokenizer, dataset, max_samples=None):\n",
        "    ds = dataset\n",
        "    if max_samples and hasattr(ds, \"select\"):\n",
        "        ds = ds.select(range(min(len(ds), max_samples)))\n",
        "    loader = DataLoader(\n",
        "        ds,\n",
        "        batch_size=(64 if model.device.type == \"cuda\" else 128),\n",
        "        shuffle=False,\n",
        "        collate_fn=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "    )\n",
        "    preds, labels = [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            y = batch.pop(\"labels\")\n",
        "            inputs = {k: v.to(model.device) for k, v in batch.items()\n",
        "                      if k in (\"input_ids\",\"attention_mask\",\"token_type_ids\")}\n",
        "            logits = model(**inputs).logits\n",
        "            preds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
        "            labels.extend(y.cpu().tolist() if isinstance(y, torch.Tensor) else y)\n",
        "    return accuracy_score(labels, preds)\n"
      ],
      "metadata": {
        "id": "YGj7P72iUNeg"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTweet (teacher path = TEACHER_PATH, student KD dir = KD_SAVE_DIR)\n",
        "# sanity: saved files exist\n",
        "for req in (\"config.json\",\"tokenizer.json\"):\n",
        "    if not (Path(KD_SAVE_DIR)/req).exists():\n",
        "        print(f\"⚠️ Missing {req} in {KD_SAVE_DIR}\")\n",
        "\n",
        "# sizes\n",
        "bt_teacher_file = _model_file(TEACHER_PATH)\n",
        "bt_student_file = _model_file(KD_SAVE_DIR)\n",
        "print(f\"[BERTweet] teacher size: {_mb(bt_teacher_file):.2f} MB\")\n",
        "print(f\"[BERTweet] KD student size: {_mb(bt_student_file):.2f} MB\")\n",
        "\n",
        "# load student + accuracy (drop KD-only cols)\n",
        "bt_student_tok = AutoTokenizer.from_pretrained(KD_SAVE_DIR)\n",
        "bt_student_mod = AutoModelForSequenceClassification.from_pretrained(KD_SAVE_DIR).to(device).eval()\n",
        "bt_eval_ds     = _drop_cols(kd_val_ds)\n",
        "bt_acc_student = _quick_acc(bt_student_mod, bt_student_tok, bt_eval_ds, max_samples=globals().get(\"EVAL_MAX_SAMPLES\", None))\n",
        "print(f\"[BERTweet] KD student accuracy = {bt_acc_student:.4f}\")\n",
        "\n",
        "# teacher accuracy (prefer original HF val if present)\n",
        "bt_teacher_tok = AutoTokenizer.from_pretrained(TEACHER_PATH, use_fast=True)\n",
        "bt_teacher_mod = AutoModelForSequenceClassification.from_pretrained(TEACHER_PATH).to(device).eval()\n",
        "if 'hf_val_dataset_bertweet' in globals():\n",
        "    bt_teacher_eval = hf_val_dataset_bertweet\n",
        "else:\n",
        "    # rebuild from kd_val_ds: decode student tokens -> text -> re-tokenize with teacher\n",
        "    texts = bt_student_tok.batch_decode(kd_val_ds[\"input_ids\"], skip_special_tokens=True)\n",
        "    enc   = bt_teacher_tok(texts, truncation=True, padding=False)\n",
        "    bt_teacher_eval = Dataset.from_dict({\n",
        "        \"input_ids\": enc[\"input_ids\"],\n",
        "        \"attention_mask\": enc[\"attention_mask\"],\n",
        "        \"labels\": kd_val_ds[\"labels\"],\n",
        "    })\n",
        "bt_teacher_eval = _drop_cols(bt_teacher_eval)\n",
        "bt_acc_teacher  = _quick_acc(bt_teacher_mod, bt_teacher_tok, bt_teacher_eval, max_samples=globals().get(\"EVAL_MAX_SAMPLES\", None))\n",
        "print(f\"[BERTweet] teacher accuracy    = {bt_acc_teacher:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nenyjur3Uchu",
        "outputId": "ee14d3a4-9da4-4f57-a405-0bfe68cbd2ed"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BERTweet] teacher size: 514.63 MB\n",
            "[BERTweet] KD student size: 313.28 MB\n",
            "[BERTweet] KD student accuracy = 0.9080\n",
            "[BERTweet] teacher accuracy    = 0.9164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load from drive the compressed model"
      ],
      "metadata": {
        "id": "_cH1kJ35cvbz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DistilBERT Evaluation and Loading"
      ],
      "metadata": {
        "id": "dy4LtS2Rthuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "HF_BEST = Path(TEACHER_PATH).parent\n",
        "\n",
        "DISTIL_KD_DIR_SRC = Path(\"/content/drive/MyDrive/ADV_DL/kd_student_distilbert\")\n",
        "\n",
        "# Robust check for weights at source\n",
        "if not DISTIL_KD_DIR_SRC.exists() or not any((DISTIL_KD_DIR_SRC / f).exists() for f in (\"pytorch_model.bin\",\"model.safetensors\")):\n",
        "    raise FileNotFoundError(\n",
        "        \"DistilBERT KD student not found at /content/drive/MyDrive/ADV_DL/kd_student_distilbert. \"\n",
        "        \"Make sure the earlier KD save cell finished successfully.\"\n",
        "    )\n",
        "\n",
        "# Destination expected by compression/eval cells (they scan hf_best for *_kd_* dirs)\n",
        "DISTIL_KD_DIR = HF_BEST / \"distilbert_kd_bert_tiny\"\n",
        "DISTIL_KD_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Copy weights/config only if dest is missing them\n",
        "if not any((DISTIL_KD_DIR / f).exists() for f in (\"pytorch_model.bin\",\"model.safetensors\")):\n",
        "    for fname in [\n",
        "        \"config.json\", \"pytorch_model.bin\", \"model.safetensors\",\n",
        "        \"tokenizer.json\", \"tokenizer_config.json\", \"vocab.txt\",\n",
        "        \"merges.txt\", \"special_tokens_map.json\"\n",
        "    ]:\n",
        "        src = DISTIL_KD_DIR_SRC / fname\n",
        "        if src.exists():\n",
        "            shutil.copy2(src, DISTIL_KD_DIR / fname)\n",
        "\n",
        "print(\"DistilBERT KD dir set to:\", DISTIL_KD_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjkLND5jUhA4",
        "outputId": "8284c9f6-0be6-41dd-b1dd-f3d388cf8de2"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ DistilBERT KD dir set to: /content/drive/MyDrive/ADV_DL/hf_best/distilbert_kd_bert_tiny\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _resolve_distil_eval_split(teacher_tok):\n",
        "    # 1) Preferred: HF splits for DistilBERT\n",
        "    if 'hf_val_dataset_distilbert' in globals():\n",
        "        return _drop_cols(hf_val_dataset_distilbert)\n",
        "    if 'hf_test_dataset_distilbert' in globals():\n",
        "        return _drop_cols(hf_test_dataset_distilbert)\n",
        "\n",
        "    # 2) Last resort: build from kd_val_ds by decoding its tokens -> raw text -> re-tokenize for DistilBERT\n",
        "    if 'kd_val_ds' in globals():\n",
        "        try:\n",
        "            dec_tok = globals().get('student_tok', None)\n",
        "            if dec_tok is None:\n",
        "                from transformers import AutoTokenizer as _AT\n",
        "                dec_tok = _AT.from_pretrained(KD_SAVE_DIR)   # BERTweet KD student tokenizer\n",
        "            if hasattr(kd_val_ds, \"column_names\") and (\"input_ids\" in kd_val_ds.column_names):\n",
        "                texts = dec_tok.batch_decode(kd_val_ds[\"input_ids\"], skip_special_tokens=True)\n",
        "                enc   = teacher_tok(texts, truncation=True, padding=False)\n",
        "                return Dataset.from_dict({\n",
        "                    \"input_ids\": enc[\"input_ids\"],\n",
        "                    \"attention_mask\": enc[\"attention_mask\"],\n",
        "                    \"labels\": kd_val_ds[\"labels\"],\n",
        "                })\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Nothing available\n",
        "    return None\n",
        "\n",
        "# define teacher tokenizer BEFORE calling resolver\n",
        "db_teacher_tok = AutoTokenizer.from_pretrained(str(DISTIL_TEACHER_DIR), use_fast=True)\n",
        "db_eval_ds = _resolve_distil_eval_split(db_teacher_tok)\n",
        "\n",
        "if db_eval_ds is None:\n",
        "    print(\"DistilBERT eval dataset not found; skipping accuracy computation for DistilBERT.\")\n",
        "else:\n",
        "    # Student accuracy\n",
        "    db_student_tok = AutoTokenizer.from_pretrained(str(DISTIL_KD_DIR))\n",
        "    db_student_mod = AutoModelForSequenceClassification.from_pretrained(str(DISTIL_KD_DIR)).to(device).eval()\n",
        "    db_acc_student = _quick_acc(\n",
        "        db_student_mod, db_student_tok, db_eval_ds,\n",
        "        max_samples=globals().get(\"EVAL_MAX_SAMPLES\", None)\n",
        "    )\n",
        "    print(f\"[DistilBERT] KD student accuracy = {db_acc_student:.4f}\")\n",
        "\n",
        "    # Teacher accuracy (same split)\n",
        "    db_teacher_mod = AutoModelForSequenceClassification.from_pretrained(str(DISTIL_TEACHER_DIR)).to(device).eval()\n",
        "    db_acc_teacher = _quick_acc(\n",
        "        db_teacher_mod, db_teacher_tok, db_eval_ds,\n",
        "        max_samples=globals().get(\"EVAL_MAX_SAMPLES\", None)\n",
        "    )\n",
        "    print(f\"[DistilBERT] teacher accuracy    = {db_acc_teacher:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0n5h8JaZjqT",
        "outputId": "27cddb5e-56b9-44de-ff26-76a30d7c54e8"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DistilBERT] KD student accuracy = 0.8507\n",
            "[DistilBERT] teacher accuracy    = 0.8946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8KY68WR0b_U"
      },
      "source": [
        "# Final Compression Results & Comparison\n",
        "\n",
        "Below we compare **DistilBERT** and **BERTweet** before and after three compression methods:\n",
        "- **Quantization** (dynamic, Linear-only, PyTorch CPU)\n",
        "- **Pruning** (global unstructured L1, 30%)\n",
        "- **Knowledge Distillation (KD)** (teacher → small student)\n",
        "\n",
        "note: dynamic quantization is CPU-only.\n",
        "\n",
        "---\n",
        "\n",
        "## DistilBERT\n",
        "\n",
        "| Method               | Size (MB) | Val Acc | Sec/Batch |\n",
        "|----------------------|----------:|--------:|----------:|\n",
        "| Baseline (teacher)   | **255.43** | **0.8980** | **0.0813** |\n",
        "| Quantized (dynamic)  | 132.29 | 0.8700 | 2.5604 |\n",
        "| Pruned (30%)         | 255.43 | 0.8980 | 2.9027 |\n",
        "| KD (bert-tiny)       | —      | 0.8526 | 0.0615 |\n",
        "\n",
        "**Observations (DistilBERT):**\n",
        "- **KD** gives the fastest inference with a modest accuracy drop (0.853 vs 0.898).\n",
        "- **Pruning (30%)** kept accuracy essentially unchanged but didn’t speed up.\n",
        "- **Quantization** reduced size by ~48% but ran slower here because it’s CPU only.\n",
        "\n",
        "---\n",
        "\n",
        "## BERTweet\n",
        "\n",
        "| Method                      | Size (MB) | Val Acc | Sec/Batch |\n",
        "|----------------------------|----------:|--------:|----------:|\n",
        "| Baseline (teacher)         | **514.63** | **0.9080** | **0.1592** |\n",
        "| Quantized (dynamic)        | 270.05 | 0.2080 | 5.0174 |\n",
        "| Pruned (30%)               | **514.63** | **0.9080** | **5.5222** |\n",
        "| KD (distilroberta student) | 313.28 | 0.6430 | 0.0615 |\n",
        "\n",
        "**Observations (BERTweet):**\n",
        "- **KD student** is much faster with an accuracy drop (0.643 vs 0.908).\n",
        "- **Quantization** accuracy collapsed (0.208), we are not sure why. We actually expected this to be the highest as it only makes the weights digits a bit shorter.\n",
        "- **Pruning** preserved accuracy but didn’t speed up.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CySXj6E56VB8"
      },
      "source": [
        "# **TEST RUN** - Compressed Models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section evaluates **all compressed models** (Quantized, Pruned, KD students) **from Drive** and produces a summary CSV for the paper.\n",
        "\n",
        "Evaluates compressed models saved in `hf_best`:\n",
        "- Quantized: `distilbert_quantized.pt`, `bertweet_quantized.pt`\n",
        "- Pruned:    `distilbert_pruned_*`, `bertweet_pruned_*`\n",
        "- KD:        `distilbert_kd_*`, `bertweet_kd_*`\n"
      ],
      "metadata": {
        "id": "PPJbyTnHpFFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = \"/content/drive/MyDrive/ADV_DL\""
      ],
      "metadata": {
        "id": "j8my0DWL9l_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQgj3X7Eqs1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0f6afae-8e92-466b-9fb5-fbd948f35fa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BASE_DIR   : /content/drive/MyDrive/ADV_DL\n",
            "HF_BEST_DIR: /content/drive/MyDrive/ADV_DL/hf_best\n",
            "device     : cuda\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "# Expect these to exist already in the notebook:\n",
        "assert 'BASE_DIR' in globals(), \"BASE_DIR is not defined.\"\n",
        "assert 'HF_BEST_DIR' in globals(), \"HF_BEST_DIR is not defined.\"\n",
        "assert 'device' in globals(), \"device is not defined (torch device).\"\n",
        "\n",
        "BASE_DIR = Path(BASE_DIR)\n",
        "HF_BEST_DIR = Path(HF_BEST_DIR)\n",
        "\n",
        "print(\"BASE_DIR   :\", BASE_DIR)\n",
        "print(\"HF_BEST_DIR:\", HF_BEST_DIR)\n",
        "print(\"device     :\", device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizers (load from Drive)\n"
      ],
      "metadata": {
        "id": "mahjPF3-ucPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "if 'distilbert_tokenizer' not in globals():\n",
        "    distilbert_tokenizer = AutoTokenizer.from_pretrained(HF_BEST_DIR / \"distilbert\")\n",
        "if 'bertweet_tokenizer' not in globals():\n",
        "    bertweet_tokenizer   = AutoTokenizer.from_pretrained(HF_BEST_DIR / \"bertweet\")\n",
        "\n",
        "print(\"✓ Tokenizers ready (DistilBERT & BERTweet).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMdqh828o2ff",
        "outputId": "c3c8d692-0a92-458c-e3de-9fc0825cce6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Tokenizers ready (DistilBERT & BERTweet).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation datasets (reuse val/test; one per family)"
      ],
      "metadata": {
        "id": "Z4jdNwHYukXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expect either val or test per family to be loaded earlier in the notebook\n",
        "assert ('hf_val_dataset_distilbert' in globals()) or ('hf_test_dataset_distilbert' in globals()), \\\n",
        "       \"Missing DistilBERT eval dataset (val or test).\"\n",
        "assert ('hf_val_dataset_bertweet' in globals()) or ('hf_test_dataset_bertweet' in globals()), \\\n",
        "       \"Missing BERTweet eval dataset (val or test).\"\n",
        "\n",
        "ds_distil = globals().get('hf_val_dataset_distilbert') or globals().get('hf_test_dataset_distilbert')\n",
        "ds_bertw  = globals().get('hf_val_dataset_bertweet')   or globals().get('hf_test_dataset_bertweet')\n",
        "\n",
        "print(\"Datasets ready (DistilBERT & BERTweet).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPH0H9qGuiNz",
        "outputId": "f1c930d8-b1d1-43ff-f913-69833368f158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets ready (DistilBERT & BERTweet).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weights & Biases\n",
        "Log accuracy and sec/batch per artifact.\n"
      ],
      "metadata": {
        "id": "74hMi81cupGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_wandb = 'wandb' in globals()\n",
        "if use_wandb:\n",
        "    run = wandb.init(\n",
        "        project = globals().get('WANDB_PROJECT', 'adv-dl-sentiment'),\n",
        "        job_type= \"compression-test\",\n",
        "        group   = \"compression-eval\",\n",
        "        reinit  = True\n",
        "    )\n",
        "    print(\"✓ W&B logging enabled.\")\n",
        "else:\n",
        "    print(\"W&B not active — skipping logging.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "cEDcxXO6unP3",
        "outputId": "5b1b0621-1fce-449a-c5bf-650e6e314dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to True."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bertweet/kd/accuracy</td><td>▁</td></tr><tr><td>bertweet/pruned/accuracy</td><td>▁</td></tr><tr><td>bertweet/quantized/accuracy</td><td>▁</td></tr><tr><td>distilbert/pruned/accuracy</td><td>▁</td></tr><tr><td>distilbert/quantized/accuracy</td><td>▁█</td></tr><tr><td>distilbert/quantized/sec_per_batch</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bertweet/kd/accuracy</td><td>0.646</td></tr><tr><td>bertweet/pruned/accuracy</td><td>0.91333</td></tr><tr><td>bertweet/quantized/accuracy</td><td>0.216</td></tr><tr><td>distilbert/pruned/accuracy</td><td>0.89867</td></tr><tr><td>distilbert/quantized/accuracy</td><td>0.894</td></tr><tr><td>distilbert/quantized/sec_per_batch</td><td>2.40332</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">splendid-sun-6</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/35fx0h1m' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/35fx0h1m</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250821_174439-35fx0h1m/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250821_193648-23nhak0v</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/23nhak0v' target=\"_blank\">misunderstood-surf-7</a></strong> to <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/23nhak0v' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/23nhak0v</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ W&B logging enabled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helpers (reuse `evaluate_model` / `measure_inference_time`)"
      ],
      "metadata": {
        "id": "pBfuLhqCu9h6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def _model_device(model):\n",
        "    try:\n",
        "        return next(model.parameters()).device\n",
        "    except StopIteration:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "def _subset_dataset(ds, max_samples):\n",
        "    if max_samples is None:\n",
        "        return ds\n",
        "    try:\n",
        "        n = len(ds)\n",
        "        if n > max_samples:\n",
        "            # HuggingFace Dataset supports .select\n",
        "            return ds.select(range(max_samples))\n",
        "    except Exception:\n",
        "        pass\n",
        "    return ds\n",
        "\n",
        "def _acc(model, tokenizer, dataset):\n",
        "    # cap evaluation size to speed up\n",
        "    MAX_SAMPLES = globals().get('EVAL_MAX_SAMPLES', 1500)  # adjust if you like\n",
        "    ds = _subset_dataset(dataset, MAX_SAMPLES)\n",
        "\n",
        "    # Prefer your notebook's evaluate_model; fall back if that one doesn't support subsets\n",
        "    if 'evaluate_model' in globals():\n",
        "        try:\n",
        "            # if your evaluate_model can take n_samples, use it\n",
        "            return evaluate_model(model, tokenizer, ds, n_samples=len(ds))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Minimal fallback (no latency measurement)\n",
        "    import numpy as np\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    dev = _model_device(model)\n",
        "    # higher batch for CPU to speed dynamic quant; moderate for GPU\n",
        "    bs = 128 if dev.type == 'cpu' else 64\n",
        "    model.eval()\n",
        "    loader = DataLoader(ds, batch_size=bs, collate_fn=DataCollatorWithPadding(tokenizer=tokenizer))\n",
        "    preds, labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            y = batch.pop(\"labels\").numpy()\n",
        "            batch = {k: v.to(dev) for k, v in batch.items()}\n",
        "            logits = model(**batch).logits\n",
        "            preds.extend(torch.argmax(logits, dim=-1).cpu().numpy())\n",
        "            labels.extend(y)\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    return accuracy_score(labels, preds)\n",
        "\n",
        "# Quantized loader: keep on CPU; deprecation warning is fine for this run\n",
        "def _load_quantized_teacher(teacher_dir, state_file):\n",
        "    base = AutoModelForSequenceClassification.from_pretrained(teacher_dir)  # CPU\n",
        "    qmod = torch.quantization.quantize_dynamic(base, {torch.nn.Linear}, dtype=torch.qint8)\n",
        "    state = torch.load(state_file, map_location='cpu')\n",
        "    qmod.load_state_dict(state)\n",
        "    qmod.eval()\n",
        "    return qmod\n"
      ],
      "metadata": {
        "id": "oP7n0o5pu0y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate: Quantized models\n"
      ],
      "metadata": {
        "id": "C9W1d6TAvIV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []  # collected across all methods\n",
        "\n",
        "distil_q_file = HF_BEST_DIR / \"distilbert_quantized.pt\"\n",
        "bertw_q_file  = HF_BEST_DIR / \"bertweet_quantized.pt\"\n",
        "\n",
        "if distil_q_file.exists():\n",
        "    model = _load_quantized_teacher(HF_BEST_DIR / \"distilbert\", distil_q_file)\n",
        "    acc = _acc(model, distilbert_tokenizer, ds_distil)\n",
        "    results.append({\"family\": \"distilbert\", \"method\": \"quantized\", \"artifact\": str(distil_q_file), \"accuracy\": acc})\n",
        "    if 'wandb' in globals(): wandb.log({\"distilbert/quantized/accuracy\": acc})\n",
        "else:\n",
        "    print(\"DistilBERT quantized file not found in hf_best.\")\n",
        "\n",
        "if bertw_q_file.exists():\n",
        "    model = _load_quantized_teacher(HF_BEST_DIR / \"bertweet\", bertw_q_file)\n",
        "    acc = _acc(model, bertweet_tokenizer, ds_bertw)\n",
        "    results.append({\"family\": \"bertweet\", \"method\": \"quantized\", \"artifact\": str(bertw_q_file), \"accuracy\": acc})\n",
        "    if 'wandb' in globals(): wandb.log({\"bertweet/quantized/accuracy\": acc})\n",
        "else:\n",
        "    print(\"BERTweet quantized file not found in hf_best.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBtCS_MrvGXj",
        "outputId": "4fedadb5-297b-4018-ec2e-f61995a43896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1093819620.py:60: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  qmod = torch.quantization.quantize_dynamic(base, {torch.nn.Linear}, dtype=torch.qint8)\n",
            "/tmp/ipython-input-1093819620.py:60: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  qmod = torch.quantization.quantize_dynamic(base, {torch.nn.Linear}, dtype=torch.qint8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate — Pruned"
      ],
      "metadata": {
        "id": "5Fxwt6lXyv0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_dirs = [p for p in HF_BEST_DIR.iterdir() if p.is_dir() and \"_pruned_\" in p.name.lower()]\n",
        "print(f\"Found {len(pruned_dirs)} pruned dirs:\", [p.name for p in pruned_dirs])\n",
        "\n",
        "for d in sorted(pruned_dirs):\n",
        "    name = d.name.lower()\n",
        "    fam  = \"distilbert\" if \"distil\" in name else \"bertweet\"\n",
        "    tok  = distilbert_tokenizer if fam == \"distilbert\" else bertweet_tokenizer\n",
        "    ds   = ds_distil if fam == \"distilbert\" else ds_bertw\n",
        "\n",
        "    # Try GPU first; if it throws (device-side assert), fall back to CPU\n",
        "    try:\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(d).to(device).eval()\n",
        "    except Exception as e:\n",
        "        print(f\"GPU load failed for {d.name} ({type(e).__name__}). Falling back to CPU.\")\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(d).to(\"cpu\").eval()\n",
        "\n",
        "    acc = _acc(model, tok, ds)\n",
        "    print(f\"[{fam}][{name}] accuracy={acc:.4f}\")\n",
        "    results.append({\"family\": fam, \"method\": f\"pruned:{name}\", \"artifact\": str(d), \"accuracy\": acc})\n",
        "    if 'wandb' in globals(): wandb.log({f\"{fam}/pruned/accuracy\": acc})\n"
      ],
      "metadata": {
        "id": "GvBqK-gkvNoP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b14a55-ba81-427a-b4c9-6c6bd086eee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2 pruned dirs: ['distilbert_pruned_30', 'bertweet_pruned_30']\n",
            "⚠️ GPU load failed for bertweet_pruned_30 (AcceleratorError). Falling back to CPU.\n",
            "[bertweet][bertweet_pruned_30] accuracy=0.9133\n",
            "⚠️ GPU load failed for distilbert_pruned_30 (AcceleratorError). Falling back to CPU.\n",
            "[distilbert][distilbert_pruned_30] accuracy=0.8987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate — KD students"
      ],
      "metadata": {
        "id": "Q_s3AXd6z73X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "kd_dirs = [p for p in HF_BEST_DIR.iterdir() if p.is_dir() and \"_kd_\" in p.name.lower()]\n",
        "print(f\"Found {len(kd_dirs)} KD dirs:\", [p.name for p in kd_dirs])\n",
        "\n",
        "def _pick_texts_and_labels(ds_src, max_n):\n",
        "    # subset for speed\n",
        "    ds_small = ds_src.select(range(min(len(ds_src), max_n))) if hasattr(ds_src, \"select\") else ds_src[:max_n]\n",
        "    # prefer an existing raw text column\n",
        "    text_key = None\n",
        "    if hasattr(ds_small, \"column_names\"):\n",
        "        for cand in (\"text\",\"Tweet\",\"tweet\",\"content\",\"raw_text\",\"orig_text\"):\n",
        "            if cand in ds_small.column_names:\n",
        "                text_key = cand\n",
        "                break\n",
        "    if text_key is not None:\n",
        "        texts  = ds_small[text_key]\n",
        "        labels = ds_small[\"labels\"]\n",
        "    else:\n",
        "        # decode from teacher tokens if no raw text present\n",
        "        # (teacher tokenizer chosen by family outside)\n",
        "        texts, labels = None, ds_small[\"labels\"]\n",
        "    return ds_small, texts, labels\n",
        "\n",
        "def _find_weight_file(search_dirs):\n",
        "    patterns = [\"pytorch_model.bin\", \"model.safetensors\", \"*.bin\", \"*.pt\", \"*.pth\"]\n",
        "    for sd in search_dirs:\n",
        "        sd = Path(sd)\n",
        "        for pat in patterns:\n",
        "            for fp in sd.glob(pat):\n",
        "                return fp\n",
        "    return None\n",
        "\n",
        "for d in sorted(kd_dirs):\n",
        "    name = d.name.lower()\n",
        "    fam  = \"distilbert\" if \"distil\" in name else \"bertweet\"\n",
        "    ds_teacher = ds_distil if fam == \"distilbert\" else ds_bertw\n",
        "    max_n = globals().get('EVAL_MAX_SAMPLES', 1500)\n",
        "\n",
        "    # 1) texts/labels\n",
        "    ds_small, texts, labels = _pick_texts_and_labels(ds_teacher, max_n)\n",
        "\n",
        "    # 2) student tokenizer (prefer folder; fallback by family/name)\n",
        "    try:\n",
        "        student_tok = AutoTokenizer.from_pretrained(str(d))\n",
        "    except Exception:\n",
        "        if \"tiny\" in name or fam == \"distilbert\":\n",
        "            # TinyBERT-style student\n",
        "            try:\n",
        "                student_tok = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\")\n",
        "            except Exception:\n",
        "                student_tok = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "        else:\n",
        "            # BERTweet-style student\n",
        "            student_tok = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")\n",
        "\n",
        "    # If we didn't have raw texts, decode from TEACHER tokenizer\n",
        "    if texts is None:\n",
        "        teacher_tok = distilbert_tokenizer if fam == \"distilbert\" else bertweet_tokenizer\n",
        "        ids_list = ds_small[\"input_ids\"]\n",
        "        texts = teacher_tok.batch_decode(ids_list, skip_special_tokens=True)\n",
        "\n",
        "    # 3) student model\n",
        "    student = None\n",
        "    try:\n",
        "        # normal case: weights exist in the KD dir\n",
        "        student = AutoModelForSequenceClassification.from_pretrained(str(d))\n",
        "    except OSError:\n",
        "        # try to find weights nearby (inside dir or hf_best root)\n",
        "        maybe_w = _find_weight_file([d, HF_BEST_DIR])\n",
        "        if maybe_w is not None:\n",
        "            # build the architecture from config in folder, else sensible base\n",
        "            try:\n",
        "                cfg = AutoConfig.from_pretrained(str(d))\n",
        "            except Exception:\n",
        "                base_ckpt = \"prajjwal1/bert-tiny\" if (\"tiny\" in name or fam == \"distilbert\") else \"vinai/bertweet-base\"\n",
        "                cfg = AutoConfig.from_pretrained(base_ckpt, num_labels=3)\n",
        "            student = AutoModelForSequenceClassification.from_config(cfg)\n",
        "            state = torch.load(maybe_w, map_location=\"cpu\")\n",
        "            # state could be either a plain state_dict or under \"state_dict\"\n",
        "            try:\n",
        "                student.load_state_dict(state, strict=False)\n",
        "            except Exception:\n",
        "                if isinstance(state, dict) and \"state_dict\" in state:\n",
        "                    student.load_state_dict(state[\"state_dict\"], strict=False)\n",
        "        else:\n",
        "            print(f\"⚠️ Skipping {d.name}: no model weights found in {d} or {HF_BEST_DIR}.\")\n",
        "            continue\n",
        "\n",
        "    # keep KD students on CPU to avoid CUDA asserts\n",
        "    student = student.to(\"cpu\").eval()\n",
        "\n",
        "    # 4) retokenize with the student tokenizer and evaluate (accuracy only)\n",
        "    enc = student_tok(texts, truncation=True, padding=False)\n",
        "    student_eval_ds = [{\"input_ids\": enc[\"input_ids\"][i],\n",
        "                        \"attention_mask\": enc[\"attention_mask\"][i],\n",
        "                        \"labels\": labels[i]} for i in range(len(labels))]\n",
        "\n",
        "    acc = _acc(student, student_tok, student_eval_ds)\n",
        "    print(f\"[{fam}][{name}] accuracy={acc:.4f}\")\n",
        "    results.append({\"family\": fam, \"method\": f\"kd:{name}\", \"artifact\": str(d), \"accuracy\": acc})\n",
        "    if 'wandb' in globals(): wandb.log({f\"{fam}/kd/accuracy\": acc})\n"
      ],
      "metadata": {
        "id": "ofwbFCdKz7Ns",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7587ddfe-fc97-45a3-ccd7-217656d50d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2 KD dirs: ['distilbert_kd_bert_tiny', 'bertweet_kd_student']\n",
            "[bertweet][bertweet_kd_student] accuracy=0.6460\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[distilbert][distilbert_kd_bert_tiny] accuracy=0.1953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save summary to Drive\n"
      ],
      "metadata": {
        "id": "lxF1L55Y0G2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "METRICS_DIR = BASE_DIR / \"metrics\"\n",
        "METRICS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "if not df.empty:\n",
        "    df = df.sort_values([\"family\", \"method\"]).reset_index(drop=True)\n",
        "    display(df)\n",
        "    out_path = METRICS_DIR / \"compression_test_summary.csv\"\n",
        "    df.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
        "    print(f\"✅ Saved summary: {out_path}\")\n",
        "    if 'wandb' in globals():\n",
        "        wandb.log({\"compression_test_summary\": wandb.Table(dataframe=df)})\n",
        "        run.finish()\n",
        "else:\n",
        "    print(\"No compressed artifacts were evaluated; summary not created.\")\n"
      ],
      "metadata": {
        "id": "gMUgzkNQ0ETG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 858
        },
        "outputId": "747a494f-e213-4868-f073-980ca477ed66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       family                       method  \\\n",
              "0    bertweet       kd:bertweet_kd_student   \n",
              "1    bertweet       kd:bertweet_kd_student   \n",
              "2    bertweet       kd:bertweet_kd_student   \n",
              "3    bertweet       kd:bertweet_kd_student   \n",
              "4    bertweet    pruned:bertweet_pruned_30   \n",
              "5    bertweet                    quantized   \n",
              "6  distilbert   kd:distilbert_kd_bert_tiny   \n",
              "7  distilbert  pruned:distilbert_pruned_30   \n",
              "8  distilbert                    quantized   \n",
              "\n",
              "                                            artifact  accuracy  \n",
              "0  /content/drive/MyDrive/ADV_DL/hf_best/bertweet...  0.646000  \n",
              "1  /content/drive/MyDrive/ADV_DL/hf_best/bertweet...  0.646000  \n",
              "2  /content/drive/MyDrive/ADV_DL/hf_best/bertweet...  0.646000  \n",
              "3  /content/drive/MyDrive/ADV_DL/hf_best/bertweet...  0.646000  \n",
              "4  /content/drive/MyDrive/ADV_DL/hf_best/bertweet...  0.913333  \n",
              "5  /content/drive/MyDrive/ADV_DL/hf_best/bertweet...  0.216000  \n",
              "6  /content/drive/MyDrive/ADV_DL/hf_best/distilbe...  0.195333  \n",
              "7  /content/drive/MyDrive/ADV_DL/hf_best/distilbe...  0.898667  \n",
              "8  /content/drive/MyDrive/ADV_DL/hf_best/distilbe...  0.894000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab3c637e-a0ff-45de-a233-527d8e160db1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>family</th>\n",
              "      <th>method</th>\n",
              "      <th>artifact</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bertweet</td>\n",
              "      <td>kd:bertweet_kd_student</td>\n",
              "      <td>/content/drive/MyDrive/ADV_DL/hf_best/bertweet...</td>\n",
              "      <td>0.646000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bertweet</td>\n",
              "      <td>kd:bertweet_kd_student</td>\n",
              "      <td>/content/drive/MyDrive/ADV_DL/hf_best/bertweet...</td>\n",
              "      <td>0.646000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bertweet</td>\n",
              "      <td>kd:bertweet_kd_student</td>\n",
              "      <td>/content/drive/MyDrive/ADV_DL/hf_best/bertweet...</td>\n",
              "      <td>0.646000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bertweet</td>\n",
              "      <td>kd:bertweet_kd_student</td>\n",
              "      <td>/content/drive/MyDrive/ADV_DL/hf_best/bertweet...</td>\n",
              "      <td>0.646000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bertweet</td>\n",
              "      <td>pruned:bertweet_pruned_30</td>\n",
              "      <td>/content/drive/MyDrive/ADV_DL/hf_best/bertweet...</td>\n",
              "      <td>0.913333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>bertweet</td>\n",
              "      <td>quantized</td>\n",
              "      <td>/content/drive/MyDrive/ADV_DL/hf_best/bertweet...</td>\n",
              "      <td>0.216000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>distilbert</td>\n",
              "      <td>kd:distilbert_kd_bert_tiny</td>\n",
              "      <td>/content/drive/MyDrive/ADV_DL/hf_best/distilbe...</td>\n",
              "      <td>0.195333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>distilbert</td>\n",
              "      <td>pruned:distilbert_pruned_30</td>\n",
              "      <td>/content/drive/MyDrive/ADV_DL/hf_best/distilbe...</td>\n",
              "      <td>0.898667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>distilbert</td>\n",
              "      <td>quantized</td>\n",
              "      <td>/content/drive/MyDrive/ADV_DL/hf_best/distilbe...</td>\n",
              "      <td>0.894000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab3c637e-a0ff-45de-a233-527d8e160db1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ab3c637e-a0ff-45de-a233-527d8e160db1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ab3c637e-a0ff-45de-a233-527d8e160db1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-78fe93c1-73a5-4cfd-bd78-95457a452cd4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-78fe93c1-73a5-4cfd-bd78-95457a452cd4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-78fe93c1-73a5-4cfd-bd78-95457a452cd4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_d298604c-1f1b-4cdb-93ce-7576a6fd3eaf\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d298604c-1f1b-4cdb-93ce-7576a6fd3eaf button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"family\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"distilbert\",\n          \"bertweet\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"method\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"pruned:bertweet_pruned_30\",\n          \"pruned:distilbert_pruned_30\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"artifact\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"/content/drive/MyDrive/ADV_DL/hf_best/bertweet_kd_student\",\n          \"/content/drive/MyDrive/ADV_DL/hf_best/bertweet_pruned_30\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27004665806275807,\n        \"min\": 0.19533333333333333,\n        \"max\": 0.9133333333333333,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.646,\n          0.9133333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved summary: /content/drive/MyDrive/ADV_DL/metrics/compression_test_summary.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bertweet/kd/accuracy</td><td>▁▁▁▁</td></tr><tr><td>bertweet/pruned/accuracy</td><td>▁</td></tr><tr><td>bertweet/quantized/accuracy</td><td>▁</td></tr><tr><td>distilbert/kd/accuracy</td><td>▁</td></tr><tr><td>distilbert/pruned/accuracy</td><td>▁</td></tr><tr><td>distilbert/quantized/accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bertweet/kd/accuracy</td><td>0.646</td></tr><tr><td>bertweet/pruned/accuracy</td><td>0.91333</td></tr><tr><td>bertweet/quantized/accuracy</td><td>0.216</td></tr><tr><td>distilbert/kd/accuracy</td><td>0.19533</td></tr><tr><td>distilbert/pruned/accuracy</td><td>0.89867</td></tr><tr><td>distilbert/quantized/accuracy</td><td>0.894</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">misunderstood-surf-7</strong> at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/23nhak0v' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment/runs/23nhak0v</a><br> View project at: <a href='https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment' target=\"_blank\">https://wandb.ai/nogapaz98-tel-aviv-university/adv-dl-sentiment</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250821_193648-23nhak0v/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results Analysis\n",
        "- **Pruning (30%)** — Best overall:\n",
        "  - **BERTweet:** **0.9133** (≈ teacher, even slightly higher → regularization effect).\n",
        "  - **DistilBERT:** **0.8987** (≈ teacher, no meaningful drop).\n",
        "- **Quantization (INT8, dynamic)**:\n",
        "  - **DistilBERT:** **0.8940** (≈ teacher) when evaluated on **CPU** → good.\n",
        "  - **BERTweet:** **0.2160** → likely a **bad artifact** (mismatch between saved quantized state and the fine-tuned checkpoint). Pruning working well on the same model rules out data/labels.\n",
        "- **Knowledge Distillation (KD)**:\n",
        "  - **BERTweet → student:** **0.6460** (large drop vs. teacher).\n",
        "  - **DistilBERT → TinyBERT:** **0.1953** (very low) and earlier evidence of **missing/unsaved student weights** in the KD folder.\n",
        "\n",
        "## What could we do to improve\n",
        "1. **BERTweet Quantization Fix**\n",
        "   - Re-export from the **fine-tuned `hf_best/bertweet/`** checkpoint; evaluate **on CPU** immediately; then save that exact INT8 artifact. Re-run the test cell (should be ≈ teacher like DistilBERT).\n",
        "\n",
        "2. **KD Pipeline Hardening**\n",
        "   - Ensure **student weights are saved** (`save_pretrained` or `trainer.save_model`) to the KD dir you evaluate.\n",
        "   - **Evaluate with the student tokenizer** (already implemented in your eval cell).\n",
        "   - Use a **stronger student**:\n",
        "     - For **BERTweet (RoBERTa-style)**: try `distilroberta-base`.\n",
        "     - For **DistilBERT (BERT-family)**: prefer `prajjwal1/bert-mini` over `bert-tiny`.\n",
        "   - KD hyperparams to try: **T=3–4**, **α (teacher loss)=0.7–0.9**, smaller **LR (1e-5–3e-5)**, **more epochs** (2–3× teacher).\n",
        "\n",
        "3. **Pruning Enhancement (optional)**\n",
        "   - Try **40–50%** sparsity with a **1–2 epoch post-prune finetune** (low LR) for larger size gains while keeping accuracy.\n",
        "\n",
        "4. **Hygiene (submission clarity)**\n",
        "   - Deduplicate CSV rows before saving.  \n",
        "   - Keep INT8 eval **CPU-only** and document `EVAL_MAX_SAMPLES` cap used for speed.\n"
      ],
      "metadata": {
        "id": "Mwgdx9XQZJrN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2u-n-Gprhg14"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00e37e0f93754189828201a2d8b41851": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "031142b2e3ac482094d50bb23b4a7002": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b574a0bad93548d7b674966cda3cd628",
            "placeholder": "​",
            "style": "IPY_MODEL_00e37e0f93754189828201a2d8b41851",
            "value": "config.json: 100%"
          }
        },
        "041edde5a8bd4b569993f53d3cf26fdd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08b9d4279323448d9e08a9d2c6fdd657": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09559db97be845618bf6ee17a03fcc06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0956bce2899a4ebabc94385057f7df46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ed6ab84876949b3ba6c42dae4da0af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f80026ec6c748cbbcfac2fdce479fab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33c0114e93eb403aa62960f1c1afeaed",
              "IPY_MODEL_c05ae15a3d3249da845a07b90214a039",
              "IPY_MODEL_5d197134c6d44f9cae581d9f86b6e49d"
            ],
            "layout": "IPY_MODEL_2e4fa6c2c36846e095b80b7c5af2698e"
          }
        },
        "10590409029146caa83437d477e78e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3444008a5fae481eae6115d1e641def7",
            "placeholder": "​",
            "style": "IPY_MODEL_162e14b7200e48dba8825aaeebc7a36d",
            "value": " 232k/232k [00:00&lt;00:00, 1.69MB/s]"
          }
        },
        "162e14b7200e48dba8825aaeebc7a36d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17aa28ae0025453d91d3a55a6874e25e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b72cbddf36148198432bdd3c0c189be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f344c3a023842738909224226992cae",
              "IPY_MODEL_77d7ebc6ae8542399c0be50ca9d9467f",
              "IPY_MODEL_282373747e57472687a6b935bacdd2db"
            ],
            "layout": "IPY_MODEL_5961190ae3b74ce484bd9a3bcc7a1143"
          }
        },
        "2354cf539d8e442ab6cd96da6bf250df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24faffb0f2cc493b81be853e98d15c32": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27c9fd3f410a4f499214833a91490f5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "282373747e57472687a6b935bacdd2db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29e88278615d4f4bbd62ff69da848e73",
            "placeholder": "​",
            "style": "IPY_MODEL_3298f42445a84befb7be6a74bdc6994d",
            "value": " 17.8M/17.8M [00:00&lt;00:00, 40.9MB/s]"
          }
        },
        "28eeb00e66254e219cb07c5e6de951bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29e88278615d4f4bbd62ff69da848e73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ba82261caac44268478b80a419c533e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e4fa6c2c36846e095b80b7c5af2698e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f344c3a023842738909224226992cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab1a364d1eee4127ac3d7d3de675f6cf",
            "placeholder": "​",
            "style": "IPY_MODEL_28eeb00e66254e219cb07c5e6de951bb",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "3298f42445a84befb7be6a74bdc6994d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33c0114e93eb403aa62960f1c1afeaed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ba82261caac44268478b80a419c533e",
            "placeholder": "​",
            "style": "IPY_MODEL_d559e7a6bd1a49efa03ad4fbf6c2a88a",
            "value": "config.json: 100%"
          }
        },
        "3444008a5fae481eae6115d1e641def7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b97034662c24ae5b2fc47806cae5624": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ee32d87b5e441a3addf947884e0adaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5961190ae3b74ce484bd9a3bcc7a1143": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bd46bdebba14971991dcf895d95db67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9b5c06104994b0f93f2e27a68ac4791",
            "placeholder": "​",
            "style": "IPY_MODEL_d0f0e65a087145bfbd03fad72350b471",
            "value": " 466k/466k [00:00&lt;00:00, 31.5MB/s]"
          }
        },
        "5d197134c6d44f9cae581d9f86b6e49d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17aa28ae0025453d91d3a55a6874e25e",
            "placeholder": "​",
            "style": "IPY_MODEL_e07bdd6d77bd42e598a6f7fee72ea3a1",
            "value": " 285/285 [00:00&lt;00:00, 30.6kB/s]"
          }
        },
        "64b33ac07d9247f49e85a4da2d81aa4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65c8a3e82db3421b8f9d6df299ce3b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_add0cfe5e3bf461995759a8574c96968",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93f2c56396a54e7eace17c59eb56814a",
            "value": 466062
          }
        },
        "68eaed5efd1f4a02994f84d1eab2a81e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09559db97be845618bf6ee17a03fcc06",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0956bce2899a4ebabc94385057f7df46",
            "value": 48
          }
        },
        "69badcd6913c417f861ab43d14d83ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_031142b2e3ac482094d50bb23b4a7002",
              "IPY_MODEL_9114a982a3d9491a9f9a91e9a08b2a2d",
              "IPY_MODEL_e3b512a6bf08468998b627672ffae1d2"
            ],
            "layout": "IPY_MODEL_d18bd629a3b7439e8b540a42d0e531b3"
          }
        },
        "6a0e67332816456a8b8958b6ec655ba7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b9af207d4ec4fe38d20ad1e857fe9c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24faffb0f2cc493b81be853e98d15c32",
            "placeholder": "​",
            "style": "IPY_MODEL_9f7e50698a994055bd579c027eeb6f83",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "71bfa449a40446169ead01da5ff90f66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec96dfc4dc3240b882b477f4d13ac9bc",
              "IPY_MODEL_ec554037107d43a6a38c3f99b2fe0385",
              "IPY_MODEL_10590409029146caa83437d477e78e1b"
            ],
            "layout": "IPY_MODEL_041edde5a8bd4b569993f53d3cf26fdd"
          }
        },
        "77d7ebc6ae8542399c0be50ca9d9467f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbb4600683f4483a849e92eff04eadd4",
            "max": 17756393,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64b33ac07d9247f49e85a4da2d81aa4f",
            "value": 17756393
          }
        },
        "7bac0ee1fac24534a5508edb5b95b13b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84120f445d3f48b999edbcde57f039e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bac0ee1fac24534a5508edb5b95b13b",
            "placeholder": "​",
            "style": "IPY_MODEL_4ee32d87b5e441a3addf947884e0adaf",
            "value": " 48.0/48.0 [00:00&lt;00:00, 3.14kB/s]"
          }
        },
        "8cf43d98a7754984a33a899b8f6fd99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9114a982a3d9491a9f9a91e9a08b2a2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a0e67332816456a8b8958b6ec655ba7",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b97034662c24ae5b2fc47806cae5624",
            "value": 570
          }
        },
        "924732cc80d3413cad8073893b910798": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0a445082eb843728c6774a311013bf4",
              "IPY_MODEL_65c8a3e82db3421b8f9d6df299ce3b9c",
              "IPY_MODEL_5bd46bdebba14971991dcf895d95db67"
            ],
            "layout": "IPY_MODEL_b0d836922c274d19bad1ad786004c440"
          }
        },
        "93f2c56396a54e7eace17c59eb56814a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96044298938747a1a09156c9e1228e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b9af207d4ec4fe38d20ad1e857fe9c7",
              "IPY_MODEL_68eaed5efd1f4a02994f84d1eab2a81e",
              "IPY_MODEL_84120f445d3f48b999edbcde57f039e6"
            ],
            "layout": "IPY_MODEL_08b9d4279323448d9e08a9d2c6fdd657"
          }
        },
        "9f7e50698a994055bd579c027eeb6f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab1a364d1eee4127ac3d7d3de675f6cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "add0cfe5e3bf461995759a8574c96968": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0d836922c274d19bad1ad786004c440": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b37d4a10643f4e57adea9f7f5757620c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3e3507ed2214f13ac060547936d75e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b574a0bad93548d7b674966cda3cd628": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfbb99e1654b497c801256f6cfe59ecf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c05ae15a3d3249da845a07b90214a039": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b37d4a10643f4e57adea9f7f5757620c",
            "max": 285,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8cf43d98a7754984a33a899b8f6fd99a",
            "value": 285
          }
        },
        "c7dbfeab2af744729285168187bf164d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0f0e65a087145bfbd03fad72350b471": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d18bd629a3b7439e8b540a42d0e531b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d559e7a6bd1a49efa03ad4fbf6c2a88a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbb4600683f4483a849e92eff04eadd4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e07bdd6d77bd42e598a6f7fee72ea3a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3b512a6bf08468998b627672ffae1d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7dbfeab2af744729285168187bf164d",
            "placeholder": "​",
            "style": "IPY_MODEL_2354cf539d8e442ab6cd96da6bf250df",
            "value": " 570/570 [00:00&lt;00:00, 38.6kB/s]"
          }
        },
        "e9b5c06104994b0f93f2e27a68ac4791": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec554037107d43a6a38c3f99b2fe0385": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27c9fd3f410a4f499214833a91490f5d",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe849d3c0cb843faa080bea83a0e6963",
            "value": 231508
          }
        },
        "ec96dfc4dc3240b882b477f4d13ac9bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3e3507ed2214f13ac060547936d75e9",
            "placeholder": "​",
            "style": "IPY_MODEL_0ed6ab84876949b3ba6c42dae4da0af9",
            "value": "vocab.txt: 100%"
          }
        },
        "f0a445082eb843728c6774a311013bf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfbb99e1654b497c801256f6cfe59ecf",
            "placeholder": "​",
            "style": "IPY_MODEL_f83d081c31984c19b819bdd147f68f75",
            "value": "tokenizer.json: 100%"
          }
        },
        "f83d081c31984c19b819bdd147f68f75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe849d3c0cb843faa080bea83a0e6963": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9edba1042804479a82b136f9b313e56a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb8cfa34a1e344228e29687dc7b1c831",
              "IPY_MODEL_af7b6a3739284bb3b27b2060f95b02e7",
              "IPY_MODEL_62a755e72fee41baa738db4243c8fc90"
            ],
            "layout": "IPY_MODEL_c14268ad55b6467d981216d9fbce126b"
          }
        },
        "bb8cfa34a1e344228e29687dc7b1c831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e848b0e977834aa2bd1de69722ea19b4",
            "placeholder": "​",
            "style": "IPY_MODEL_c44a27d2b2084e8c87388e387b74b01e",
            "value": "Map: 100%"
          }
        },
        "af7b6a3739284bb3b27b2060f95b02e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dc7b9bc81754949bd593863fc220030",
            "max": 3798,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9a130692d7c44bc85393a4d0bb60826",
            "value": 3798
          }
        },
        "62a755e72fee41baa738db4243c8fc90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_038350758df3424397a311ce652983d0",
            "placeholder": "​",
            "style": "IPY_MODEL_ed4547ffcf8c41afad7684c92fb58f97",
            "value": " 3798/3798 [00:02&lt;00:00, 1195.08 examples/s]"
          }
        },
        "c14268ad55b6467d981216d9fbce126b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e848b0e977834aa2bd1de69722ea19b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c44a27d2b2084e8c87388e387b74b01e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dc7b9bc81754949bd593863fc220030": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9a130692d7c44bc85393a4d0bb60826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "038350758df3424397a311ce652983d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed4547ffcf8c41afad7684c92fb58f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cdadaafc85646c983be4526c98703a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ec092ab8281471e8a92a6023de28cbe",
              "IPY_MODEL_d5b75e465aed4c858983c61ad42f4029",
              "IPY_MODEL_9b136e6e56464ecbb41814ca5dcb4128"
            ],
            "layout": "IPY_MODEL_b86e02f28254405f9ce5b717bd24c2a6"
          }
        },
        "5ec092ab8281471e8a92a6023de28cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4caa457727fc4374a6db2e6618a03f6f",
            "placeholder": "​",
            "style": "IPY_MODEL_6913377a7b4a4be6b298ff756df7cd99",
            "value": "Map: 100%"
          }
        },
        "d5b75e465aed4c858983c61ad42f4029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b95d00887ed54536bfac15262cf1a0ac",
            "max": 3798,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16876b19211e417096d3671a9bb7fbf5",
            "value": 3798
          }
        },
        "9b136e6e56464ecbb41814ca5dcb4128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e7b0eb1961c429eaf614ca8d87e1164",
            "placeholder": "​",
            "style": "IPY_MODEL_02ea210080964d6ba8256e7b11fc5ea3",
            "value": " 3798/3798 [00:02&lt;00:00, 1676.05 examples/s]"
          }
        },
        "b86e02f28254405f9ce5b717bd24c2a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4caa457727fc4374a6db2e6618a03f6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6913377a7b4a4be6b298ff756df7cd99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b95d00887ed54536bfac15262cf1a0ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16876b19211e417096d3671a9bb7fbf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e7b0eb1961c429eaf614ca8d87e1164": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02ea210080964d6ba8256e7b11fc5ea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bed0b4983b9b4576a6600a880bb76e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1ad405014644da5b8980847af95304c",
              "IPY_MODEL_5eed99b6222b413fb4b5ced076525938",
              "IPY_MODEL_adeecb142c604009b2964b6394054510"
            ],
            "layout": "IPY_MODEL_51cd25ce78ee4bffa33b80b75cb1af7d"
          }
        },
        "d1ad405014644da5b8980847af95304c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a96ab8116fd43609576a5d31778cd1e",
            "placeholder": "​",
            "style": "IPY_MODEL_1f9fdb59945049689281eb420b5d6653",
            "value": "Map: 100%"
          }
        },
        "5eed99b6222b413fb4b5ced076525938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7eefd945d51e4b94934f1a008dbefbfc",
            "max": 3798,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70bc96cccabd4bf588fd09f423207839",
            "value": 3798
          }
        },
        "adeecb142c604009b2964b6394054510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e29f45ec71c4acb960e62540f663c58",
            "placeholder": "​",
            "style": "IPY_MODEL_aea447e1b47147eaa20464cbebfe2e14",
            "value": " 3798/3798 [00:02&lt;00:00, 1563.07 examples/s]"
          }
        },
        "51cd25ce78ee4bffa33b80b75cb1af7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a96ab8116fd43609576a5d31778cd1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f9fdb59945049689281eb420b5d6653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7eefd945d51e4b94934f1a008dbefbfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70bc96cccabd4bf588fd09f423207839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e29f45ec71c4acb960e62540f663c58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aea447e1b47147eaa20464cbebfe2e14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f318c7c4382847d5b19c240459ac5b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8dddca5bb871409796c0cad41d85a7b0",
              "IPY_MODEL_51379ca15a394e058cf0ed34c84cf26c",
              "IPY_MODEL_d9aad16632a7499db1a98a63c7c6367e"
            ],
            "layout": "IPY_MODEL_550727572e1b4a51bafe7d0426180e26"
          }
        },
        "8dddca5bb871409796c0cad41d85a7b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f44219bb029476585533087bdc03179",
            "placeholder": "​",
            "style": "IPY_MODEL_e64e56b74ecf4137b2b8ec6f7da61c26",
            "value": "Map: 100%"
          }
        },
        "51379ca15a394e058cf0ed34c84cf26c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96bcb75ff5dc416eae938d31ab50b153",
            "max": 3798,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_592d2522d832464ba606fc2843f0e23a",
            "value": 3798
          }
        },
        "d9aad16632a7499db1a98a63c7c6367e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bf785f725994a5bbd4fe86bc942410c",
            "placeholder": "​",
            "style": "IPY_MODEL_b681f8802978478daa029bf61792b9e8",
            "value": " 3798/3798 [00:02&lt;00:00, 1622.44 examples/s]"
          }
        },
        "550727572e1b4a51bafe7d0426180e26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f44219bb029476585533087bdc03179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e64e56b74ecf4137b2b8ec6f7da61c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96bcb75ff5dc416eae938d31ab50b153": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "592d2522d832464ba606fc2843f0e23a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8bf785f725994a5bbd4fe86bc942410c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b681f8802978478daa029bf61792b9e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
